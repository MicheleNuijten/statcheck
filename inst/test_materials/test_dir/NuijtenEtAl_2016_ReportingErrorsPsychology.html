<!DOCTYPE html>
<html lang="en" class="no-js">
<head>
    <meta charset="UTF-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="access" content="Yes">
    

    <meta name="journal_id" content="13428"/>

    <meta name="dc.title" content="The prevalence of statistical reporting errors in psychology (1985&#8211;2013)"/>

    <meta name="dc.source" content="Behavior Research Methods 2015 48:4"/>

    <meta name="dc.format" content="text/html"/>

    <meta name="dc.publisher" content="Springer"/>

    <meta name="dc.date" content="2015-10-23"/>

    <meta name="dc.type" content="OriginalPaper"/>

    <meta name="dc.language" content="En"/>

    <meta name="dc.copyright" content="2015 The Author(s)"/>

    <meta name="dc.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="dc.description" content="This study documents reporting errors in a sample of over 250,000 p-values reported in eight major psychology journals from 1985 until 2013, using the new R package &#8220;statcheck.&#8221; statcheck retrieved null-hypothesis significance testing (NHST) results from over half of the articles from this period. In line with earlier research, we found that half of all published psychology papers that use NHST contained at least one p-value that was inconsistent with its test statistic and degrees of freedom. One in eight papers contained a grossly inconsistent p-value that may have affected the statistical conclusion. In contrast to earlier findings, we found that the average prevalence of inconsistent p-values has been stable over the years or has declined. The prevalence of gross inconsistencies was higher in p-values reported as significant than in p-values reported as nonsignificant. This could indicate a systematic bias in favor of significant results. Possible solutions for the high prevalence of reporting inconsistencies could be to encourage sharing data, to let co-authors check results in a so-called &#8220;co-pilot model,&#8221; and to use statcheck to flag possible inconsistencies in one&#8217;s own manuscript or during the review process."/>

    <meta name="prism.issn" content="1554-3528"/>

    <meta name="prism.publicationName" content="Behavior Research Methods"/>

    <meta name="prism.publicationDate" content="2015-10-23"/>

    <meta name="prism.volume" content="48"/>

    <meta name="prism.number" content="4"/>

    <meta name="prism.section" content="OriginalPaper"/>

    <meta name="prism.startingPage" content="1205"/>

    <meta name="prism.endingPage" content="1226"/>

    <meta name="prism.copyright" content="2015 The Author(s)"/>

    <meta name="prism.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="prism.url" content="https://link.springer.com/article/10.3758/s13428-015-0664-2"/>

    <meta name="prism.doi" content="doi:10.3758/s13428-015-0664-2"/>

    <meta name="citation_pdf_url" content="https://link.springer.com/content/pdf/10.3758/s13428-015-0664-2.pdf"/>

    <meta name="citation_fulltext_html_url" content="https://link.springer.com/article/10.3758/s13428-015-0664-2"/>

    <meta name="citation_journal_title" content="Behavior Research Methods"/>

    <meta name="citation_journal_abbrev" content="Behav Res "/>

    <meta name="citation_publisher" content="Springer US"/>

    <meta name="citation_issn" content="1554-3528"/>

    <meta name="citation_title" content="The prevalence of statistical reporting errors in psychology (1985&#8211;2013)"/>

    <meta name="citation_volume" content="48"/>

    <meta name="citation_issue" content="4"/>

    <meta name="citation_publication_date" content="2016/12"/>

    <meta name="citation_online_date" content="2015/10/23"/>

    <meta name="citation_firstpage" content="1205"/>

    <meta name="citation_lastpage" content="1226"/>

    <meta name="citation_article_type" content="Article"/>

    <meta name="citation_fulltext_world_readable" content=""/>

    <meta name="citation_language" content="en"/>

    <meta name="dc.identifier" content="doi:10.3758/s13428-015-0664-2"/>

    <meta name="DOI" content="10.3758/s13428-015-0664-2"/>

    <meta name="citation_doi" content="10.3758/s13428-015-0664-2"/>

    <meta name="description" content="This study documents reporting errors in a sample of over 250,000 p-values reported in eight major psychology journals from 1985 until 2013, using the new "/>

    <meta name="dc.creator" content="Mich&#232;le B. Nuijten"/>

    <meta name="dc.creator" content="Chris H. J. Hartgerink"/>

    <meta name="dc.creator" content="Marcel A. L. M. van Assen"/>

    <meta name="dc.creator" content="Sacha Epskamp"/>

    <meta name="dc.creator" content="Jelte M. Wicherts"/>

    <meta name="dc.subject" content="Cognitive Psychology"/>

    <meta name="citation_reference" content="citation_journal_title=PLoS One; citation_title=Public availability of published research data in high-impact journals; citation_author=AA Alsheikh-Ali, W Qureshi, MH Al-Mallah, JPA Ioannidis; citation_volume=6; citation_issue=9; citation_publication_date=2011; citation_pages=e24357; citation_doi=10.1371/journal.pone.0024357; citation_id=CR1"/>

    <meta name="citation_reference" content="citation_title=Publication Manual of the American Psychological Association; citation_publication_date=1983; citation_id=CR2; citation_publisher=American Psychological Association"/>

    <meta name="citation_reference" content="citation_title=Publication Manual of the American Psychological Association; citation_publication_date=2010; citation_id=CR3; citation_publisher=American Psychological Association"/>

    <meta name="citation_reference" content="citation_journal_title=Behavior Research Methods; citation_title=The (mis)reporting of statistical results in psychology journals; citation_author=M Bakker, JM Wicherts; citation_volume=43; citation_publication_date=2011; citation_pages=666-678; citation_doi=10.3758/s13428-011-0089-5; citation_id=CR4"/>

    <meta name="citation_reference" content="Bakker, M., &amp; Wicherts, J. M. (2014). Outlier removal and the relation with reporting errors and quality of research. Manuscript submitted for publication."/>

    <meta name="citation_reference" content="citation_journal_title=International Journal of Methods in Psychiatric Research; citation_title=Inconsistencies between reported test statistics and p-values in two psychiatry journals; citation_author=D Berle, V Starcevic; citation_volume=16; citation_issue=4; citation_publication_date=2007; citation_pages=202-207; citation_doi=10.1002/mpr.225; citation_id=CR6"/>

    <meta name="citation_reference" content="citation_journal_title=Psicothema; citation_title=Consistency errors in p-values reported in Spanish psychology journals; citation_author=JM Caperos, A Pardo; citation_volume=25; citation_issue=3; citation_publication_date=2013; citation_pages=408-414; citation_id=CR7"/>

    <meta name="citation_reference" content="Chamberlain, S., Boettiger, C., &amp; Ram, K. (2014). rplos: Interface to PLoS Journals search API. R package version 0.4.0. 
                    http://CRAN.R-project.org/package=rplos
                    
                  
                        "/>

    <meta name="citation_reference" content="citation_journal_title=American Psychologist; citation_title=The earth is round (P less-than.05); citation_author=J Cohen; citation_volume=49; citation_issue=12; citation_publication_date=1994; citation_pages=997-1003; citation_doi=10.1037/0003-066X.49.12.997; citation_id=CR9"/>

    <meta name="citation_reference" content="Cumming, G., Fidler, F., Leonard, M., Kalinowski, P., Christiansen, A., Kleinig, A., . . . Wilson, S. (2007). Statistical reform in psychology: Is anything changing? Psychological science, 18(3), 230&#8211;232."/>

    <meta name="citation_reference" content="Epskamp, S., &amp; Nuijten, M. B. (2015). statcheck: Extract statistics from articles and recompute p values. R package version 1.0.1. 
                    http://CRAN.R-project.org/package=statcheck
                    
                  
                        "/>

    <meta name="citation_reference" content="citation_journal_title=Scientometrics; citation_title=Negative results are disappearing from most disciplines and countries; citation_author=D Fanelli; citation_volume=90; citation_issue=3; citation_publication_date=2012; citation_pages=891-904; citation_doi=10.1007/s11192-011-0494-7; citation_id=CR12"/>

    <meta name="citation_reference" content="Fanelli, D. (2013). Why Growing Retractions Are (Mostly) a Good Sign. Plos Medicine, 10(12). doi: 
                    10.1371/journal.pmed.1001563
                    
                  
                        "/>

    <meta name="citation_reference" content="citation_journal_title=Nature; citation_title=Rise in retractions is a signal of integrity; citation_author=D Fanelli; citation_volume=509; citation_issue=7498; citation_publication_date=2014; citation_pages=33-33; citation_doi=10.1038/509033a; citation_id=CR14"/>

    <meta name="citation_reference" content="Fidler, F., &amp; Cumming, G. (2005). Teaching confidence intervals: Problems and potential solutions. Proceedings of the 55th International Statistics Institute Session."/>

    <meta name="citation_reference" content="Fiedler, K., &amp; Schwarz, N. (2015). Questionable Research Practices Revisited."/>

    <meta name="citation_reference" content="citation_journal_title=Journal of Personality and Social Psychology; citation_title=Best research practices in psychology: Illustrating epistemological and pragmatic considerations with the case of relationship science; citation_author=EJ Finkel, PW Eastwick, HT Reis; citation_volume=108; citation_issue=2; citation_publication_date=2015; citation_pages=275-297; citation_doi=10.1037/pspi0000007; citation_id=CR17"/>

    <meta name="citation_reference" content="citation_journal_title=Bmc Medical Research Methodology; citation_title=Incongruence between test statistics and P values in medical papers; citation_author=E Garcia-Berthou, C Alcaraz; citation_volume=4; citation_publication_date=2004; citation_pages=13; citation_doi=10.1186/1471-2288-4-13; citation_id=CR18"/>

    <meta name="citation_reference" content="citation_journal_title=Perspectives on Psychological Science; citation_title=Science or art? How aesthetic standards grease the way through the publication bottleneck but undermine science; citation_author=R Giner-Sorolla; citation_volume=7; citation_publication_date=2012; citation_pages=562-571; citation_doi=10.1177/1745691612457576; citation_id=CR19"/>

    <meta name="citation_reference" content="citation_journal_title=Jama-Journal of the American Medical Association; citation_title=Data extraction errors in meta-analyses that use standardized mean differences; citation_author=PC Gotzsche, A Hrobjartsson, K Maric, B Tendal; citation_volume=298; citation_issue=4; citation_publication_date=2007; citation_pages=430-437; citation_doi=10.1001/jama.298.4.430; citation_id=CR20"/>

    <meta name="citation_reference" content="Hartgerink, C. H. J., van Assen, M. A. L. M., &amp; Wicherts, J. M. (2015). Too Good to be False: Non-Significant Results Revisited. Retrieved from osf.io/qpfnw."/>

    <meta name="citation_reference" content="citation_journal_title=Educational and Psychological Measurement; citation_title=The historical growth of statistical significance testing in psychology-and its future prospects; citation_author=R Hubbard, PA Ryan; citation_volume=60; citation_publication_date=2000; citation_pages=661-681; citation_id=CR22"/>

    <meta name="citation_reference" content="citation_journal_title=Psychological science; citation_title=Measuring the prevalence of questionable research practices with incentives for truth-telling; citation_author=LK John, G Loewenstein, D Prelec; citation_volume=23; citation_publication_date=2012; citation_pages=524-532; citation_doi=10.1177/0956797611430953; citation_id=CR23"/>

    <meta name="citation_reference" content="citation_journal_title=American Psychologist; citation_title=Null hypothesis significance testing - On the survival of a flawed method; citation_author=J Krueger; citation_volume=56; citation_issue=1; citation_publication_date=2001; citation_pages=16-26; citation_doi=10.1037/0003-066X.56.1.16; citation_id=CR24"/>

    <meta name="citation_reference" content="citation_journal_title=The Quarterly Journal of Experimental Psychology; citation_title=The life of p:&#8220;Just significant&#8221; results are on the rise; citation_author=NC Leggett, NA Thomas, T Loetscher, ME Nicholls; citation_volume=66; citation_issue=12; citation_publication_date=2013; citation_pages=2303-2309; citation_doi=10.1080/17470218.2013.863371; citation_id=CR25"/>

    <meta name="citation_reference" content="citation_journal_title=Human Communication Research; citation_title=Eta squared, partial eta squared, and misreporting of effect size in communication research; citation_author=TR Levine, CR Hullett; citation_volume=28; citation_issue=4; citation_publication_date=2002; citation_pages=612-625; citation_doi=10.1111/j.1468-2958.2002.tb00828.x; citation_id=CR26"/>

    <meta name="citation_reference" content="citation_journal_title=Perspectives on Psychological Science; citation_title=Scientific Utopia: II - Restructuring Incentives and Practices to Promote Truth Over Publishability; citation_author=BA Nosek, J Spies, M Motyl; citation_volume=7; citation_publication_date=2012; citation_pages=615-631; citation_doi=10.1177/1745691612459058; citation_id=CR27"/>

    <meta name="citation_reference" content="R Core Team. (2014). R: A Language and Environment for Statistical Computing. 
                    http://www.R-project.org/
                    
                  
                        "/>

    <meta name="citation_reference" content="citation_journal_title=Psychological Bulletin; citation_title=The fallacy of the null hypothesis significance test; citation_author=WW Rozeboom; citation_volume=57; citation_publication_date=1960; citation_pages=416-428; citation_doi=10.1037/h0042040; citation_id=CR29"/>

    <meta name="citation_reference" content="citation_journal_title=Perspectives on Psychological Science; citation_title=Analytic Review as a Solution to the Misreporting of Statistical Results in Psychological Science; citation_author=J Sakaluk, A Williams, M Biernat; citation_volume=9; citation_issue=6; citation_publication_date=2014; citation_pages=652-660; citation_doi=10.1177/1745691614549257; citation_id=CR30"/>

    <meta name="citation_reference" content="citation_journal_title=Journal of Experimental Psychology: General; citation_title=P-curve: A key to the file-drawer; citation_author=U Simonsohn, LD Nelson, JP Simmons; citation_volume=143; citation_issue=2; citation_publication_date=2014; citation_pages=534-547; citation_doi=10.1037/a0033242; citation_id=CR31"/>

    <meta name="citation_reference" content="citation_journal_title=Journal of the American Statistical Association; citation_title=Publication decisions and their possible effects on inferences drawn from tests of significance - Or vice versa; citation_author=TD Sterling; citation_volume=54; citation_publication_date=1959; citation_pages=30-34; citation_id=CR32"/>

    <meta name="citation_reference" content="citation_journal_title=American Statistician; citation_title=Publication decisions revisited - The effect of the outcome of statistical tests on the decision to publish and vice-versa; citation_author=TD Sterling, WL Rosenbaum, JJ Weinkam; citation_volume=49; citation_issue=1; citation_publication_date=1995; citation_pages=108-112; citation_id=CR33"/>

    <meta name="citation_reference" content="Van Assen, M. A. L. M., Van Aert, R. C. M., &amp; Wicherts, J. M. (2014). Meta-analysis using effect size distributions of only statistically significant studies. Psychological Methods."/>

    <meta name="citation_reference" content="Veldkamp, C. L. S., Nuijten, M. B., Dominguez-Alvarez, L., Van Assen, M. A. L. M., &amp; Wicherts, J. M. (2014). Statistical reporting errors and collaboration on statistical analyses in psychological science PLoS One."/>

    <meta name="citation_reference" content="citation_journal_title=Psychonomic Bulletin &amp; Review; citation_title=A practical solution to the pervasive problems of p values; citation_author=EJ Wagenmakers; citation_volume=14; citation_publication_date=2007; citation_pages=779-804; citation_doi=10.3758/BF03194105; citation_id=CR36"/>

    <meta name="citation_reference" content="citation_journal_title=Nature; citation_title=Psychology must learn a lesson from fraud case; citation_author=JM Wicherts; citation_volume=480; citation_publication_date=2011; citation_pages=7; citation_doi=10.1038/480007a; citation_id=CR37"/>

    <meta name="citation_reference" content="citation_journal_title=Journal of Open Psychology Data; citation_title=Science revolves around the data; citation_author=JM Wicherts; citation_volume=1; citation_issue=1; citation_publication_date=2013; citation_pages=e1; citation_doi=10.5334/jopd.e1; citation_id=CR38"/>

    <meta name="citation_reference" content="citation_journal_title=Intelligence; citation_title=Publish (your data) or (let the data) perish! Why not publish your data too?; citation_author=JM Wicherts, M Bakker; citation_publication_date=2012; citation_id=CR39"/>

    <meta name="citation_reference" content="citation_journal_title=PLoS One; citation_title=Willingness to share research data is related to the strength of the evidence and the quality of reporting of statistical results; citation_author=JM Wicherts, M Bakker, D Molenaar; citation_volume=6; citation_issue=11; citation_publication_date=2011; citation_pages=e26828; citation_doi=10.1371/journal.pone.0026828; citation_id=CR40"/>

    <meta name="citation_author" content="Mich&#232;le B. Nuijten"/>

    <meta name="citation_author_email" content="m.b.nuijten@uvt.nl"/>

    <meta name="citation_author_institution" content="Department of Methodology and Statistics, Tilburg School of Social and Behavioral Sciences, Tilburg University, Tilburg, Netherlands"/>

    <meta name="citation_author" content="Chris H. J. Hartgerink"/>

    <meta name="citation_author_institution" content="Department of Methodology and Statistics, Tilburg School of Social and Behavioral Sciences, Tilburg University, Tilburg, Netherlands"/>

    <meta name="citation_author" content="Marcel A. L. M. van Assen"/>

    <meta name="citation_author_institution" content="Department of Methodology and Statistics, Tilburg School of Social and Behavioral Sciences, Tilburg University, Tilburg, Netherlands"/>

    <meta name="citation_author" content="Sacha Epskamp"/>

    <meta name="citation_author_institution" content="Psychological Methods, University of Amsterdam, Amsterdam, Netherlands"/>

    <meta name="citation_author" content="Jelte M. Wicherts"/>

    <meta name="citation_author_institution" content="Department of Methodology and Statistics, Tilburg School of Social and Behavioral Sciences, Tilburg University, Tilburg, Netherlands"/>

    <meta name="twitter:card" content="summary"/>

    <meta name="twitter:title" content="The prevalence of statistical reporting errors in psychology (1985&#82"/>

    <meta name="twitter:site" content="@SpringerLink"/>

    <meta name="twitter:description" content="This study documents reporting errors in a sample of over 250,000 p-values reported in eight major psychology journals from 1985 until 2013, using the new R package &#8220;statcheck.&#8221; statcheck retrieved null-hypothesis significance testing (NHST) results from over half of the articles from this period. In line with earlier research, we found that half of all published psychology papers that use NHST contained at least one p-value that was inconsistent with its test statistic and degrees of freedom. One in eight papers contained a grossly inconsistent p-value that may have affected the statistical conclusion. In contrast to earlier findings, we found that the average prevalence of inconsistent p-values has been stable over the years or has declined. The prevalence of gross inconsistencies was higher in p-values reported as significant than in p-values reported as nonsignificant. This could indicate a systematic bias in favor of significant results. Possible solutions for the high prevalence of reporting inconsistencies could be to encourage sharing data, to let co-authors check results in a so-called &#8220;co-pilot model,&#8221; and to use statcheck to flag possible inconsistencies in one&#8217;s own manuscript or during the review process."/>

    <meta name="twitter:image" content="https://static-content.springer.com/cover/journal/13428/48/4.jpg"/>

    <meta name="twitter:image:alt" content="Content cover image"/>

    <meta name="citation_springer_api_url" content="http://api.springer.com/metadata/pam?q=doi:10.3758/s13428-015-0664-2&amp;api_key="/>

    <meta name="format-detection" content="telephone=no"/>

    <meta name="citation_cover_date" content="2016/12/01"/>


    
        <meta property="og:url" content="https://link.springer.com/article/10.3758/s13428-015-0664-2"/>
        <meta property="og:type" content="article"/>
        <meta property="og:site_name" content="Behavior Research Methods"/>
        <meta property="og:title" content="The prevalence of statistical reporting errors in psychology (1985–2013)"/>
        <meta property="og:description" content="This study documents reporting errors in a sample of over 250,000 p-values reported in eight major psychology journals from 1985 until 2013, using the new R package “statcheck.” statcheck retrieved null-hypothesis significance testing (NHST) results from over half of the articles from this period. In line with earlier research, we found that half of all published psychology papers that use NHST contained at least one p-value that was inconsistent with its test statistic and degrees of freedom. One in eight papers contained a grossly inconsistent p-value that may have affected the statistical conclusion. In contrast to earlier findings, we found that the average prevalence of inconsistent p-values has been stable over the years or has declined. The prevalence of gross inconsistencies was higher in p-values reported as significant than in p-values reported as nonsignificant. This could indicate a systematic bias in favor of significant results. Possible solutions for the high prevalence of reporting inconsistencies could be to encourage sharing data, to let co-authors check results in a so-called “co-pilot model,” and to use statcheck to flag possible inconsistencies in one’s own manuscript or during the review process."/>
        <meta property="og:image" content="https://media.springernature.com/w110/springer-static/cover/journal/13428.jpg"/>
    
    <title>The prevalence of statistical reporting errors in psychology (1985–2013) | SpringerLink</title>
        <link rel="shortcut icon" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
    <link rel="icon" sizes="16x16 32x32 48x48" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
    <link rel="icon" sizes="16x16" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-16x16-8bd8c1c945.png />
    <link rel="icon" sizes="32x32" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-32x32-61a52d80ab.png />
    <link rel="icon" sizes="48x48" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-48x48-0ec46b6b10.png />
    <link rel="apple-touch-icon" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />
    <link rel="apple-touch-icon" sizes="72x72" href=/oscar-static/images/favicons/springerlink/ic_launcher_hdpi-f77cda7f65.png />
    <link rel="apple-touch-icon" sizes="76x76" href=/oscar-static/images/favicons/springerlink/app-icon-ipad-c3fd26520d.png />
    <link rel="apple-touch-icon" sizes="114x114" href=/oscar-static/images/favicons/springerlink/app-icon-114x114-3d7d4cf9f3.png />
    <link rel="apple-touch-icon" sizes="120x120" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@2x-67b35150b3.png />
    <link rel="apple-touch-icon" sizes="144x144" href=/oscar-static/images/favicons/springerlink/ic_launcher_xxhdpi-986442de7b.png />
    <link rel="apple-touch-icon" sizes="152x152" href=/oscar-static/images/favicons/springerlink/app-icon-ipad@2x-677ba24d04.png />
    <link rel="apple-touch-icon" sizes="180x180" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />

    <link rel="stylesheet" href=/oscar-static/app-springerlink/css/core-article-2e8ab716a5.css media="screen">
    <link rel="stylesheet" id="js-mustard" href=/oscar-static/app-springerlink/css/enhanced-article-637281cf09.css media="only screen and (-webkit-min-device-pixel-ratio:0) and (min-color-index:0), (-ms-high-contrast: none), only all and (min--moz-device-pixel-ratio:0) and (min-resolution: 3e1dpcm)">

    
    <script type="text/javascript">
        window.dataLayer = [{"Country":"NL","doi":"10.3758-s13428-015-0664-2","Journal Title":"Behavior Research Methods","Journal Id":13428,"Keywords":"Reporting errors, \n                        p-values, Significance, False positives, NHST, Questionable research practices, Publication bias","kwrd":["Reporting_errors","\n________________________p-values","Significance","False_positives","NHST","Questionable_research_practices","Publication_bias"],"Labs":"Y","ksg":"Krux.segments","kuid":"Krux.uid","Has Body":"Y","Features":[],"Open Access":"Y","hasAccess":"Y","user":{"license":{"businessPartnerID":[],"businessPartnerIDString":""}},"Access Type":"subscription","Bpids":"","Bpnames":"","BPID":["1"],"VG Wort Identifier":"vgzm.415900-10.3758-s13428-015-0664-2","Full HTML":"Y","Subject Codes":["SCY","SCY20060"],"pmc":["Y","Y20060"],"session":{"authentication":{"loginStatus":"N"},"attributes":{"edition":"academic"}},"content":{"serial":{"eissn":"1554-3528"},"type":"Article","category":{"pmc":{"primarySubject":"Psychology","primarySubjectCode":"Y","secondarySubjects":{"1":"Cognitive Psychology"},"secondarySubjectCodes":{"1":"Y20060"}},"sucode":"SC1"},"attributes":{"deliveryPlatform":"oscar"}},"Event Category":"Article","GA Key":"UA-26408784-1","DOI":"10.3758/s13428-015-0664-2","Page":"article"}];
        var event = new CustomEvent('dataLayerCreated');
        document.dispatchEvent(event);
    </script>


    


<script src="/oscar-static/js/jquery-220afd743d.js" id="jquery"></script>

<script>
    function OptanonWrapper() {
        dataLayer.push({
            'event' : 'onetrustActive'
        });
    }
</script>


    <script data-test="onetrust-link" type="text/javascript" src="https://cdn.cookielaw.org/consent/6b2ec9cd-5ace-4387-96d2-963e596401c6.js" charset="UTF-8"></script>






</head>
<body class="shared-article-renderer">
    <div class="u-vh-full">
        <div class="c-ad c-ad--LB1" data-test="springer-doubleclick-ad">
    <div class="c-ad c-ad__inner">
        <p class="c-ad__label">Advertisement</p>
        <div id="div-gpt-ad-LB1" data-gpt-unitpath="/270604982/springerlink/13428/article" data-gpt-sizes="728x90" data-gpt-targeting="pos=LB1;articleid=664;"></div>
    </div>
</div>
<div class="c-banner c-banner--compact c-banner--marketing">
    <div class="u-container">
        <p class="u-ma-0">
    Springer Nature is making SARS-CoV-2 and COVID-19 research free.
<a class="c-banner__link u-underline"
   href="https://www.springernature.com/gp/researchers/campaigns/coronavirus"
   data-track="click"
   data-track-action="view coronavirus collection"
   data-track-category="article header"
   data-track-label="link">View research</a> |
<a class="c-banner__link u-underline"
   href="https://www.nature.com/articles/d41586-020-00154-w"
   data-track="click"
   data-track-action="latest news coronavirus"
   data-track-category="article header"
   data-track-label="link">View latest news</a> |
<a class="c-banner__link u-underline"
   href="https://www.nature.com/briefing/signup/"
   data-track="click"
   data-track-action="signup briefing coronavirus"
   data-track-category="article header"
   data-track-label="link">Sign up for updates</a>

</p>
    </div>
</div>

<div class="u-position-relative">
    <header class="c-header u-mb-24" data-test="publisher-header">
        <div class="c-header__container">
            <div class="c-header__brand">
                
    <a id="logo" class="u-display-block" href="/" title="Go to homepage" data-test="springerlink-logo">
        <picture>
            <source type="image/svg+xml" srcset=/oscar-static/images/springerlink/svg/springerlink-253e23a83d.svg>
            <img src=/oscar-static/images/springerlink/png/springerlink-1db8a5b8b1.png alt="SpringerLink" width="148" height="30" data-test="header-academic">
        </picture>
        
        
    </a>


            </div>
            <div class="c-header__navigation">
                
    
        <button type="button"
                class="c-header__link u-button-reset u-mr-24"
                data-expander
                data-expander-target="#popup-search"
                data-expander-autofocus="true"
                data-test="header-search-button">
            <span class="u-display-flex u-align-items-center">
                Search
                <svg class="c-icon u-ml-8" width="14" height="14" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </span>
        </button>
        <nav>
            <ul class="c-header__menu" data-enhanced-menu>
                <li class="c-header__item">
                    <a class="c-header__link" href="/">Home</a>
                </li>

                
                    <li class="c-header__item">
                        <a data-test="login-link" class="c-header__link" href="//link.springer.com/signup-login?previousUrl=https%3A%2F%2Flink.springer.com%2Farticle%2F10.3758%2Fs13428-015-0664-2">Log in</a>
                    </li>
                

                
            </ul>
        </nav>
    

    



            </div>
        </div>
    </header>

    
        <div id="popup-search" class="c-popup-search u-mb-16 js-header-search u-js-hide">
            <div class="c-popup-search__content">
                <div class="u-container">
                    <div class="c-popup-search__container" data-test="springerlink-popup-search">
                        <div class="app-search">
    <form role="search" method="GET" action="/search" >
        <label for="search" class="app-search__label">Search SpringerLink</label>
        <div class="app-search__content">
            <input id="search" class="app-search__input" data-search-input autocomplete="off" role="textbox" name="query" type="text" value="">
            <button class="app-search__button" type="submit">
                <span class="u-visually-hidden">Search</span>
                <div class="app-search__icon">
                    <svg class="c-icon" width="14" height="14" aria-hidden="true" focusable="false">
                        <use xlink:href="#global-icon-search"></use>
                    </svg>
                </div>
            </button>
            
                <input type="hidden" name="searchType" value="publisherSearch">
            
            
        </div>
    </form>
</div>

                    </div>
                </div>
            </div>
        </div>
    
</div>

        <div class="u-container u-mt-32 u-mb-32 u-clearfix" id="main-content" data-component="article-container">

            <main class="c-article-main-column u-float-left js-main-column">
                <article itemscope itemtype="http://schema.org/ScholarlyArticle" lang="en">
                    <div class="c-article-header">
                        <header>
                            <ul class="c-article-identifiers" data-test="article-identifier">
                                
    
    
        
            <li class="c-article-identifiers__item">
                <span class="c-article-identifiers__open" data-test="open-access">Open Access</span>
            </li>
        
    
    

                                <li class="c-article-identifiers__item"><a href="#article-info" data-track="click" data-track-action="publication date" data-track-category="article body" data-track-label="link">Published: <time datetime="2015-10-23" itemprop="datePublished">23 October 2015</time></a></li>
                            </ul>

                            
                            <h1 class="c-article-title u-h1" data-test="article-title" data-article-title="" itemprop="name headline">The prevalence of statistical reporting errors in psychology (1985–2013)</h1>
                            <ul class="c-author-list js-list-authors js-etal-collapsed" data-etal="25" data-etal-small="3" data-test="authors-list"><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-category="article body" data-track-label="link" href="#auth-1" data-corresp-id="c1">Michèle B. Nuijten<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-email"></use></svg></a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Tilburg University" /><meta itemprop="address" content="grid.12295.3d, 0000000109433265, Department of Methodology and Statistics, Tilburg School of Social and Behavioral Sciences, Tilburg University, Tilburg, Netherlands" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-category="article body" data-track-label="link" href="#auth-2">Chris H. J. Hartgerink</a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Tilburg University" /><meta itemprop="address" content="grid.12295.3d, 0000000109433265, Department of Methodology and Statistics, Tilburg School of Social and Behavioral Sciences, Tilburg University, Tilburg, Netherlands" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-category="article body" data-track-label="link" href="#auth-3">Marcel A. L. M. van Assen</a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Tilburg University" /><meta itemprop="address" content="grid.12295.3d, 0000000109433265, Department of Methodology and Statistics, Tilburg School of Social and Behavioral Sciences, Tilburg University, Tilburg, Netherlands" /></span></sup>, </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-category="article body" data-track-label="link" href="#auth-4">Sacha Epskamp</a></span><sup class="u-js-hide"><a href="#Aff2">2</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="University of Amsterdam" /><meta itemprop="address" content="grid.7177.6, 0000000084992262, Psychological Methods, University of Amsterdam, Amsterdam, Netherlands" /></span></sup> &amp; </li><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-category="article body" data-track-label="link" href="#auth-5">Jelte M. Wicherts</a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="Tilburg University" /><meta itemprop="address" content="grid.12295.3d, 0000000109433265, Department of Methodology and Statistics, Tilburg School of Social and Behavioral Sciences, Tilburg University, Tilburg, Netherlands" /></span></sup> </li></ul>
                            <p class="c-article-info-details" data-container-section="info">
                                
    <a data-test="journal-link" href="/journal/13428"><i data-test="journal-title">Behavior Research Methods</i></a>

                                <b data-test="journal-volume"><span class="u-visually-hidden">volume</span> 48</b>, <span class="u-visually-hidden">pages</span><span itemprop="pageStart">1205</span>–<span itemprop="pageEnd">1226</span>(<span data-test="article-publication-year">2016</span>)<a href="#citeas" class="c-article-info-details__cite-as u-hide-print" data-track="click" data-track-action="cite this article" data-track-category="article body" data-track-label="link">Cite this article</a>
                            </p>
                            
    

                            <div data-test="article-metrics">
                                <div id="altmetric-container">
    
        <div class="c-article-metrics-bar__wrapper u-clear-both">
            <ul class="c-article-metrics-bar u-list-inline">
                
                    <li class=" c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">30k <span class="c-article-metrics-bar__label">Accesses</span></p>
                    </li>
                
                
                    <li class="c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">116 <span class="c-article-metrics-bar__label">Citations</span></p>
                    </li>
                
                
                    
                        <li class="c-article-metrics-bar__item">
                            <p class="c-article-metrics-bar__count">379 <span class="c-article-metrics-bar__label">Altmetric</span></p>
                        </li>
                    
                
                <li class="c-article-metrics-bar__item">
                    <p class="c-article-metrics-bar__details"><a href="/article/10.3758%2Fs13428-015-0664-2/metrics" data-track="click" data-track-action="view metrics" data-track-category="article body" data-track-label="link" rel="nofollow">Metrics <span class="u-visually-hidden">details</span></a></p>
                </li>
            </ul>
        </div>
    
</div>

                            </div>
                            
                            
                            
                        </header>
                    </div>

                    <div data-article-body="true" data-track-component="article body" class="c-article-body">
                        <section aria-labelledby="Abs1" lang="en"><div class="c-article-section" id="Abs1-section"><h2 class="c-article-section__title u-h2 js-section-title js-c-reading-companion-sections-item" id="Abs1">Abstract</h2><div class="c-article-section__content" id="Abs1-content"><p>This study documents reporting errors in a sample of over 250,000 <i>p</i>-values reported in eight major psychology journals from 1985 until 2013, using the new R package “statcheck.” statcheck retrieved null-hypothesis significance testing (NHST) results from over half of the articles from this period. In line with earlier research, we found that half of all published psychology papers that use NHST contained at least one <i>p</i>-value that was inconsistent with its test statistic and degrees of freedom. One in eight papers contained a grossly inconsistent <i>p</i>-value that may have affected the statistical conclusion. In contrast to earlier findings, we found that the average prevalence of inconsistent <i>p</i>-values has been stable over the years or has declined. The prevalence of gross inconsistencies was higher in <i>p</i>-values reported as significant than in <i>p</i>-values reported as nonsignificant. This could indicate a systematic bias in favor of significant results. Possible solutions for the high prevalence of reporting inconsistencies could be to encourage sharing data, to let co-authors check results in a so-called “co-pilot model,” and to use statcheck to flag possible inconsistencies in one’s own manuscript or during the review process.</p></div></div></section>
                        
    


                        

                        

                        
                            
                                <div class="c-article-section__content"><p>Most conclusions in psychology are based on the results of null hypothesis significance testing (NHST; Cumming et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Cumming, G., Fidler, F., Leonard, M., Kalinowski, P., Christiansen, A., Kleinig, A., . . . Wilson, S. (2007). Statistical reform in psychology: Is anything changing? Psychological science, 18(3), 230–232." href="/article/10.3758/s13428-015-0664-2#ref-CR10" id="ref-link-section-d131366e351">2007</a>; Hubbard &amp; Ryan, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2000" title="Hubbard, R., &amp; Ryan, P. A. (2000). The historical growth of statistical significance testing in psychology-and its future prospects. Educational and Psychological Measurement, 60, 661–681." href="/article/10.3758/s13428-015-0664-2#ref-CR22" id="ref-link-section-d131366e354">2000</a>; Sterling, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1959" title="Sterling, T. D. (1959). Publication decisions and their possible effects on inferences drawn from tests of significance - Or vice versa. Journal of the American Statistical Association, 54, 30–34." href="/article/10.3758/s13428-015-0664-2#ref-CR32" id="ref-link-section-d131366e357">1959</a>; Sterling, Rosenbaum, &amp; Weinkam, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1995" title="Sterling, T. D., Rosenbaum, W. L., &amp; Weinkam, J. J. (1995). Publication decisions revisited - The effect of the outcome of statistical tests on the decision to publish and vice-versa. American Statistician, 49(1), 108–112." href="/article/10.3758/s13428-015-0664-2#ref-CR33" id="ref-link-section-d131366e360">1995</a>). Therefore, it is important that NHST is performed correctly and that NHST results are reported accurately. However, there is evidence that many reported <i>p</i>-values do not match their accompanying test statistic and degrees of freedom (Bakker &amp; Wicherts, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Bakker, M., &amp; Wicherts, J. M. (2011). The (mis)reporting of statistical results in psychology journals. Behavior Research Methods, 43, 666–678. doi:&#xA;                    10.3758/s13428-011-0089-5&#xA;                    &#xA;                  &#xA;                        " href="/article/10.3758/s13428-015-0664-2#ref-CR4" id="ref-link-section-d131366e367">2011</a>; Bakker &amp; Wicherts, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Bakker, M., &amp; Wicherts, J. M. (2014). Outlier removal and the relation with reporting errors and quality of research. Manuscript submitted for publication." href="/article/10.3758/s13428-015-0664-2#ref-CR5" id="ref-link-section-d131366e370">2014</a>; Berle &amp; Starcevic, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Berle, D., &amp; Starcevic, V. (2007). Inconsistencies between reported test statistics and p-values in two psychiatry journals. International Journal of Methods in Psychiatric Research, 16(4), 202–207. doi:&#xA;                    10.1002/mpr.225&#xA;                    &#xA;                  &#xA;                        " href="/article/10.3758/s13428-015-0664-2#ref-CR6" id="ref-link-section-d131366e373">2007</a>; Caperos &amp; Pardo, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Caperos, J. M., &amp; Pardo, A. (2013). Consistency errors in p-values reported in Spanish psychology journals. Psicothema, 25(3), 408–414." href="/article/10.3758/s13428-015-0664-2#ref-CR7" id="ref-link-section-d131366e376">2013</a>; Garcia-Berthou &amp; Alcaraz, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Garcia-Berthou, E., &amp; Alcaraz, C. (2004). Incongruence between test statistics and P values in medical papers. Bmc Medical Research Methodology, 4, 13. doi:&#xA;                    10.1186/1471-2288-4-13&#xA;                    &#xA;                  &#xA;                        " href="/article/10.3758/s13428-015-0664-2#ref-CR18" id="ref-link-section-d131366e379">2004</a>; Veldkamp, Nuijten, Dominguez-Alvarez, Van Assen, &amp; Wicherts, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Veldkamp, C. L. S., Nuijten, M. B., Dominguez-Alvarez, L., Van Assen, M. A. L. M., &amp; Wicherts, J. M. (2014). Statistical reporting errors and collaboration on statistical analyses in psychological science PLoS One." href="/article/10.3758/s13428-015-0664-2#ref-CR35" id="ref-link-section-d131366e382">2014</a>; Wicherts, Bakker, &amp; Molenaar, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Wicherts, J. M., Bakker, M., &amp; Molenaar, D. (2011). Willingness to share research data is related to the strength of the evidence and the quality of reporting of statistical results. PLoS One, 6(11), e26828." href="/article/10.3758/s13428-015-0664-2#ref-CR40" id="ref-link-section-d131366e386">2011</a>). These studies highlighted that roughly half of all published empirical psychology articles using NHST contained at least one inconsistent <i>p</i>-value and that around one in seven articles contained a gross inconsistency, in which the reported <i>p</i>-value was significant and the computed <i>p</i>-value was not, or vice versa.</p></div><div class="c-article-section__content"><p>This alarmingly high error rate can have large consequences. Reporting inconsistencies could affect whether an effect is perceived to be significant or not, which can influence substantive conclusions. If a result is inconsistent it is often impossible (in the absence of raw data) to determine whether the test statistic, the degrees of freedom, or the <i>p</i>-value were incorrectly reported. If the test statistic is incorrect and it is used to calculate the effect size for a meta-analysis, this effect size will be incorrect as well, which could affect the outcome of the meta-analysis (Bakker &amp; Wicherts, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Bakker, M., &amp; Wicherts, J. M. (2011). The (mis)reporting of statistical results in psychology journals. Behavior Research Methods, 43, 666–678. doi:&#xA;                    10.3758/s13428-011-0089-5&#xA;                    &#xA;                  &#xA;                        " href="/article/10.3758/s13428-015-0664-2#ref-CR4" id="ref-link-section-d131366e404">2011</a>; in fact, the misreporting of all kinds of statistics is a problem for meta-analyses; Gotzsche, Hrobjartsson, Maric, &amp; Tendal, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Gotzsche, P. C., Hrobjartsson, A., Maric, K., &amp; Tendal, B. (2007). Data extraction errors in meta-analyses that use standardized mean differences. Jama-Journal of the American Medical Association, 298(4), 430–437." href="/article/10.3758/s13428-015-0664-2#ref-CR20" id="ref-link-section-d131366e407">2007</a>; Levine &amp; Hullett, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2002" title="Levine, T. R., &amp; Hullett, C. R. (2002). Eta squared, partial eta squared, and misreporting of effect size in communication research. Human Communication Research, 28(4), 612–625. doi:&#xA;                    10.1111/j.1468-2958.2002.tb00828.x&#xA;                    &#xA;                  &#xA;                        " href="/article/10.3758/s13428-015-0664-2#ref-CR26" id="ref-link-section-d131366e410">2002</a>). Incorrect <i>p</i>-values could affect the outcome of tests that analyze the distribution of <i>p</i>-values, such as the <i>p</i>-curve (Simonsohn, Nelson, &amp; Simmons, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Simonsohn, U., Nelson, L. D., &amp; Simmons, J. P. (2014). P-curve: A key to the file-drawer. Journal of Experimental Psychology: General, 143(2), 534–547." href="/article/10.3758/s13428-015-0664-2#ref-CR31" id="ref-link-section-d131366e423">2014</a>) and <i>p</i>-uniform (Van Assen, Van Aert, &amp; Wicherts, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Van Assen, M. A. L. M., Van Aert, R. C. M., &amp; Wicherts, J. M. (2014). Meta-analysis using effect size distributions of only statistically significant studies. Psychological Methods." href="/article/10.3758/s13428-015-0664-2#ref-CR34" id="ref-link-section-d131366e429">2014</a>). Moreover, Wicherts et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Wicherts, J. M., Bakker, M., &amp; Molenaar, D. (2011). Willingness to share research data is related to the strength of the evidence and the quality of reporting of statistical results. PLoS One, 6(11), e26828." href="/article/10.3758/s13428-015-0664-2#ref-CR40" id="ref-link-section-d131366e432">2011</a>) reported that a higher prevalence of reporting errors were associated with a failure to share data upon request.</p></div><div class="c-article-section__content"><p>Even though reporting inconsistencies can be honest mistakes, they have also been categorized as one of several fairly common questionable research practices (QRPs) in psychology (John, Loewenstein, &amp; Prelec, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2012" title="John, L. K., Loewenstein, G., &amp; Prelec, D. (2012). Measuring the prevalence of questionable research practices with incentives for truth-telling. Psychological science, 23, 524–532. doi:&#xA;                    10.1177/0956797611430953&#xA;                    &#xA;                  &#xA;                        " href="/article/10.3758/s13428-015-0664-2#ref-CR23" id="ref-link-section-d131366e438">2012</a>). Interestingly, psychologists’ responses to John et al.’s survey fitted a Guttman scale reasonably well. This suggests that a psychologist’s admission to a QRP that is less often admitted to by others usually implies his or her admission to QRPs with a higher admission rate in the entire sample. Given that rounding down <i>p</i>-values close to .05 was one of the QRPs with relatively low admission rates, the frequency of misreported <i>p</i>-values could provide information on the frequency of the use of more common QRPs. The results of John et al. would therefore imply that a high prevalence of reporting errors (or more specifically, incorrect rounding down of <i>p</i>-values to be below .05) can be seen as an indicator of the use of other QRPs, such as the failure to report all dependent variables, collecting of more data after seeing whether results are significant, failing to report all conditions, and stopping data collection after achieving the desired result. Contrary to many other QRPs in John et al.’s list, misreported <i>p</i>-values that bear on significance can be readily detected on the basis of the articles’ text.</p></div><div class="c-article-section__content"><p>Previous research found a decrease in negative results (Fanelli, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2012" title="Fanelli, D. (2012). Negative results are disappearing from most disciplines and countries. Scientometrics, 90(3), 891–904. doi:&#xA;                    10.1007/s11192-011-0494-7&#xA;                    &#xA;                  &#xA;                        " href="/article/10.3758/s13428-015-0664-2#ref-CR12" id="ref-link-section-d131366e456">2012</a>) and an increase in reporting inconsistencies (Leggett, Thomas, Loetscher, &amp; Nicholls, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Leggett, N. C., Thomas, N. A., Loetscher, T., &amp; Nicholls, M. E. (2013). The life of p:“Just significant” results are on the rise. The Quarterly Journal of Experimental Psychology, 66(12), 2303–2309." href="/article/10.3758/s13428-015-0664-2#ref-CR25" id="ref-link-section-d131366e459">2013</a>), suggesting that QRPs are on the rise. On the other hand, it has been found that the number of published corrections to the literature did not change over time, suggesting no change in QRPs over time (Fanelli, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Fanelli, D. (2013). Why Growing Retractions Are (Mostly) a Good Sign. Plos Medicine, 10(12). doi: &#xA;                    10.1371/journal.pmed.1001563&#xA;                    &#xA;                  &#xA;                        " href="/article/10.3758/s13428-015-0664-2#ref-CR13" id="ref-link-section-d131366e462">2013</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Fanelli, D. (2014). Rise in retractions is a signal of integrity. Nature, 509(7498), 33–33." href="/article/10.3758/s13428-015-0664-2#ref-CR14" id="ref-link-section-d131366e465">2014</a>). Studying the prevalence of misreported <i>p</i>-values over time could shed light on possible changes in the prevalence of QRPs.</p></div><div class="c-article-section__content"><p>Besides possible changes in QRPs over time, some evidence suggests that the prevalence of QRPs may differ between subfields of psychology. Leggett et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Leggett, N. C., Thomas, N. A., Loetscher, T., &amp; Nicholls, M. E. (2013). The life of p:“Just significant” results are on the rise. The Quarterly Journal of Experimental Psychology, 66(12), 2303–2309." href="/article/10.3758/s13428-015-0664-2#ref-CR25" id="ref-link-section-d131366e474">2013</a>) recently studied reporting errors in two main psychology journals in 1965 and 2005. They found that the increase in reporting inconsistencies over the years was higher in the <i>Journal of Personality and Social Psychology</i> (JPSP), the flagship journal of social psychology, than in the <i>Journal of Experimental Psychology: General</i> (JEPG). This is in line with the finding of John et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2012" title="John, L. K., Loewenstein, G., &amp; Prelec, D. (2012). Measuring the prevalence of questionable research practices with incentives for truth-telling. Psychological science, 23, 524–532. doi:&#xA;                    10.1177/0956797611430953&#xA;                    &#xA;                  &#xA;                        " href="/article/10.3758/s13428-015-0664-2#ref-CR23" id="ref-link-section-d131366e483">2012</a>) that social psychologists admit to more QRPs, find them more applicable to their field, and find them more defensible as compared to other subgroups in psychology (but see also Fiedler &amp; Schwarz, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2015" title="Fiedler, K., &amp; Schwarz, N. (2015). Questionable Research Practices Revisited." href="/article/10.3758/s13428-015-0664-2#ref-CR16" id="ref-link-section-d131366e486">2015</a>, on this issue). However, the number of journals and test results in Leggett et al.’s study was rather limited and so it is worthwhile to consider more data before drawing conclusions with respect to differences in QRPs between subfields in psychology.</p></div><div class="c-article-section__content"><p>The current evidence for reporting inconsistencies is based on relatively small sample sizes of articles and <i>p</i>-values. The goal of our current study was to evaluate reporting errors in a large sample of more than a quarter million <i>p</i>-values retrieved from eight flagship journals covering the major subfields in psychology. Manually checking errors is time-consuming work, therefore we present and validate an automated procedure in the R package <i>statcheck</i> (Epskamp &amp; Nuijten, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2015" title="Epskamp, S., &amp; Nuijten, M. B. (2015). statcheck: Extract statistics from articles and recompute p values. R package version 1.0.1. &#xA;                    http://CRAN.R-project.org/package=statcheck&#xA;                    &#xA;                  &#xA;                        " href="/article/10.3758/s13428-015-0664-2#ref-CR11" id="ref-link-section-d131366e502">2015</a>). The validation of statcheck is described in <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.3758/s13428-015-0664-2#Sec14">Appendix A</a>.</p></div><div class="c-article-section__content"><p>We used statcheck to investigate the overall prevalence of reporting inconsistencies and compare our findings to findings in previous studies. Furthermore, we investigated whether there has been an increase in inconsistencies over the period 1985 to 2013, and, on a related note, whether there has been any increase in the number of NHST results in general and per paper. We also documented any differences in the prevalence and increase of reporting errors between journals. Specifically, we studied whether articles in social psychology contain more inconsistencies than articles in other subfields of psychology.</p></div><section aria-labelledby="Sec1"><div class="c-article-section" id="Sec1-section"><h2 class="c-article-section__title u-h2 js-section-title js-c-reading-companion-sections-item" id="Sec1">Method</h2><div class="c-article-section__content" id="Sec1-content"><h3 class="c-article__sub-heading u-h3" id="Sec2">“statcheck”</h3><p>To evaluate the prevalence of reporting errors, we used the automated procedure <i>statcheck</i> (version 1.0.1.; Epskamp &amp; Nuijten, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2015" title="Epskamp, S., &amp; Nuijten, M. B. (2015). statcheck: Extract statistics from articles and recompute p values. R package version 1.0.1. &#xA;                    http://CRAN.R-project.org/package=statcheck&#xA;                    &#xA;                  &#xA;                        " href="/article/10.3758/s13428-015-0664-2#ref-CR11" id="ref-link-section-d131366e525">2015</a>). This freely available R package (R Core Team, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="R Core Team. (2014). R: A Language and Environment for Statistical Computing. &#xA;                    http://www.R-project.org/&#xA;                    &#xA;                  &#xA;                        " href="/article/10.3758/s13428-015-0664-2#ref-CR28" id="ref-link-section-d131366e528">2014</a>) extracts statistical results and recalculates <i>p</i>-values based on reported test statistics and their degrees of freedom. Roughly, the underlying procedure executes the following four steps.</p><ul class="u-list-style-none">
                    <li>
                      <p>
                                    <i>Step 1:</i> First, statcheck converts a PDF or HTML file to a plain text file. The conversion from PDF to plain text can sometimes be problematic, because some journal publishers use images of signs such as “&lt;”, “&gt;”, or “=”, instead of the actual character. These images are not converted to the text file. HTML files do not have such problems and typically render accurate plain text files.</p>
                    </li>
                    <li>
                      <p>
                                    <i>Step 2:</i> From the plain text file, statcheck extracts <i>t</i>, <i>F</i>, <i>r</i>, χ<sup>2</sup>, and <i>Z</i> statistics, with the accompanying degrees of freedom (<i>df</i>) and <i>p</i>-value. Since statcheck is an automated procedure, it can only search for prespecified strings of text. Therefore, we chose to let statcheck search for results that are reported completely and exactly in APA style (American Psychological Association, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="American Psychological Association. (2010). Publication Manual of the American Psychological Association (6th ed.). Washington, DC: American Psychological Association." href="/article/10.3758/s13428-015-0664-2#ref-CR3" id="ref-link-section-d131366e573">2010</a>). A general example would be “<i>test statistic</i> (df1, df2) =/&lt;/&gt; …, <i>p</i> =/&lt;/&gt; …”. Two more specific examples are: “<i>t</i>(37) = −4.93, <i>p</i> &lt;.001”, “<i>χ</i>
                                    <sup>2</sup>(1, N = 226) = 6.90, <i>p</i> &lt;.01.” statcheck takes different spacing into account, and also reads results that are reported as nonsignificant (<i>ns</i>). On the other hand, it does not read results that deviate from the APA template. For instance, statcheck overlooks cases in which a result includes an effect size estimate in between the test statistic and the <i>p</i>-value (e.g., “<i>F</i>(2, 70) = 4.48, <i>MSE</i> = 6.61, <i>p</i> &lt;.02”) or when two results are combined into one sentence (e.g., “<i>F</i>(1, 15) = 19.9 and 5.16, <i>p</i> &lt;.001 and <i>p</i> &lt;.05, respectively”). These restrictions usually also imply that statcheck will not read results in tables, since these are often incompletely reported (see <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.3758/s13428-015-0664-2#Sec14">Appendix A</a> for a more detailed overview of what statcheck can and cannot read).</p>
                    </li>
                    <li>
                      <p>
                                    <i>Step 3:</i> statcheck uses the extracted test statistics and degrees of freedom to recalculate the <i>p</i>-value. By default all tests are assumed to be two-tailed. We compared <i>p</i>-values recalculated by statcheck in R version 3.1.2 and Microsoft Office Excel 2013 and found that the results of both programs were consistent up to the tenth decimal point. This indicates that underlying algorithms used to approximate the distributions are not specific to the R environment.</p>
                    </li>
                    <li>
                      <p>
                                    <i>Step 4:</i> Finally, statcheck compares the reported and recalculated <i>p</i>-value. Whenever the reported <i>p</i>-value is inconsistent with the recalculated <i>p</i>-value, the result is marked as an <i>inconsistency</i>. If the reported <i>p</i>-value is inconsistent with the recalculated <i>p</i>-value and the inconsistency changes the statistical conclusion (assuming α = .05), the result is marked as a <i>gross inconsistency</i>. To take into account one-sided tests, statcheck scans the whole text of the article for the words “one-tailed,” “one-sided,” or “directional.” If a result is initially marked as inconsistent, but the article mentions one of these words <i>and</i> the result would have been consistent if it were one-sided, then the result is marked as consistent. Note that statcheck does not take into account <i>p</i>-values that are adjusted for multiple testing (e.g., a Bonferroni correction). <i>P</i>-values adjusted for multiple comparisons that are higher than the recalculated <i>p</i>-value can therefore erroneously be marked as inconsistent. However, when we automatically searched our sample of 30,717 articles, we found that only 96 articles reported the string “Bonferroni” (0.3 %) and nine articles reported the string “Huynh-Feldt” or “Huynh Feldt” (0.03 %). We conclude from this that corrections for multiple testing are rarely used and will not significantly distort conclusions in our study.</p>
                    </li>
                  </ul>
                        <p>Similar to Bakker and Wicherts (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Bakker, M., &amp; Wicherts, J. M. (2011). The (mis)reporting of statistical results in psychology journals. Behavior Research Methods, 43, 666–678. doi:&#xA;                    10.3758/s13428-011-0089-5&#xA;                    &#xA;                  &#xA;                        " href="/article/10.3758/s13428-015-0664-2#ref-CR4" id="ref-link-section-d131366e691">2011</a>), statcheck takes numeric rounding into account. Consider the following example: <i>t</i>(28) = 2.0, <i>p</i>&lt;.05. The recalculated <i>p</i>-value that corresponds to a <i>t</i>-value of 2.0 with 28 degrees of freedom is .055, which appears to be inconsistent with the reported <i>p</i>-value of &lt;.05. However, a reported <i>t</i>-value of 2.0 could correspond to any rounded value between 1.95 and 2.05, with a corresponding range of <i>p</i>-values between .0498 and .0613, which means that the reported <i>p</i> &lt;.05 is not considered inconsistent.</p><p>Furthermore, statcheck considers <i>p</i>-values reported as <i>p</i> = .05 as significant. We inspected 10 % of the 2,473 instances in our sample in which a result was reported as “<i>p</i> = .05” and inspected whether these <i>p</i>-values were interpreted as significant. In the cases where multiple <i>p</i>-values from the same article were selected, we only included the <i>p</i>-value that was drawn first to avoid dependencies in the data. Our final sample consisted of 236 instances where “<i>p</i> = .05” was reported and of these <i>p</i>-values 94.3 % was interpreted as being significant. We therefore decided to count <i>p</i>-values reported as “<i>p</i> = .05” as indicating that the authors presented the result as significant.</p><p>The main advantage of statcheck is that it enables searching for reporting errors in very large samples, which would be infeasible by hand. Furthermore, manual checking is subject to human error, which statcheck eliminates. The disadvantage of statcheck is that it is not as comprehensive as a manual procedure, because it will miss results that deviate from standard reporting and results in tables, and it does not take into account adjustments on <i>p</i>-values. Consequently, statcheck will miss some reported results and will incorrectly earmark some correct <i>p</i>-values as a reporting error. Even though it is not feasible to create an automated procedure that is as accurate as a manual search in veryfying correctness of the results, it is important to exclude the possibility that statcheck yields a biased depiction of the true inconsistency rate. To avoid bias in the prevalence of reporting errors, we performed a validity study of statcheck, in which we compared statcheck’s results with the results of Wicherts, Bakker, and Molenaar (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Wicherts, J. M., Bakker, M., &amp; Molenaar, D. (2011). Willingness to share research data is related to the strength of the evidence and the quality of reporting of statistical results. PLoS One, 6(11), e26828." href="/article/10.3758/s13428-015-0664-2#ref-CR40" id="ref-link-section-d131366e762">2011</a>), who performed a manual search for and verification of reporting errors in a sample of 49 articles.</p><p>The validity study showed that statcheck read 67.5 % of the results that were manually extracted. Most of the results that statcheck missed were either reported with an effect size between the test statistics and the <i>p</i>-value (e.g., <i>F</i>(2, 70) = 4.48, MSE = 6.61, <i>p</i> &lt;.02; 201 instances in total) or reported in a table (150 instances in total). Furthermore, Wicherts et al. found that 49 of 1,148 <i>p</i>-values were inconsistent (4.3 %) and ten of 1,148 <i>p</i>-values were grossly inconsistent (.9 %), whereas statcheck (with automatic one-tailed test detection) found that 56 of 775 <i>p</i>-values were inconsistent (7.2 %) and eight of 775 <i>p</i>-values were grossly inconsistent (1.0 %). The higher inconsistency rate found by statcheck was mainly due to our decision to count <i>p</i> = .000 as incorrect (a <i>p</i>-value cannot exactly be zero), whereas this was counted correct by Wicherts et al. If we do not include these 11 inconsistencies due to <i>p</i> = .000, statcheck finds an inconsistency percentage of 5.8 % (45 of 775 results), 1.5 percentage points higher than in Wicherts et al. This difference was due to the fact that statcheck did not take into account 11 corrections for multiple testing and Wicherts et al. did. The inter-rater reliability in this scenario between the manual coding in Wicherts et al. and the automatic coding in statcheck was .76 for the inconsistencies and .89 for the gross inconsistencies. Since statcheck slightly overestimated the prevalence of inconsistencies in this sample of papers, we conclude that statcheck can render slightly different inconsistency rates than a search by hand. Therefore, the results of statcheck should be interpreted with care. For details of the validity study and an explanation of all discrepancies between statcheck and Wicherts et al., see <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.3758/s13428-015-0664-2#Sec14">Appendix A</a>.</p><h3 class="c-article__sub-heading u-h3 c-article__sub-heading--divider" id="Sec3">Sample</h3><p>A pilot study of social science journals in the Web of Science citation data base showed that few journals outside psychology include APA reporting style, therefore we limited our sample to psychology journals. As explained above, statcheck cannot always read results from articles in PDF due to problems in the conversion from PDF to plain text. These problems do not occur in articles in HTML format. Therefore, to obtain the most reliable statcheck results we restricted our sample to articles that were available in HTML format. The time span over which we downloaded articles depended on the year a journal started to publish articles in HTML. We collected the data in 2014, so we included articles up until 2013 to ensure complete sets of articles for an entire year. Via EBSCOhost we manually downloaded all articles in HTML from 1985 to 2013 from six flagship psychology journals that represent six main sub disciplines: <i>Journal of Applied Psychology</i> (JAP; Applied Psychology), <i>Journal of Consulting and Clinical Psychology</i> (JCCP; Clinical Psychology), <i>Developmental Psychology</i> (DP; Developmental Psychology), <i>Journal of Experimental Psychology: General</i> (JEPG; Experimental Psychology), and <i>Journal of Personality and Social Psychology</i> (JPSP; Social Psychology). These journals are published by the APA and follow the APA reporting guidelines. Furthermore, we manually downloaded all articles in HTML from two journals in general psychology: <i>Psychological Science</i> (PS; 2003–2013) and <i>Frontiers in Psychology</i> (FP; 2010–2013). In this manual download we did not include retractions, errata, and editorials. Finally, we automatically downloaded all HTML articles with the subject “psychology” from the <i>Public Library of Science</i> (PLoS; 2000–2013), using the rplos R package (Chamberlain, Boettiger, &amp; Ram, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Chamberlain, S., Boettiger, C., &amp; Ram, K. (2014). rplos: Interface to PLoS Journals search API. R package version 0.4.0. &#xA;                    http://CRAN.R-project.org/package=rplos&#xA;                    &#xA;                  &#xA;                        " href="/article/10.3758/s13428-015-0664-2#ref-CR8" id="ref-link-section-d131366e836">2014</a>).<sup><a href="#Fn1"><span class="u-visually-hidden">Footnote </span>1</a></sup> In this automatic process we did not exclude retractions, errata, or editorials. The final sample consisted of 30,717 articles. The number of downloaded articles per journal is given in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.3758/s13428-015-0664-2#Tab1">1</a>. To obtain reporting error prevalences for each subfield and for psychology in total, statcheck was used on all downloaded articles.</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-1"><figure><figcaption class="c-article-table__figcaption"><b id="Tab1" data-test="table-caption">Table 1 Specifications of the years from which HTML articles were available, the number of downloaded articles per journal, the number of articles with APA-reported null-hypothesis significance testing (NHST) results, the number of APA-reported NHST results, and the median number of APA-reported NHST results per article</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-category="article body" data-track-label="button" rel="nofollow" href="/article/10.3758/s13428-015-0664-2/tables/1"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <h3 class="c-article__sub-heading u-h3 c-article__sub-heading--divider" id="Sec4">Statistical analyses</h3><p>Our population of interest is all APA-reported NHST results in the full text of the articles from the eight selected flagship journals in psychology from 1985 until 2013. Our sample includes this entire population. We therefore made no use of inferential statistics, since inferential statistics are only necessary to draw conclusions about populations when having much smaller samples. We restricted ourselves to descriptive statistics; every documented difference or trend entails a difference between or trend in the entire population or subpopulations based on journals. For linear trends we report regression weights and percentages of variance explained to aid interpretation.</p></div></div></section><section aria-labelledby="Sec5"><div class="c-article-section" id="Sec5-section"><h2 class="c-article-section__title u-h2 js-section-title js-c-reading-companion-sections-item" id="Sec5">Results</h2><div class="c-article-section__content" id="Sec5-content"><p>We report the prevalence of reporting inconsistencies at different levels. We document general prevalence of NHST results and present percentages of articles that use NHST per journal and over the years. Because only the five APA journals provided HTMLs for all years from 1985 to 2013, the overall trends are reported for APA journals only, and do not include results from Psychological Science, PLoS, and Frontiers, which only cover recent years. Reporting inconsistencies are presented both at the level of article and at the level of the individual <i>p</i>-value, i.e., the percentage of articles with at least one inconsistency and the average percentage of <i>p</i>-values within an article that is inconsistent, respectively. We also describe differences between journals and trends over time.</p><h3 class="c-article__sub-heading u-h3" id="Sec6">Percentage of articles with null-hypothesis significance testing (NHST) results</h3><p>Overall, statcheck detected NHST results in 54.4 % of the articles, but this percentage differed per journal. The percentage of articles with at least one detected NHST result ranged from 24.1 % in PLoS to 85.1 % in JPSP (see Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.3758/s13428-015-0664-2#Tab1">1</a>). This can reflect a difference in the number of null-hypothesis significance tests performed, but it could also reflect a difference in the rigor with which the APA reporting standards are followed or how often tables are used to report results. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.3758/s13428-015-0664-2#Fig1">1</a> shows the percentage of downloaded articles that contained NHST results over the years, averaged over all APA journals (DP, JCCP, JEPG, JPSP, and JAP; dark gray panel), and split up per journal (light gray panels for the APA journals and white panels for the non-APA journals). All journals showed an increase in the percentage of articles with APA-reported NHST results over the years except for DP and FP, for which this rate remained constant and/or declined, respectively. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.3758/s13428-015-0664-2#Sec24">Appendix B</a> lists the number of articles with NSHT results over the years per journal.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-1"><figure><figcaption><b id="Fig1" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 1</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-category="article body" data-track-label="image" data-track-action="view figure" href="/article/10.3758/s13428-015-0664-2/figures/1" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.3758%2Fs13428-015-0664-2/MediaObjects/13428_2015_664_Fig1_HTML.gif?as=webp"></source><img aria-describedby="figure-1-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.3758%2Fs13428-015-0664-2/MediaObjects/13428_2015_664_Fig1_HTML.gif" alt="figure1" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-1-desc"><p>The percentage of articles with American Psychological Association (APA)-reported null-hypothesis significance testing (NHST) results over the years, averaged over all APA journals (<i>Developmental Psychology</i> (DP), <i>Journal of Consulting and Clinical Psychology</i> (JCCP), <i>Journal of Experimental Psychology: General</i> (JEPG), <i>Journal of Personality and Social Psychology</i> (JPSP), and <i>Journal of Applied Psychology</i> (JAP); dark gray panel), and split up per journal – light gray panels for the APA journals and white panels for the non-APA journals (<i>Psychological Science</i> (PS), <i>Frontiers in Psychology</i> (FP), and <i>Public Library of Science</i> (PLoS)). For each trend we report the unstandardized linear regression coefficient (b) and the coefficient of determination (R<sup>2</sup>) of the linear trend</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-category="article body" data-track-label="button" data-track-action="view figure" href="/article/10.3758/s13428-015-0664-2/figures/1" data-track-dest="link:Figure1 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <h3 class="c-article__sub-heading u-h3" id="Sec7">Number of published NHST results over the years</h3><p>We inspected the development of the average number of APA-reported NHST results per article, given that the article contained at least one detectable NHST result (see Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.3758/s13428-015-0664-2#Fig2">2</a>). Note that in 1985 the APA manual already required statistics to be reported in the manner that statcheck can read (American Psychological Association, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1983" title="American Psychological Association. (1983). Publication Manual of the American Psychological Association (3rd ed.). Washington, DC: American Psychological Association." href="/article/10.3758/s13428-015-0664-2#ref-CR2" id="ref-link-section-d131366e1421">1983</a>). Hence, any change in retrieved NHST results over time should reflect the actual change in the number of NHST results reported in articles rather than any change in the capability of statcheck to detect results.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-2"><figure><figcaption><b id="Fig2" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 2</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-category="article body" data-track-label="image" data-track-action="view figure" href="/article/10.3758/s13428-015-0664-2/figures/2" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.3758%2Fs13428-015-0664-2/MediaObjects/13428_2015_664_Fig2_HTML.gif?as=webp"></source><img aria-describedby="figure-2-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.3758%2Fs13428-015-0664-2/MediaObjects/13428_2015_664_Fig2_HTML.gif" alt="figure2" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-2-desc"><p>The average number of American Psychological Association (APA)-reported null-hypothesis significance testing (NHST) results per article that contains NHST results over the years, averaged over all APA journals (<i>Developmental Psychology</i> (DP), <i>Journal of Consulting and Clinical Psychology</i> (JCCP), <i>Journal of Experimental Psychology: General</i> (JEPG), <i>Journal of Personality and Social Psychology</i> (JPSP), and <i>Journal of Applied Psychology</i> (JAP); dark gray panel), and split up per journal (light gray panels for the APA journals and white panels for the non-APA journals – <i>Psychological Science</i> (PS), <i>Frontiers in Psychology</i> (FP), and <i>Public Library of Science</i> (PLoS)). For each trend we report the unstandardized linear regression coefficient (b) and the coefficient of determination (R<sup>2</sup>) of the linear trend</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-category="article body" data-track-label="button" data-track-action="view figure" href="/article/10.3758/s13428-015-0664-2/figures/2" data-track-dest="link:Figure2 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>Across all APA journals, the number of NHST results per article has increased over the period of 29 years (b = .25, R<sup>2</sup> = .68), with the strongest increases in JEPG and JPSP. These journals went from an average of around 10–15 NHST results per article in 1985 to as much as around 30 results per article on average in 2013. The mean number of NHST results per article remained relatively stable in DP, JCCP, and JAP; over the years, the articles with NHST results in these journals contained an average of ten NHST results. It is hard to say anything definite about trends in PS, FP, and PLOS, since we have only a limited number of years for these journals (the earliest years we have information for are 2003, 2010, and 2004, respectively). Both the increase in the percentage of articles that report NHST results and the increased number of NHST results per article show that NHST is increasingly popular in psychology. It is therefore important that the results of these tests are reported correctly.</p><h3 class="c-article__sub-heading u-h3" id="Sec8">General prevalence of inconsistencies</h3><p>Across all journals and years 49.6 % of the articles with NHST results contained at least one inconsistency (8,273 of the 16,695 articles) and 12.9 % (2,150) of the articles with NHST results contained at least one gross inconsistency. Furthermore, overall 9.7 % (24,961) of the <i>p</i>-values were inconsistent, and 1.4 % (3,581) of the <i>p</i>-values were grossly inconsistent. We also calculated the percentage of inconsistencies per article and averaged these percentages over all articles. We call this the “(gross) inconsistency rate.” Across journals, the inconsistency rate was 10.6 % and the gross inconsistency rate was 1.6 %.</p><h3 class="c-article__sub-heading u-h3" id="Sec9">Prevalence of inconsistencies per journal</h3><p>We calculated the prevalence of inconsistencies per journal at two levels. First, we calculated the percentage of articles with NHST results per journal that contained at least one (gross) inconsistency. Second, we calculated the inconsistency rate per journal. The top panel of Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.3758/s13428-015-0664-2#Fig3">3</a> shows the average percentage of articles with at least one (gross) inconsistency, per journal. The journals are ordered from the journal with the highest percentage of articles with an inconsistency to the journal with the least articles with an inconsistency. JPSP showed the highest prevalence of articles with at least one inconsistency (57.6 %), followed by JEPG (54.8 %). The journals in which the percentage of articles with an inconsistency was lowest are PS and JAP (39.7 % and 33.6 % respectively). JPSP also had the highest percentage of articles with at least one gross inconsistency (15.8 %), this time followed by DP (15.2 %). PS had the lowest percentage of articles with gross inconsistencies (6.5 %).</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-3"><figure><figcaption><b id="Fig3" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 3</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-category="article body" data-track-label="image" data-track-action="view figure" href="/article/10.3758/s13428-015-0664-2/figures/3" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.3758%2Fs13428-015-0664-2/MediaObjects/13428_2015_664_Fig3_HTML.gif?as=webp"></source><img aria-describedby="figure-3-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.3758%2Fs13428-015-0664-2/MediaObjects/13428_2015_664_Fig3_HTML.gif" alt="figure3" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-3-desc"><p>The average percentage of articles within a journal with at least one (gross) inconsistency and the average percentage of (grossly) inconsistent <i>p</i>-values per article, split up by journal. Inconsistencies are depicted in white and gross inconsistencies in grey. For the journals <i>Journal of Personality and Social Psychology</i> (JPSP), <i>Journal of Experimental Psychology: General</i> (JEPG), <i>Developmental Psychology</i> (DP), <i>Frontiers in Psychology</i> (FP), <i>Public Library of Science</i> (PLoS), <i>Journal of Consulting and Clinical Psychology</i> (JCCP), <i>Psychological Science</i> (PS), and <i>Journal of Applied Psychology</i> (JAP), respectively, the number of articles with null-hypothesis significance testing (NHST) results is 4,346, 821, 2,607, 702, 2,487, 2,413, 1,681, and 1,638, and the average number of NHST results in an article is 23.4, 23.0, 14.4, 14.5, 12.7, 11.4, 9.3, and 9.2</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-category="article body" data-track-label="button" data-track-action="view figure" href="/article/10.3758/s13428-015-0664-2/figures/3" data-track-dest="link:Figure3 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>The inconsistency rate shows a different pattern than the percentage of articles with all inconsistencies. PLoS showed the highest percentage of inconsistent <i>p</i>-values per article overall, followed by FP (14.0 % and 12.8 %, respectively). Furthermore, whereas JPSP was the journal with the highest percentage of articles with inconsistencies, it had one of the lowest probabilities that a <i>p</i>-value in an article was inconsistent (9.0 %). This discrepancy is caused by a difference between journals in the number of <i>p</i>-values per article: the articles in JPSP contain many <i>p</i>-values (see Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.3758/s13428-015-0664-2#Tab1">1</a>, right column). Hence, notwithstanding a low probability of a single <i>p</i>-value in an article being inconsistent, the probability that an article contained at least one inconsistent <i>p</i>-value was relatively high. The gross inconsistency rate was quite similar over all journals except JAP, in which the gross inconsistency rate was relatively high (2.5 %).</p><h3 class="c-article__sub-heading u-h3" id="Sec10">Prevalence of inconsistencies over the years</h3><p>If gross inconsistencies are indicative of QRPs and QRPs have increased over the years, we would expect an increase of gross inconsistencies over the years (see also Leggett et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Leggett, N. C., Thomas, N. A., Loetscher, T., &amp; Nicholls, M. E. (2013). The life of p:“Just significant” results are on the rise. The Quarterly Journal of Experimental Psychology, 66(12), 2303–2309." href="/article/10.3758/s13428-015-0664-2#ref-CR25" id="ref-link-section-d131366e1581">2013</a>). To study this, we inspected the gross inconsistency rate in journals over time. The results are shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.3758/s13428-015-0664-2#Fig4">4</a>.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-4"><figure><figcaption><b id="Fig4" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 4</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-category="article body" data-track-label="image" data-track-action="view figure" href="/article/10.3758/s13428-015-0664-2/figures/4" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.3758%2Fs13428-015-0664-2/MediaObjects/13428_2015_664_Fig4_HTML.gif?as=webp"></source><img aria-describedby="figure-4-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.3758%2Fs13428-015-0664-2/MediaObjects/13428_2015_664_Fig4_HTML.gif" alt="figure4" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-4-desc"><p>Average percentage of inconsistencies (open circles) and gross inconsistencies (solid circles) in an article over the years averaged over all American Psychological Association (APA) journals (<i>Developmental Psychology</i> (DP), <i>Journal of Consulting and Clinical Psychology</i> (JCCP), <i>Journal of Experimental Psychology: General</i> (JEPG), <i>Journal of Personality and Social Psychology</i> (JPSP), and <i>Journal of Applied Psychology</i> (JAP); dark gray panel) and split up per journal (light gray panels for the APA journals and white panels for non-APA journals – <i>Psychological Science</i> (PS), <i>Frontiers in Psychology</i> (FP), and <i>Public Library of Science</i> (PLoS)). The unstandardized regression coefficient b and the coefficient of determination R<sup>2</sup> of the linear trend are shown per journal for both inconsistencies (incons) and gross inconsistencies (gross) over the years</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-category="article body" data-track-label="button" data-track-action="view figure" href="/article/10.3758/s13428-015-0664-2/figures/4" data-track-dest="link:Figure4 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>The number of (gross) inconstencies has decreased or remained stable over the years across the APA journals. In DP, JCCP, JPEG, and JPSP the percentage of all inconsistencies in an article has decreased over the years. For JAP there is a positive (but very small) regression coefficient for year, indicating an increasing error rate, but the R<sup>2</sup> is close to zero. The same pattern held for the prevalence of gross inconsistencies over the years. DP, JCCP, and JPSP have shown a decrease in gross inconsistencies, in JEPG and JAP the R<sup>2</sup> is very small, and the prevalence seems to have remained practically stable. The trends for PS, FP, and PLoS are hard to interpret given the limited number of years of covarage. Overall, it seems that, contrary to the evidence suggesting that the use of QRPs could be on the rise (Fanelli, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2012" title="Fanelli, D. (2012). Negative results are disappearing from most disciplines and countries. Scientometrics, 90(3), 891–904. doi:&#xA;                    10.1007/s11192-011-0494-7&#xA;                    &#xA;                  &#xA;                        " href="/article/10.3758/s13428-015-0664-2#ref-CR12" id="ref-link-section-d131366e1640">2012</a>; Leggett et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Leggett, N. C., Thomas, N. A., Loetscher, T., &amp; Nicholls, M. E. (2013). The life of p:“Just significant” results are on the rise. The Quarterly Journal of Experimental Psychology, 66(12), 2303–2309." href="/article/10.3758/s13428-015-0664-2#ref-CR25" id="ref-link-section-d131366e1643">2013</a>), neither the inconsistencies nor the gross inconsistencies have shown an increase over time. If anything, the current results reflect a decrease of reporting error prevalences over the years.</p><p>We also looked at the development of inconsistencies at the article level. More specifically, we looked at the percentage of articles with at least one inconsistency over the years, averaged over all APA journals (DP, JCCP, JEPG, JPSP, and JAP; dark gray panel in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.3758/s13428-015-0664-2#Fig5">5</a>) and split up per journal (light gray panels for the APA journals and white panels for the non-APA journals in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.3758/s13428-015-0664-2#Fig5">5</a>). Results show that there has been an increase in JEPG and JPSP for the percentage of articles with NHST results that have at least one inconsistency, which is again associated with the increase in the number of NHST results per article in these journals (see Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.3758/s13428-015-0664-2#Fig2">2</a>). In DP and JCCP, there was a decrease in articles with an inconsistency. For JAP there is no clear trend; the R<sup>2</sup> is close to zero. A more general trend is evident in the prevalence of articles with gross inconsistencies: in all journals, except PS and PLOS, the percentage of articles with NHST that contain at least one gross inconsistency has been decreasing. Note that the trends for PS, FP, and PLOS are unstable due to the limited number of years we have data for. Overall, it seems that, even though the prevalence of articles with inconsistencies has increased in some journals, the prevalence of articles with gross inconsistencies has shown a decline over the studied period.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-5"><figure><figcaption><b id="Fig5" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 5</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-category="article body" data-track-label="image" data-track-action="view figure" href="/article/10.3758/s13428-015-0664-2/figures/5" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.3758%2Fs13428-015-0664-2/MediaObjects/13428_2015_664_Fig5_HTML.gif?as=webp"></source><img aria-describedby="figure-5-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.3758%2Fs13428-015-0664-2/MediaObjects/13428_2015_664_Fig5_HTML.gif" alt="figure5" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-5-desc"><p>Percentage of articles with at least one inconsistency (open circles) or at least one gross inconsistency (solid circles), split up by journal. The unstandardized regression coefficient b and the coefficient of determination R<sup>2</sup> of the linear trend are shown per journal for both inconsistencies (incons) as gross inconsistencies (gross) over the years. <i>APA</i> American Psychological Assocation, <i>DP</i> Developmental Psychology, <i>JCCP</i> Journal of Consulting and Clinical Psychology, JEPG Journal of Experimental Psychology: General , <i>JPSP</i> Journal of Personality and Social Psychology, <i>JAP</i> Journal of Applied Psychology, <i>PS</i> Psychological Science, <i>FP</i> Frontiers in Psychology, <i>PLoS</i> Public Library of Science</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-category="article body" data-track-label="button" data-track-action="view figure" href="/article/10.3758/s13428-015-0664-2/figures/5" data-track-dest="link:Figure5 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <h3 class="c-article__sub-heading u-h3" id="Sec11">Prevalence of gross inconsistencies in results reported as significant and nonsignificant</h3><p>We inspected the gross inconsistencies in more detail by comparing the percentage of gross inconsistencies in <i>p</i>-values reported as significant and <i>p</i>-values reported as nonsignificant. Of all <i>p</i>-values reported as significant 1.56 % was grossly inconsistent, whereas only .97 % of all <i>p</i>-values reported as nonsignificant was grossly inconsistent, indicating it is more likely for a <i>p</i>-value reported as significant to be a gross inconsistency than for a <i>p</i>-value reported as nonsignificant. We also inspected the prevalence of gross inconsistencies in significant and non-significant <i>p</i>-values per journal (see Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.3758/s13428-015-0664-2#Fig6">6</a>). In all journals, the prevalence of gross inconsistencies is higher in significant <i>p</i>-values than in nonsignificant <i>p</i>-values (except for FP, in which the prevalence is equal in the two types of <i>p</i>-values). This difference in prevalence is highest in JCCP (1.03 percentage point), JAP (.97 percentage point), and JPSP (.83 percentage point) respectively, followed by JEPG (.51 percentage point) and DP (.26 percentage point), and smallest in PLOS (.19 percentage point) and FP (.00 percentage point).</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-6"><figure><figcaption><b id="Fig6" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 6</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-category="article body" data-track-label="image" data-track-action="view figure" href="/article/10.3758/s13428-015-0664-2/figures/6" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.3758%2Fs13428-015-0664-2/MediaObjects/13428_2015_664_Fig6_HTML.gif?as=webp"></source><img aria-describedby="figure-6-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.3758%2Fs13428-015-0664-2/MediaObjects/13428_2015_664_Fig6_HTML.gif" alt="figure6" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-6-desc"><p>The percentage of gross inconsistencies in <i>p</i>-values reported as significant (white bars) and nonsignificant (gray bars), split up by journal. For the journals <i>Journal of Applied Psychology</i> (JAP), <i>Journal of Consulting and Clinical Psychology</i> (JCCP), <i>Developmental Psychology</i> (DP), <i>Public Library of Science</i> (PLoS), <i>Psychological Science</i> (PS), <i>Frontiers in Psychology</i> (FP), <i>Journal of Personality and Social Psychology</i> (JPSP), and <i>Journal of Experimental Psychology: General</i> (JEPG), respectively, the total number of significant <i>p</i>-values was 11,654, 21,120, 29,962, 22,071, 12,482, 7,377, 78,889, and 14,084, and the total number of nonsignificant <i>p</i>-values was 3,119, 5,558, 6,698, 9,134, 2,936, 2,712, 17,868, and 4,407</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-category="article body" data-track-label="button" data-track-action="view figure" href="/article/10.3758/s13428-015-0664-2/figures/6" data-track-dest="link:Figure6 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>It is hard to interpret the percentages of inconsistencies in significant and nonsignificant <i>p</i>-values substantively, since they depend on several factors, such as the specific <i>p</i>-value: it seems more likely that a <i>p</i>-value of .06 is reported as smaller than .05 than a <i>p</i>-value of .78. That is, because journals may differ in the distribution of specific <i>p</i>-values we should also be careful in comparing gross inconsistencies in <i>p</i>-values reported as significant across journals. Furthermore, without the raw data it is impossible to determine whether it is the <i>p</i>-value that is erroneous, or the test statistic or degrees of freedom. As an example of the latter case, a simple typographical error such as “<i>F</i>(2,56) = 1.203, <i>p</i> &lt; .001” instead of “<i>F</i>(2,56) = 12.03, <i>p</i> &lt; .001” produces a gross inconsistency, without the <i>p</i>-value being incorrect. Although we cannot interpret the absolute percentages and their differences, the finding that gross inconsistencies are more likely in <i>p</i>-values presented as significant than in <i>p</i>-values presented as nonsignificant could indicate a systematic bias and is reason for concern.</p><p>Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.3758/s13428-015-0664-2#Fig7">7</a> shows the prevalence of gross inconsistencies in significant (solid line) and nonsignificant (dotted line) <i>p</i>-values over time, averaged over all journals. The size of the circles represents the total number of significant (open circle) and nonsignificant (solid circle) <i>p</i>-values in that particular year. Note that we only have information for PS, FP, and PLOS since 2003, 2010, and 2004, respectively. The prevalence of gross inconsistencies in significant <i>p</i>-values seems to decline slightly over the years (<i>b</i> = −.04, R<sup>2</sup> = .65). The prevalence of the gross inconsistencies in nonsignificant <i>p</i>-values does not show any change (<i>b</i> = .00, R<sup>2</sup> = .00). In short, the potential systematic bias leading to more gross inconsistencies in significant results seems to be present in all journals except for FP, but there is no evidence that this bias is increasing over the years.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-7"><figure><figcaption><b id="Fig7" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 7</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-category="article body" data-track-label="image" data-track-action="view figure" href="/article/10.3758/s13428-015-0664-2/figures/7" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.3758%2Fs13428-015-0664-2/MediaObjects/13428_2015_664_Fig7_HTML.gif?as=webp"></source><img aria-describedby="figure-7-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.3758%2Fs13428-015-0664-2/MediaObjects/13428_2015_664_Fig7_HTML.gif" alt="figure7" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-7-desc"><p>The percentage of gross inconsistencies in <i>p</i>-values reported as significant (solid line) and nonsignificant (dotted line), over the years, averaged over journals. The size of the open and solid circles represents the number of significant and nonsignificant <i>p</i>-values in that year, respectively</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-category="article body" data-track-label="button" data-track-action="view figure" href="/article/10.3758/s13428-015-0664-2/figures/7" data-track-dest="link:Figure7 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>To investigate the consequence of these gross inconsistencies, we compared the percentage of significant results in the reported <i>p</i>-values with the percentage of significant results in the computed <i>p</i>-values. Averaged over all journals and years, 76.6 % of all reported <i>p</i>-values were significant. However, only 74.4 % of all computed <i>p</i>-values were significant, which means that the percentage of significant findings in the investigated literature is overestimated by 2.2 percentage points due to gross inconsistencies.</p><h3 class="c-article__sub-heading u-h3" id="Sec12">Prevalence of inconsistencies as found by other studies</h3><p>Our study can be considered a large replication of several previous studies (Bakker &amp; Wicherts, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Bakker, M., &amp; Wicherts, J. M. (2011). The (mis)reporting of statistical results in psychology journals. Behavior Research Methods, 43, 666–678. doi:&#xA;                    10.3758/s13428-011-0089-5&#xA;                    &#xA;                  &#xA;                        " href="/article/10.3758/s13428-015-0664-2#ref-CR4" id="ref-link-section-d131366e1926">2011</a>; Bakker &amp; Wicherts, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Bakker, M., &amp; Wicherts, J. M. (2014). Outlier removal and the relation with reporting errors and quality of research. Manuscript submitted for publication." href="/article/10.3758/s13428-015-0664-2#ref-CR5" id="ref-link-section-d131366e1929">2014</a>; Berle &amp; Starcevic, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Berle, D., &amp; Starcevic, V. (2007). Inconsistencies between reported test statistics and p-values in two psychiatry journals. International Journal of Methods in Psychiatric Research, 16(4), 202–207. doi:&#xA;                    10.1002/mpr.225&#xA;                    &#xA;                  &#xA;                        " href="/article/10.3758/s13428-015-0664-2#ref-CR6" id="ref-link-section-d131366e1932">2007</a>; Caperos &amp; Pardo, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Caperos, J. M., &amp; Pardo, A. (2013). Consistency errors in p-values reported in Spanish psychology journals. Psicothema, 25(3), 408–414." href="/article/10.3758/s13428-015-0664-2#ref-CR7" id="ref-link-section-d131366e1935">2013</a>; Garcia-Berthou &amp; Alcaraz, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Garcia-Berthou, E., &amp; Alcaraz, C. (2004). Incongruence between test statistics and P values in medical papers. Bmc Medical Research Methodology, 4, 13. doi:&#xA;                    10.1186/1471-2288-4-13&#xA;                    &#xA;                  &#xA;                        " href="/article/10.3758/s13428-015-0664-2#ref-CR18" id="ref-link-section-d131366e1938">2004</a>; Veldkamp et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Veldkamp, C. L. S., Nuijten, M. B., Dominguez-Alvarez, L., Van Assen, M. A. L. M., &amp; Wicherts, J. M. (2014). Statistical reporting errors and collaboration on statistical analyses in psychological science PLoS One." href="/article/10.3758/s13428-015-0664-2#ref-CR35" id="ref-link-section-d131366e1942">2014</a>; Wicherts et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Wicherts, J. M., Bakker, M., &amp; Molenaar, D. (2011). Willingness to share research data is related to the strength of the evidence and the quality of reporting of statistical results. PLoS One, 6(11), e26828." href="/article/10.3758/s13428-015-0664-2#ref-CR40" id="ref-link-section-d131366e1945">2011</a>). Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.3758/s13428-015-0664-2#Tab2">2</a> shows the prevalence of inconsistent <i>p</i>-values as determined by our study and previous studies.</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-2"><figure><figcaption class="c-article-table__figcaption"><b id="Tab2" data-test="table-caption">Table 2 Prevalence of inconsistencies in the current study and in earlier studies</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-category="article body" data-track-label="button" rel="nofollow" href="/article/10.3758/s13428-015-0664-2/tables/2"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                        <p>Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.3758/s13428-015-0664-2#Tab2">2</a> shows that the estimated percentage of inconsistent results can vary considerably between studies, ranging from 4.3 % of the results (Wicherts et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Wicherts, J. M., Bakker, M., &amp; Molenaar, D. (2011). Willingness to share research data is related to the strength of the evidence and the quality of reporting of statistical results. PLoS One, 6(11), e26828." href="/article/10.3758/s13428-015-0664-2#ref-CR40" id="ref-link-section-d131366e2521">2011</a>) to 14.3 % of the results (Berle &amp; Starcevic, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Berle, D., &amp; Starcevic, V. (2007). Inconsistencies between reported test statistics and p-values in two psychiatry journals. International Journal of Methods in Psychiatric Research, 16(4), 202–207. doi:&#xA;                    10.1002/mpr.225&#xA;                    &#xA;                  &#xA;                        " href="/article/10.3758/s13428-015-0664-2#ref-CR6" id="ref-link-section-d131366e2524">2007</a>). The median rate of inconsistent results is 11.1 % (1.4 percentage points higher than the 9.7 % in the current study). The percentage of gross inconsistencies ranged from .4 % (Garcia-Berthou &amp; Alcaraz, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Garcia-Berthou, E., &amp; Alcaraz, C. (2004). Incongruence between test statistics and P values in medical papers. Bmc Medical Research Methodology, 4, 13. doi:&#xA;                    10.1186/1471-2288-4-13&#xA;                    &#xA;                  &#xA;                        " href="/article/10.3758/s13428-015-0664-2#ref-CR18" id="ref-link-section-d131366e2527">2004</a>) to 2.3 % (Caperos &amp; Pardo, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Caperos, J. M., &amp; Pardo, A. (2013). Consistency errors in p-values reported in Spanish psychology journals. Psicothema, 25(3), 408–414." href="/article/10.3758/s13428-015-0664-2#ref-CR7" id="ref-link-section-d131366e2530">2013</a>), with a median of 1.1 % (.3 percentage points lower than the 1.4 % found in the current study). The percentage of articles with at least one inconsistency ranged from as low as 10.1 % (Berle &amp; Starcevic, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Berle, D., &amp; Starcevic, V. (2007). Inconsistencies between reported test statistics and p-values in two psychiatry journals. International Journal of Methods in Psychiatric Research, 16(4), 202–207. doi:&#xA;                    10.1002/mpr.225&#xA;                    &#xA;                  &#xA;                        " href="/article/10.3758/s13428-015-0664-2#ref-CR6" id="ref-link-section-d131366e2534">2007</a>) to as high as 63.0 % (Veldkamp et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Veldkamp, C. L. S., Nuijten, M. B., Dominguez-Alvarez, L., Van Assen, M. A. L. M., &amp; Wicherts, J. M. (2014). Statistical reporting errors and collaboration on statistical analyses in psychological science PLoS One." href="/article/10.3758/s13428-015-0664-2#ref-CR35" id="ref-link-section-d131366e2537">2014</a>), with a median of 46.7 % (2.9 percentage points lower than the estimated 49.6 % in the current study). Finally, the lowest percentage of articles with at least one gross inconsistency is 2.6 % (Berle &amp; Starcevic, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Berle, D., &amp; Starcevic, V. (2007). Inconsistencies between reported test statistics and p-values in two psychiatry journals. International Journal of Methods in Psychiatric Research, 16(4), 202–207. doi:&#xA;                    10.1002/mpr.225&#xA;                    &#xA;                  &#xA;                        " href="/article/10.3758/s13428-015-0664-2#ref-CR6" id="ref-link-section-d131366e2540">2007</a>) and the highest is 20.5 % (Veldkamp et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Veldkamp, C. L. S., Nuijten, M. B., Dominguez-Alvarez, L., Van Assen, M. A. L. M., &amp; Wicherts, J. M. (2014). Statistical reporting errors and collaboration on statistical analyses in psychological science PLoS One." href="/article/10.3758/s13428-015-0664-2#ref-CR35" id="ref-link-section-d131366e2543">2014</a>), with a median of 14.3 % (1.4 percentage points higher than the 12.9 % found in the current study).</p><p>Some of the differences in prevalences could be caused by differences in inclusion criteria. For instance, Bakker and Wicherts (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Bakker, M., &amp; Wicherts, J. M. (2011). The (mis)reporting of statistical results in psychology journals. Behavior Research Methods, 43, 666–678. doi:&#xA;                    10.3758/s13428-011-0089-5&#xA;                    &#xA;                  &#xA;                        " href="/article/10.3758/s13428-015-0664-2#ref-CR4" id="ref-link-section-d131366e2549">2011</a>) included only <i>t</i>, <i>F</i>, and <i>χ</i>
                           <sup><i>2</i></sup> values; Wicherts et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Wicherts, J. M., Bakker, M., &amp; Molenaar, D. (2011). Willingness to share research data is related to the strength of the evidence and the quality of reporting of statistical results. PLoS One, 6(11), e26828." href="/article/10.3758/s13428-015-0664-2#ref-CR40" id="ref-link-section-d131366e2566">2011</a>) included only <i>t</i>, <i>F</i>, and <i>χ</i>
                           <sup><i>2</i></sup> values of which the reported <i>p</i>-value was smaller than .05; Berle and Starcevic (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Berle, D., &amp; Starcevic, V. (2007). Inconsistencies between reported test statistics and p-values in two psychiatry journals. International Journal of Methods in Psychiatric Research, 16(4), 202–207. doi:&#xA;                    10.1002/mpr.225&#xA;                    &#xA;                  &#xA;                        " href="/article/10.3758/s13428-015-0664-2#ref-CR6" id="ref-link-section-d131366e2586">2007</a>) included only exactly reported <i>p</i>-values; Bakker and Wicherts (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Bakker, M., &amp; Wicherts, J. M. (2014). Outlier removal and the relation with reporting errors and quality of research. Manuscript submitted for publication." href="/article/10.3758/s13428-015-0664-2#ref-CR5" id="ref-link-section-d131366e2592">2014</a>) only included completely reported <i>t</i> and <i>F</i> values. Furthermore, two studies evaluated <i>p</i>-values in the medical field (Garcia-Berthou &amp; Alcaraz, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Garcia-Berthou, E., &amp; Alcaraz, C. (2004). Incongruence between test statistics and P values in medical papers. Bmc Medical Research Methodology, 4, 13. doi:&#xA;                    10.1186/1471-2288-4-13&#xA;                    &#xA;                  &#xA;                        " href="/article/10.3758/s13428-015-0664-2#ref-CR18" id="ref-link-section-d131366e2605">2004</a>) and in psychiatry (Berle &amp; Starcevic, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Berle, D., &amp; Starcevic, V. (2007). Inconsistencies between reported test statistics and p-values in two psychiatry journals. International Journal of Methods in Psychiatric Research, 16(4), 202–207. doi:&#xA;                    10.1002/mpr.225&#xA;                    &#xA;                  &#xA;                        " href="/article/10.3758/s13428-015-0664-2#ref-CR6" id="ref-link-section-d131366e2608">2007</a>) instead of in psychology. Lastly, there can be differences in which <i>p</i>-values are counted as inconsistent. For instance, the current study counts <i>p</i> = .000 as incorrect, whereas this was not the case in for example Wicherts et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Wicherts, J. M., Bakker, M., &amp; Molenaar, D. (2011). Willingness to share research data is related to the strength of the evidence and the quality of reporting of statistical results. PLoS One, 6(11), e26828." href="/article/10.3758/s13428-015-0664-2#ref-CR40" id="ref-link-section-d131366e2617">2011</a>; see also <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.3758/s13428-015-0664-2#Sec14">Appendix A</a>).</p><p>Based on Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.3758/s13428-015-0664-2#Tab2">2</a> we conclude that our study corroborates earlier findings. The prevalence of reporting inconsistencies is high: almost all studies find that roughly one in ten results is erroneously reported. Even though the percentage of results that is grossly inconsistent is lower, the studies show that a substantial percentage of published articles contain at least one gross inconsistency, which is reason for concern.</p></div></div></section><section aria-labelledby="Sec13"><div class="c-article-section" id="Sec13-section"><h2 class="c-article-section__title u-h2 js-section-title js-c-reading-companion-sections-item" id="Sec13">Discussion</h2><div class="c-article-section__content" id="Sec13-content"><p>In this paper we investigated the prevalence of reporting errors in eight major journals in psychology using the automated R package statcheck (Epskamp &amp; Nuijten, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2015" title="Epskamp, S., &amp; Nuijten, M. B. (2015). statcheck: Extract statistics from articles and recompute p values. R package version 1.0.1. &#xA;                    http://CRAN.R-project.org/package=statcheck&#xA;                    &#xA;                  &#xA;                        " href="/article/10.3758/s13428-015-0664-2#ref-CR11" id="ref-link-section-d131366e2638">2015</a>). Over half of the articles in the six flagship journals reported NHST results that statcheck was able to retrieve. Notwithstanding the many debates on the downsides of NHST (see e.g., Fidler &amp; Cumming, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Fidler, F., &amp; Cumming, G. (2005). Teaching confidence intervals: Problems and potential solutions. Proceedings of the 55th International Statistics Institute Session." href="/article/10.3758/s13428-015-0664-2#ref-CR15" id="ref-link-section-d131366e2641">2005</a>; Wagenmakers, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Wagenmakers, E. J. (2007). A practical solution to the pervasive problems of p values. Psychonomic Bulletin &amp; Review, 14, 779–804. doi:&#xA;                    10.3758/BF03194105&#xA;                    &#xA;                  &#xA;                        " href="/article/10.3758/s13428-015-0664-2#ref-CR36" id="ref-link-section-d131366e2644">2007</a>), the use of NHST in psychology appears to have increased from 1985 to 2013 (see Figs. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.3758/s13428-015-0664-2#Fig1">1</a> and <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.3758/s13428-015-0664-2#Fig2">2</a>), although this increase can also reflect an increase in adherence to APA reporting standards. Our findings show that in general the prevalence of reporting inconsistencies in six flagship psychology journals is substantial. Roughly half of all articles with NHST results contained at least one inconsistency and about 13 % contained a gross inconsistency that may have affected the statistical conclusion. At the level of individual <i>p</i>-values we found that on average 10.6 % of the <i>p</i>-values in an article were inconsistent, whereas 1.6 % of the <i>p</i>-values were grossly inconsistent.</p><p>Contrary to what one would expect based on the suggestion that QRPs have been on the rise (Leggett et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Leggett, N. C., Thomas, N. A., Loetscher, T., &amp; Nicholls, M. E. (2013). The life of p:“Just significant” results are on the rise. The Quarterly Journal of Experimental Psychology, 66(12), 2303–2309." href="/article/10.3758/s13428-015-0664-2#ref-CR25" id="ref-link-section-d131366e2666">2013</a>), we found no general increase in the prevalence of inconsistent <i>p</i>-values in the studied journals from 1985 to 2013. When focusing on inconsistencies at the article level, we only found an increase in the percentage of articles with NHST results that showed at least one inconsistency for JEPG and JPSP. Note this was associated with clear increases in the number of reported NHST results per article in these journals. Furthermore, we did not find an increase in gross inconsistencies in any of the journals. If anything, we saw that the prevalence of articles with gross inconsistencies has been decreasing since 1985, albeit only slightly. We also found no increase in the prevalence of gross inconsistencies in <i>p</i>-values that were reported as significant as compared to gross inconsistencies in <i>p</i>-values reported as nonsignificant. This is at odds with the notion that QRPs in general and reporting errors in particular have been increasing in the last decades. On the other hand, the stability or decrease in reporting errors is in line with research showing no trend in the proportion of published errata, which implies that there is also no trend in the proportion of articles with (reporting) errors (Fanelli, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Fanelli, D. (2013). Why Growing Retractions Are (Mostly) a Good Sign. Plos Medicine, 10(12). doi: &#xA;                    10.1371/journal.pmed.1001563&#xA;                    &#xA;                  &#xA;                        " href="/article/10.3758/s13428-015-0664-2#ref-CR13" id="ref-link-section-d131366e2678">2013</a>).</p><p>Furthermore, we found no evidence that inconsistencies are more prevalent in JPSP than in other journals. The (gross) inconsistency rate was not the highest in JPSP. The prevalence of (gross) inconsistencies has been declining in JPSP, as it did in other journals. We did find that JPSP showed a higher prevalence of articles with at least one inconsistency than other journals, but this was associated with the higher number of NSHT results per article in JPSP. Hence our findings are not in line with the previous findings that JPSP shows a higher (increase in) inconsistency rate (Leggett et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Leggett, N. C., Thomas, N. A., Loetscher, T., &amp; Nicholls, M. E. (2013). The life of p:“Just significant” results are on the rise. The Quarterly Journal of Experimental Psychology, 66(12), 2303–2309." href="/article/10.3758/s13428-015-0664-2#ref-CR25" id="ref-link-section-d131366e2684">2013</a>). Since statcheck cannot distinguish between <i>p</i>-values pertaining to core hypotheses and <i>p</i>-values pertaining to, for example, manipulation checks, it is hard to interpret the differences in inconsistencies between fields and the implications of these differences. To warrant such a conclusion the inconsistencies would have to be manually analyzed within the context of the papers containing the inconsistencies.</p><p>We also found that gross inconsistencies are more prevalent in <i>p</i>-values reported as significant than in <i>p</i>-values reported as nonsignificant. This could suggest a systematic bias favoring significant results, potentially leading to an excess of false positives in the literature. The higher prevalence of gross inconsistencies in significant <i>p</i>-values versus nonsignificant <i>p</i>-values was highest in JCCP, JAP, and JPSP, and lowest in PLOS and FP. Note again that we do not know the hypotheses underlying these <i>p</i>-values. It is possible that in some cases a nonsignificant <i>p</i>-value would be in line with a hypothesis and thus in line with the researcher’s predictions. Our data do not speak to the causes of this over-representation of significant results. Perhaps these <i>p</i>-values are intentionally rounded down (a practice that 20 % of the surveyed psychological researchers admitted to; John et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2012" title="John, L. K., Loewenstein, G., &amp; Prelec, D. (2012). Measuring the prevalence of questionable research practices with incentives for truth-telling. Psychological science, 23, 524–532. doi:&#xA;                    10.1177/0956797611430953&#xA;                    &#xA;                  &#xA;                        " href="/article/10.3758/s13428-015-0664-2#ref-CR23" id="ref-link-section-d131366e2718">2012</a>) to convince the reviewers and other readers of an effect. Or perhaps researchers fail to double check significantly reported <i>p</i>-values, because they are in line with their expectations, hence leaving such reporting errors more likely to remain undetected. It is also possible that the cause of the over-representation of falsely significant results lies with publication bias: perhaps researchers report significant <i>p</i>-values as nonsignificant just as often as vice versa, but in the process of publication, only the (accidentally) significant <i>p</i>-values get published.</p><p>There are two main limitations in our study. Firstly, by using the automated procedure statcheck to detect reporting inconsistencies, our sample did not include NHST results that were not reported exactly according to APA format or results reported in tables. However, based on the validity study and on earlier results (Bakker &amp; Wicherts, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Bakker, M., &amp; Wicherts, J. M. (2011). The (mis)reporting of statistical results in psychology journals. Behavior Research Methods, 43, 666–678. doi:&#xA;                    10.3758/s13428-011-0089-5&#xA;                    &#xA;                  &#xA;                        " href="/article/10.3758/s13428-015-0664-2#ref-CR4" id="ref-link-section-d131366e2734">2011</a>), we conclude that there does not seem to be a difference in the prevalence of reporting inconsistencies between results in APA format and results that are not exactly in APA format (see <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.3758/s13428-015-0664-2#Sec14">Appendix A</a>). The validity study did suggest, however, that statcheck might slightly overestimate the number of inconsistencies. One reason could be that statcheck cannot correctly evaluate <i>p</i>-values that were adjusted for multiple testing. However, we found that these adjustments are rarely used. Notably, the term “Bonferroni” was mentioned in a meager 0.3 % of the 30,717 papers. This finding is interesting in itself; with a median number of 11 NHST results per paper, most papers report multiple <i>p</i>-values. Without any correction for multiple testing, this suggests that overall Type I error rates in the eight psychology journals are already higher than the nominal level of .05. Nevertheless, the effect of adjustments of <i>p</i>-values on the error estimates from statcheck is expected to be small. We therefore conclude that, as long as the results are interpreted with care, statcheck provides a good method to analyze vast amounts of literature to locate reporting inconsistencies. Future developments of statcheck could focus on taking into account corrections for multiple testing and results reported in tables or with effect sizes reported between the test statistic and <i>p</i>-value.</p><p>The second limitation of our study is that we chose to limit our sample to only a selection of flagship journals from several sub disciplines of psychology. It is possible that the prevalence of inconsistencies in these journals is not representative for the psychological literature. For instance, it has been found that journals with lower impact factors have a higher prevalence of reporting inconsistencies than high impact journals (Bakker &amp; Wicherts, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Bakker, M., &amp; Wicherts, J. M. (2011). The (mis)reporting of statistical results in psychology journals. Behavior Research Methods, 43, 666–678. doi:&#xA;                    10.3758/s13428-011-0089-5&#xA;                    &#xA;                  &#xA;                        " href="/article/10.3758/s13428-015-0664-2#ref-CR4" id="ref-link-section-d131366e2756">2011</a>). In this study we avoid conclusions about psychology in general, but treat the APA-reported NHST results in the full text of the articles from journals we selected as the population of interest (which made statistical inference superfluous). All conclusions in this paper therefore hold for the APA-reported NHST results in the eight selected journals. Nevertheless, the relatively high impact factors of these journals attest to the relevance of the current study.</p><p>There are several possible solutions to the problem of reporting inconsistencies. Firstly, researchers can check their own papers before submitting, either by hand or with the R package statcheck. Editors and reviewers could also make use of statcheck to quickly flag possible reporting inconsistencies in a submission, after which the flagged results can be checked by hand. This should reduce erroneous conclusions caused by gross inconsistencies. Checking articles with statcheck can also prevent such inconsistencies from distorting meta-analyses or analyses of <i>p</i>-value distributions (Simonsohn et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Simonsohn, U., Nelson, L. D., &amp; Simmons, J. P. (2014). P-curve: A key to the file-drawer. Journal of Experimental Psychology: General, 143(2), 534–547." href="/article/10.3758/s13428-015-0664-2#ref-CR31" id="ref-link-section-d131366e2765">2014</a>; Van Assen et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Van Assen, M. A. L. M., Van Aert, R. C. M., &amp; Wicherts, J. M. (2014). Meta-analysis using effect size distributions of only statistically significant studies. Psychological Methods." href="/article/10.3758/s13428-015-0664-2#ref-CR34" id="ref-link-section-d131366e2768">2014</a>). This solution would be in line with the notion of Analytic Review (Sakaluk, Williams, &amp; Biernat, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Sakaluk, J., Williams, A., &amp; Biernat, M. (2014). Analytic Review as a Solution to the Misreporting of Statistical Results in Psychological Science. Perspectives on Psychological Science, 9(6), 652–660." href="/article/10.3758/s13428-015-0664-2#ref-CR30" id="ref-link-section-d131366e2771">2014</a>), in which a reviewer receives the data file and syntax of a manuscript to check if the reported analyses were actually conducted and reported correctly. One of the main concerns about Analytic Review is that it would take reviewers a lot of additional work. The use of statcheck in Analytic Review could reduce this workload substantially.</p><p>Secondly, the prevalence of inconsistencies might decrease if co-authors check each other’s work, a so-called “co-pilot model” (Wicherts, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Wicherts, J. M. (2011). Psychology must learn a lesson from fraud case. Nature, 480, 7. doi:&#xA;                    10.1038/480007a&#xA;                    &#xA;                  &#xA;                        " href="/article/10.3758/s13428-015-0664-2#ref-CR37" id="ref-link-section-d131366e2777">2011</a>). In recent research (Veldkamp et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Veldkamp, C. L. S., Nuijten, M. B., Dominguez-Alvarez, L., Van Assen, M. A. L. M., &amp; Wicherts, J. M. (2014). Statistical reporting errors and collaboration on statistical analyses in psychological science PLoS One." href="/article/10.3758/s13428-015-0664-2#ref-CR35" id="ref-link-section-d131366e2780">2014</a>) this idea has been investigated by relating the probability that a <i>p</i>-value was inconsistent to six different co-piloting activities (e.g., multiple authors conducting the statistical analyses). Veldkamp et al. did not find direct evidence for a relation between co-piloting and reduced prevalence of reporting errors. However, the investigated co-pilot activities did not explicitly include the actual checking of each other’s <i>p</i>-values, hence we do not rule out the possibility that reporting errors would decrease if co-authors double checked <i>p</i>-values.</p><p>Thirdly, it has been found that reporting errors are related to reluctance to share data (Wicherts et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Wicherts, J. M., Bakker, M., &amp; Molenaar, D. (2011). Willingness to share research data is related to the strength of the evidence and the quality of reporting of statistical results. PLoS One, 6(11), e26828." href="/article/10.3758/s13428-015-0664-2#ref-CR40" id="ref-link-section-d131366e2795">2011</a>). Although any causal relation cannot be established, a solution might be to require open data by default, allowing exceptions only when explicit reasons are available for not sharing. Subsequently, researchers know their data could be checked and may feel inclined to double check the <i>Results</i> section before publishing the paper. Besides a possible reduction in reporting errors, sharing data has many other advantages. Sharing data for instance facilitates aggregating data for better effect size estimates, enable reanalyzing published articles, and increase credibility of scientific findings (see also Nosek, Spies, &amp; Motyl, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2012" title="Nosek, B. A., Spies, J., &amp; Motyl, M. (2012). Scientific Utopia: II - Restructuring Incentives and Practices to Promote Truth Over Publishability. Perspectives on Psychological Science, 7, 615–631. doi:&#xA;                    10.1177/1745691612459058&#xA;                    &#xA;                  &#xA;                        " href="/article/10.3758/s13428-015-0664-2#ref-CR27" id="ref-link-section-d131366e2801">2012</a>; Sakaluk et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Sakaluk, J., Williams, A., &amp; Biernat, M. (2014). Analytic Review as a Solution to the Misreporting of Statistical Results in Psychological Science. Perspectives on Psychological Science, 9(6), 652–660." href="/article/10.3758/s13428-015-0664-2#ref-CR30" id="ref-link-section-d131366e2804">2014</a>; Wicherts, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Wicherts, J. M. (2013). Science revolves around the data. Journal of Open Psychology Data, 1(1), e1." href="/article/10.3758/s13428-015-0664-2#ref-CR38" id="ref-link-section-d131366e2807">2013</a>; Wicherts &amp; Bakker, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2012" title="Wicherts, J. M., &amp; Bakker, M. (2012). Publish (your data) or (let the data) perish! Why not publish your data too? Intelligence. doi:&#xA;                    10.1016/j.intell.2012.01.004&#xA;                    &#xA;                  &#xA;                        " href="/article/10.3758/s13428-015-0664-2#ref-CR39" id="ref-link-section-d131366e2811">2012</a>). The APA already requires data to be available for verification purposes (American Psychological Association, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="American Psychological Association. (2010). Publication Manual of the American Psychological Association (6th ed.). Washington, DC: American Psychological Association." href="/article/10.3758/s13428-015-0664-2#ref-CR3" id="ref-link-section-d131366e2814">2010</a>, p. 240), many journals explicitly encourage data sharing in their policies, and the journal Psychological Science has started to award badges to papers of which the data are publicly available. Despite these policies and encouragements, raw data are still rarely available (Alsheikh-Ali, Qureshi, Al-Mallah, &amp; Ioannidis, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Alsheikh-Ali, A. A., Qureshi, W., Al-Mallah, M. H., &amp; Ioannidis, J. P. A. (2011). Public availability of published research data in high-impact journals. PLoS One, 6(9), e24357. doi:&#xA;                    10.1371/journal.pone.0024357&#xA;                    &#xA;                  &#xA;                        " href="/article/10.3758/s13428-015-0664-2#ref-CR1" id="ref-link-section-d131366e2817">2011</a>). One objection that has been raised is that due to privacy concerns data cannot be made publicly available (see e.g., Finkel, Eastwick, &amp; Reis, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2015" title="Finkel, E. J., Eastwick, P. W., &amp; Reis, H. T. (2015). Best research practices in psychology: Illustrating epistemological and pragmatic considerations with the case of relationship science. Journal of Personality and Social Psychology, 108(2), 275–297." href="/article/10.3758/s13428-015-0664-2#ref-CR17" id="ref-link-section-d131366e2820">2015</a>). Even though this can be a legitimate concern for some studies with particularly sensitive data, these are exceptions; the data of most psychology studies could be published without risks (Nosek et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2012" title="Nosek, B. A., Spies, J., &amp; Motyl, M. (2012). Scientific Utopia: II - Restructuring Incentives and Practices to Promote Truth Over Publishability. Perspectives on Psychological Science, 7, 615–631. doi:&#xA;                    10.1177/1745691612459058&#xA;                    &#xA;                  &#xA;                        " href="/article/10.3758/s13428-015-0664-2#ref-CR27" id="ref-link-section-d131366e2823">2012</a>).</p><p>To find a successful solution to the substantial prevalence of reporting errors, more research is needed on how reporting errors arise. It is important to know whether reporting inconsistencies are mere sloppiness or whether they are intentional. We found that the large majority of inconsistencies were not gross inconsistencies around <i>p</i> = .05, but inconsistencies that did not directly influence any statistical conclusion. Rounding down a <i>p</i>-value of, say, .38 down to .37 does not seem to be in the direct interest of the researcher, suggesting that the majority of inconsistencies are accidental. On the other hand, we did find that the large majority of grossly inconsistent <i>p</i>-values were nonsignificant <i>p</i>-values that were presented as significant, instead of vice versa. This seems to indicate a systematic bias that causes an over-representation of significant results in the literature. Whatever the cause of this over-representation might be, there seems to be too much focus on getting “perfect,” significant results (see also Giner-Sorolla, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2012" title="Giner-Sorolla, R. (2012). Science or art? How aesthetic standards grease the way through the publication bottleneck but undermine science. Perspectives on Psychological Science, 7, 562–571. doi:&#xA;                    10.1177/1745691612457576&#xA;                    &#xA;                  &#xA;                        " href="/article/10.3758/s13428-015-0664-2#ref-CR19" id="ref-link-section-d131366e2841">2012</a>). Considering that the ubiquitous significance level of .05 is arbitrary, and that there is a vast amount of critique on NHST in general (see e.g., Cohen, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1994" title="Cohen, J. (1994). The earth is round (P less-than.05). American Psychologist, 49(12), 997–1003." href="/article/10.3758/s13428-015-0664-2#ref-CR9" id="ref-link-section-d131366e2845">1994</a>; Fidler &amp; Cumming, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Fidler, F., &amp; Cumming, G. (2005). Teaching confidence intervals: Problems and potential solutions. Proceedings of the 55th International Statistics Institute Session." href="/article/10.3758/s13428-015-0664-2#ref-CR15" id="ref-link-section-d131366e2848">2005</a>; Krueger, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Krueger, J. (2001). Null hypothesis significance testing - On the survival of a flawed method. American Psychologist, 56(1), 16–26." href="/article/10.3758/s13428-015-0664-2#ref-CR24" id="ref-link-section-d131366e2851">2001</a>; Rozeboom, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1960" title="Rozeboom, W. W. (1960). The fallacy of the null hypothesis significance test. Psychological Bulletin, 57, 416–428." href="/article/10.3758/s13428-015-0664-2#ref-CR29" id="ref-link-section-d131366e2854">1960</a>; Wagenmakers, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Wagenmakers, E. J. (2007). A practical solution to the pervasive problems of p values. Psychonomic Bulletin &amp; Review, 14, 779–804. doi:&#xA;                    10.3758/BF03194105&#xA;                    &#xA;                  &#xA;                        " href="/article/10.3758/s13428-015-0664-2#ref-CR36" id="ref-link-section-d131366e2857">2007</a>), it should be clear that it is more important that <i>p</i>-values are accurately reported than that they are below .05.</p><p>There are many more interesting aspects of the collected 258,105 <i>p</i>-values that could be investigated, but this is beyond the scope of this paper. In another paper, the nonsignificant test results from this dataset are investigated for false negatives (Hartgerink, van Assen, &amp; Wicherts, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2015" title="Hartgerink, C. H. J., van Assen, M. A. L. M., &amp; Wicherts, J. M. (2015). Too Good to be False: Non-Significant Results Revisited. Retrieved from osf.io/qpfnw." href="/article/10.3758/s13428-015-0664-2#ref-CR21" id="ref-link-section-d131366e2870">2015</a>). Here a method is used to detect false negatives and the results indicate two out of three papers with nonsignificant test results might contain false-negative results. This is only one out of the many possibilities and we publicly share the anonymized data on our Open Science Framework page (<a href="https://osf.io/gdr4q/">https://osf.io/gdr4q/</a>) to encourage further research.</p><p>Our study illustrates that science is done by humans, and humans easily make mistakes. However, the prevalence of inconsistent <i>p</i>-values in eight major journals in psychology has generally been stable over the years, or even declining. Hopefully, statcheck can contribute to further reducing the prevalence of reporting inconsistencies in psychology.</p></div></div></section>
                            
                        

                        <section aria-labelledby="notes"><div class="c-article-section" id="notes-section"><h2 class="c-article-section__title u-h2 js-section-title js-c-reading-companion-sections-item" id="notes">Notes</h2><div class="c-article-section__content" id="notes-content"><ol class="c-article-footnote c-article-footnote--listed"><li class="c-article-footnote--listed__item" id="Fn1"><span class="c-article-footnote--listed__index">1.</span><div class="c-article-footnote--listed__content"><p>We note there is a minor difference in the number of search results from the webpage and the package due to default specifications in the rplos package. See also <a href="https://github.com/ropensci/rplos/issues/75">https://github.com/ropensci/rplos/issues/75</a>
                              </p></div></li><li class="c-article-footnote--listed__item" id="Fn2"><span class="c-article-footnote--listed__index">2.</span><div class="c-article-footnote--listed__content"><p>The only one-tailed test that is still counted by statcheck as inconsistent is a result that is reported as one-tailed and has a rounded test statistic: t(14) = 2.0, <i>p</i> &lt;.03. The correct rounding of test statistics is not incorporated in the automatic one-tailed test detection, but this will be incorporated in the next version. For now this will not bias the results that much, since these are rare cases.</p></div></li><li class="c-article-footnote--listed__item" id="Fn3"><span class="c-article-footnote--listed__index">3.</span><div class="c-article-footnote--listed__content"><p>Note that the APA advises any <i>p</i>-value smaller than .001 to be reported as <i>p</i> &lt; .001. These cases could be considered as exactly reported. Our analysis does not take this into account. Furthermore, statements like “all tests &gt;.05” are not included in our analysis.</p></div></li></ol></div></div></section><section aria-labelledby="Bib1"><div class="c-article-section" id="Bib1-section"><h2 class="c-article-section__title u-h2 js-section-title js-c-reading-companion-sections-item" id="Bib1">References</h2><div class="c-article-section__content" id="Bib1-content"><div data-container-section="references"><ol class="c-article-references"><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="AA. Alsheikh-Ali, W. Qureshi, MH. Al-Mallah, JPA. Ioannidis, " /><meta itemprop="datePublished" content="2011" /><meta itemprop="headline" content="Alsheikh-Ali, A. A., Qureshi, W., Al-Mallah, M. H., &amp; Ioannidis, J. P. A. (2011). Public availability of publi" /><p class="c-article-references__text" id="ref-CR1">Alsheikh-Ali, A. A., Qureshi, W., Al-Mallah, M. H., &amp; Ioannidis, J. P. A. (2011). Public availability of published research data in high-impact journals. <i>PLoS One, 6</i>(9), e24357. doi:<a href="https://doi.org/10.1371/journal.pone.0024357">10.1371/journal.pone.0024357</a>
                        </p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1371%2Fjournal.pone.0024357" aria-label="View reference 1">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=21915316" aria-label="View reference 1 on PubMed" rel="nofollow">PubMed</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3168487" aria-label="View reference 1 on PubMed Central" rel="nofollow">PubMed Central</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 1 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Public%20availability%20of%20published%20research%20data%20in%20high-impact%20journals&amp;journal=PLoS%20One&amp;doi=10.1371%2Fjournal.pone.0024357&amp;volume=6&amp;issue=9&amp;publication_year=2011&amp;author=Alsheikh-Ali%2CAA&amp;author=Qureshi%2CW&amp;author=Al-Mallah%2CMH&amp;author=Ioannidis%2CJPA">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="datePublished" content="1983" /><meta itemprop="headline" content="American Psychological Association. (1983). Publication Manual of the American Psychological Association (3rd " /><p class="c-article-references__text" id="ref-CR2">American Psychological Association. (1983). <i>Publication Manual of the American Psychological Association</i> (3rd ed.). Washington, DC: American Psychological Association.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 2 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Publication%20Manual%20of%20the%20American%20Psychological%20Association&amp;publication_year=1983">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="datePublished" content="2010" /><meta itemprop="headline" content="American Psychological Association. (2010). Publication Manual of the American Psychological Association (6th " /><p class="c-article-references__text" id="ref-CR3">American Psychological Association. (2010). <i>Publication Manual of the American Psychological Association</i> (6th ed.). Washington, DC: American Psychological Association.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 3 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Publication%20Manual%20of%20the%20American%20Psychological%20Association&amp;publication_year=2010">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="M. Bakker, JM. Wicherts, " /><meta itemprop="datePublished" content="2011" /><meta itemprop="headline" content="Bakker, M., &amp; Wicherts, J. M. (2011). The (mis)reporting of statistical results in psychology journals. Behavi" /><p class="c-article-references__text" id="ref-CR4">Bakker, M., &amp; Wicherts, J. M. (2011). The (mis)reporting of statistical results in psychology journals. <i>Behavior Research Methods, 43,</i> 666–678. doi:<a href="https://doi.org/10.3758/s13428-011-0089-5">10.3758/s13428-011-0089-5</a>
                        </p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.3758%2Fs13428-011-0089-5" aria-label="View reference 4">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=21494917" aria-label="View reference 4 on PubMed" rel="nofollow">PubMed</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3174372" aria-label="View reference 4 on PubMed Central" rel="nofollow">PubMed Central</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 4 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20%28mis%29reporting%20of%20statistical%20results%20in%20psychology%20journals&amp;journal=Behavior%20Research%20Methods&amp;doi=10.3758%2Fs13428-011-0089-5&amp;volume=43&amp;pages=666-678&amp;publication_year=2011&amp;author=Bakker%2CM&amp;author=Wicherts%2CJM">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Bakker, M., &amp; Wicherts, J. M. (2014). Outlier removal and the relation with reporting errors and quality of re" /><p class="c-article-references__text" id="ref-CR5">Bakker, M., &amp; Wicherts, J. M. (2014). <i>Outlier removal and the relation with reporting errors and quality of research</i>. Manuscript submitted for publication.</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="D. Berle, V. Starcevic, " /><meta itemprop="datePublished" content="2007" /><meta itemprop="headline" content="Berle, D., &amp; Starcevic, V. (2007). Inconsistencies between reported test statistics and p-values in two psychi" /><p class="c-article-references__text" id="ref-CR6">Berle, D., &amp; Starcevic, V. (2007). Inconsistencies between reported test statistics and p-values in two psychiatry journals. <i>International Journal of Methods in Psychiatric Research, 16</i>(4), 202–207. doi:<a href="https://doi.org/10.1002/mpr.225">10.1002/mpr.225</a>
                        </p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1002%2Fmpr.225" aria-label="View reference 6">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=18188836" aria-label="View reference 6 on PubMed" rel="nofollow">PubMed</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 6 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Inconsistencies%20between%20reported%20test%20statistics%20and%20p-values%20in%20two%20psychiatry%20journals&amp;journal=International%20Journal%20of%20Methods%20in%20Psychiatric%20Research&amp;doi=10.1002%2Fmpr.225&amp;volume=16&amp;issue=4&amp;pages=202-207&amp;publication_year=2007&amp;author=Berle%2CD&amp;author=Starcevic%2CV">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="JM. Caperos, A. Pardo, " /><meta itemprop="datePublished" content="2013" /><meta itemprop="headline" content="Caperos, J. M., &amp; Pardo, A. (2013). Consistency errors in p-values reported in Spanish psychology journals. Ps" /><p class="c-article-references__text" id="ref-CR7">Caperos, J. M., &amp; Pardo, A. (2013). Consistency errors in p-values reported in Spanish psychology journals. <i>Psicothema, 25</i>(3), 408–414.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=23910759" aria-label="View reference 7 on PubMed" rel="nofollow">PubMed</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 7 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Consistency%20errors%20in%20p-values%20reported%20in%20Spanish%20psychology%20journals&amp;journal=Psicothema&amp;volume=25&amp;issue=3&amp;pages=408-414&amp;publication_year=2013&amp;author=Caperos%2CJM&amp;author=Pardo%2CA">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Chamberlain, S., Boettiger, C., &amp; Ram, K. (2014). rplos: Interface to PLoS Journals search API. R package vers" /><p class="c-article-references__text" id="ref-CR8">Chamberlain, S., Boettiger, C., &amp; Ram, K. (2014). <i>rplos: Interface to PLoS Journals search API</i>. R package version 0.4.0. <a href="http://cran.r-project.org/package=rplos">http://CRAN.R-project.org/package=rplos</a>
                        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="J. Cohen, " /><meta itemprop="datePublished" content="1994" /><meta itemprop="headline" content="Cohen, J. (1994). The earth is round (P less-than.05). American Psychologist, 49(12), 997–1003." /><p class="c-article-references__text" id="ref-CR9">Cohen, J. (1994). The earth is round (P less-than.05). <i>American Psychologist, 49</i>(12), 997–1003.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1037%2F0003-066X.49.12.997" aria-label="View reference 9">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 9 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20earth%20is%20round%20%28P%20less-than.05%29&amp;journal=American%20Psychologist&amp;volume=49&amp;issue=12&amp;pages=997-1003&amp;publication_year=1994&amp;author=Cohen%2CJ">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Cumming, G., Fidler, F., Leonard, M., Kalinowski, P., Christiansen, A., Kleinig, A., . . . Wilson, S. (2007). " /><p class="c-article-references__text" id="ref-CR10">Cumming, G., Fidler, F., Leonard, M., Kalinowski, P., Christiansen, A., Kleinig, A., . . . Wilson, S. (2007). Statistical reform in psychology: Is anything changing? <i>Psychological science, 18</i>(3), 230–232.</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Epskamp, S., &amp; Nuijten, M. B. (2015). statcheck: Extract statistics from articles and recompute p values. R pa" /><p class="c-article-references__text" id="ref-CR11">Epskamp, S., &amp; Nuijten, M. B. (2015). <i>statcheck: Extract statistics from articles and recompute p values</i>. R package version 1.0.1. <a href="http://cran.r-project.org/package=statcheck">http://CRAN.R-project.org/package=statcheck</a>
                        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="D. Fanelli, " /><meta itemprop="datePublished" content="2012" /><meta itemprop="headline" content="Fanelli, D. (2012). Negative results are disappearing from most disciplines and countries. Scientometrics, 90(" /><p class="c-article-references__text" id="ref-CR12">Fanelli, D. (2012). Negative results are disappearing from most disciplines and countries. <i>Scientometrics, 90</i>(3), 891–904. doi:<a href="https://doi.org/10.1007/s11192-011-0494-7">10.1007/s11192-011-0494-7</a>
                        </p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1007%2Fs11192-011-0494-7" aria-label="View reference 12">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 12 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Negative%20results%20are%20disappearing%20from%20most%20disciplines%20and%20countries&amp;journal=Scientometrics&amp;doi=10.1007%2Fs11192-011-0494-7&amp;volume=90&amp;issue=3&amp;pages=891-904&amp;publication_year=2012&amp;author=Fanelli%2CD">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Fanelli, D. (2013). Why Growing Retractions Are (Mostly) a Good Sign. Plos Medicine, 10(12). doi: 10.1371/jour" /><p class="c-article-references__text" id="ref-CR13">Fanelli, D. (2013). Why Growing Retractions Are (Mostly) a Good Sign. <i>Plos Medicine, 10</i>(12). doi: <a href="https://doi.org/10.1371/journal.pmed.1001563">10.1371/journal.pmed.1001563</a>
                        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="D. Fanelli, " /><meta itemprop="datePublished" content="2014" /><meta itemprop="headline" content="Fanelli, D. (2014). Rise in retractions is a signal of integrity. Nature, 509(7498), 33–33." /><p class="c-article-references__text" id="ref-CR14">Fanelli, D. (2014). Rise in retractions is a signal of integrity. <i>Nature, 509</i>(7498), 33–33.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1038%2F509033a" aria-label="View reference 14">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=24784207" aria-label="View reference 14 on PubMed" rel="nofollow">PubMed</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 14 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Rise%20in%20retractions%20is%20a%20signal%20of%20integrity&amp;journal=Nature&amp;volume=509&amp;issue=7498&amp;pages=33-33&amp;publication_year=2014&amp;author=Fanelli%2CD">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Fidler, F., &amp; Cumming, G. (2005). Teaching confidence intervals: Problems and potential solutions. Proceedings" /><p class="c-article-references__text" id="ref-CR15">Fidler, F., &amp; Cumming, G. (2005). Teaching confidence intervals: Problems and potential solutions. <i>Proceedings of the 55th International Statistics Institute Session</i>.</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Fiedler, K., &amp; Schwarz, N. (2015). Questionable Research Practices Revisited." /><p class="c-article-references__text" id="ref-CR16">Fiedler, K., &amp; Schwarz, N. (2015). <i>Questionable Research Practices Revisited</i>.</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="EJ. Finkel, PW. Eastwick, HT. Reis, " /><meta itemprop="datePublished" content="2015" /><meta itemprop="headline" content="Finkel, E. J., Eastwick, P. W., &amp; Reis, H. T. (2015). Best research practices in psychology: Illustrating epis" /><p class="c-article-references__text" id="ref-CR17">Finkel, E. J., Eastwick, P. W., &amp; Reis, H. T. (2015). Best research practices in psychology: Illustrating epistemological and pragmatic considerations with the case of relationship science. <i>Journal of Personality and Social Psychology, 108</i>(2), 275–297.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1037%2Fpspi0000007" aria-label="View reference 17">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=25603376" aria-label="View reference 17 on PubMed" rel="nofollow">PubMed</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 17 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Best%20research%20practices%20in%20psychology%3A%20Illustrating%20epistemological%20and%20pragmatic%20considerations%20with%20the%20case%20of%20relationship%20science&amp;journal=Journal%20of%20Personality%20and%20Social%20Psychology&amp;volume=108&amp;issue=2&amp;pages=275-297&amp;publication_year=2015&amp;author=Finkel%2CEJ&amp;author=Eastwick%2CPW&amp;author=Reis%2CHT">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="E. Garcia-Berthou, C. Alcaraz, " /><meta itemprop="datePublished" content="2004" /><meta itemprop="headline" content="Garcia-Berthou, E., &amp; Alcaraz, C. (2004). Incongruence between test statistics and P values in medical papers." /><p class="c-article-references__text" id="ref-CR18">Garcia-Berthou, E., &amp; Alcaraz, C. (2004). Incongruence between test statistics and P values in medical papers. <i>Bmc Medical Research Methodology, 4,</i> 13. doi:<a href="https://doi.org/10.1186/1471-2288-4-13">10.1186/1471-2288-4-13</a>
                        </p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1186%2F1471-2288-4-13" aria-label="View reference 18">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=15169550" aria-label="View reference 18 on PubMed" rel="nofollow">PubMed</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC443510" aria-label="View reference 18 on PubMed Central" rel="nofollow">PubMed Central</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 18 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Incongruence%20between%20test%20statistics%20and%20P%20values%20in%20medical%20papers&amp;journal=Bmc%20Medical%20Research%20Methodology&amp;doi=10.1186%2F1471-2288-4-13&amp;volume=4&amp;publication_year=2004&amp;author=Garcia-Berthou%2CE&amp;author=Alcaraz%2CC">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="R. Giner-Sorolla, " /><meta itemprop="datePublished" content="2012" /><meta itemprop="headline" content="Giner-Sorolla, R. (2012). Science or art? How aesthetic standards grease the way through the publication bottl" /><p class="c-article-references__text" id="ref-CR19">Giner-Sorolla, R. (2012). Science or art? How aesthetic standards grease the way through the publication bottleneck but undermine science. <i>Perspectives on Psychological Science, 7,</i> 562–571. doi:<a href="https://doi.org/10.1177/1745691612457576">10.1177/1745691612457576</a>
                        </p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1177%2F1745691612457576" aria-label="View reference 19">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=26168113" aria-label="View reference 19 on PubMed" rel="nofollow">PubMed</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 19 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Science%20or%20art%3F%20How%20aesthetic%20standards%20grease%20the%20way%20through%20the%20publication%20bottleneck%20but%20undermine%20science&amp;journal=Perspectives%20on%20Psychological%20Science&amp;doi=10.1177%2F1745691612457576&amp;volume=7&amp;pages=562-571&amp;publication_year=2012&amp;author=Giner-Sorolla%2CR">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="PC. Gotzsche, A. Hrobjartsson, K. Maric, B. Tendal, " /><meta itemprop="datePublished" content="2007" /><meta itemprop="headline" content="Gotzsche, P. C., Hrobjartsson, A., Maric, K., &amp; Tendal, B. (2007). Data extraction errors in meta-analyses tha" /><p class="c-article-references__text" id="ref-CR20">Gotzsche, P. C., Hrobjartsson, A., Maric, K., &amp; Tendal, B. (2007). Data extraction errors in meta-analyses that use standardized mean differences. <i>Jama-Journal of the American Medical Association, 298</i>(4), 430–437.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1001%2Fjama.298.4.430" aria-label="View reference 20">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 20 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Data%20extraction%20errors%20in%20meta-analyses%20that%20use%20standardized%20mean%20differences&amp;journal=Jama-Journal%20of%20the%20American%20Medical%20Association&amp;volume=298&amp;issue=4&amp;pages=430-437&amp;publication_year=2007&amp;author=Gotzsche%2CPC&amp;author=Hrobjartsson%2CA&amp;author=Maric%2CK&amp;author=Tendal%2CB">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Hartgerink, C. H. J., van Assen, M. A. L. M., &amp; Wicherts, J. M. (2015). Too Good to be False: Non-Significant " /><p class="c-article-references__text" id="ref-CR21">Hartgerink, C. H. J., van Assen, M. A. L. M., &amp; Wicherts, J. M. (2015). Too Good to be False: Non-Significant Results Revisited. <i>Retrieved from osf.io/qpfnw</i>.</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="R. Hubbard, PA. Ryan, " /><meta itemprop="datePublished" content="2000" /><meta itemprop="headline" content="Hubbard, R., &amp; Ryan, P. A. (2000). The historical growth of statistical significance testing in psychology-and" /><p class="c-article-references__text" id="ref-CR22">Hubbard, R., &amp; Ryan, P. A. (2000). The historical growth of statistical significance testing in psychology-and its future prospects. <i>Educational and Psychological Measurement, 60,</i> 661–681.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 22 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20historical%20growth%20of%20statistical%20significance%20testing%20in%20psychology-and%20its%20future%20prospects&amp;journal=Educational%20and%20Psychological%20Measurement&amp;volume=60&amp;pages=661-681&amp;publication_year=2000&amp;author=Hubbard%2CR&amp;author=Ryan%2CPA">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="LK. John, G. Loewenstein, D. Prelec, " /><meta itemprop="datePublished" content="2012" /><meta itemprop="headline" content="John, L. K., Loewenstein, G., &amp; Prelec, D. (2012). Measuring the prevalence of questionable research practices" /><p class="c-article-references__text" id="ref-CR23">John, L. K., Loewenstein, G., &amp; Prelec, D. (2012). Measuring the prevalence of questionable research practices with incentives for truth-telling. <i>Psychological science, 23,</i> 524–532. doi:<a href="https://doi.org/10.1177/0956797611430953">10.1177/0956797611430953</a>
                        </p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1177%2F0956797611430953" aria-label="View reference 23">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=22508865" aria-label="View reference 23 on PubMed" rel="nofollow">PubMed</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 23 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Measuring%20the%20prevalence%20of%20questionable%20research%20practices%20with%20incentives%20for%20truth-telling&amp;journal=Psychological%20science&amp;doi=10.1177%2F0956797611430953&amp;volume=23&amp;pages=524-532&amp;publication_year=2012&amp;author=John%2CLK&amp;author=Loewenstein%2CG&amp;author=Prelec%2CD">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="J. Krueger, " /><meta itemprop="datePublished" content="2001" /><meta itemprop="headline" content="Krueger, J. (2001). Null hypothesis significance testing - On the survival of a flawed method. American Psycho" /><p class="c-article-references__text" id="ref-CR24">Krueger, J. (2001). Null hypothesis significance testing - On the survival of a flawed method. <i>American Psychologist, 56</i>(1), 16–26.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1037%2F0003-066X.56.1.16" aria-label="View reference 24">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=11242984" aria-label="View reference 24 on PubMed" rel="nofollow">PubMed</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 24 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Null%20hypothesis%20significance%20testing%20-%20On%20the%20survival%20of%20a%20flawed%20method&amp;journal=American%20Psychologist&amp;volume=56&amp;issue=1&amp;pages=16-26&amp;publication_year=2001&amp;author=Krueger%2CJ">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="NC. Leggett, NA. Thomas, T. Loetscher, ME. Nicholls, " /><meta itemprop="datePublished" content="2013" /><meta itemprop="headline" content="Leggett, N. C., Thomas, N. A., Loetscher, T., &amp; Nicholls, M. E. (2013). The life of p:“Just significant” resul" /><p class="c-article-references__text" id="ref-CR25">Leggett, N. C., Thomas, N. A., Loetscher, T., &amp; Nicholls, M. E. (2013). The life of p:“Just significant” results are on the rise. <i>The Quarterly Journal of Experimental Psychology, 66</i>(12), 2303–2309.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1080%2F17470218.2013.863371" aria-label="View reference 25">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=24205936" aria-label="View reference 25 on PubMed" rel="nofollow">PubMed</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 25 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20life%20of%20p%3A%E2%80%9CJust%20significant%E2%80%9D%20results%20are%20on%20the%20rise&amp;journal=The%20Quarterly%20Journal%20of%20Experimental%20Psychology&amp;volume=66&amp;issue=12&amp;pages=2303-2309&amp;publication_year=2013&amp;author=Leggett%2CNC&amp;author=Thomas%2CNA&amp;author=Loetscher%2CT&amp;author=Nicholls%2CME">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="TR. Levine, CR. Hullett, " /><meta itemprop="datePublished" content="2002" /><meta itemprop="headline" content="Levine, T. R., &amp; Hullett, C. R. (2002). Eta squared, partial eta squared, and misreporting of effect size in c" /><p class="c-article-references__text" id="ref-CR26">Levine, T. R., &amp; Hullett, C. R. (2002). Eta squared, partial eta squared, and misreporting of effect size in communication research. <i>Human Communication Research, 28</i>(4), 612–625. doi:<a href="https://doi.org/10.1111/j.1468-2958.2002.tb00828.x">10.1111/j.1468-2958.2002.tb00828.x</a>
                        </p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1111%2Fj.1468-2958.2002.tb00828.x" aria-label="View reference 26">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 26 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Eta%20squared%2C%20partial%20eta%20squared%2C%20and%20misreporting%20of%20effect%20size%20in%20communication%20research&amp;journal=Human%20Communication%20Research&amp;doi=10.1111%2Fj.1468-2958.2002.tb00828.x&amp;volume=28&amp;issue=4&amp;pages=612-625&amp;publication_year=2002&amp;author=Levine%2CTR&amp;author=Hullett%2CCR">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="BA. Nosek, J. Spies, M. Motyl, " /><meta itemprop="datePublished" content="2012" /><meta itemprop="headline" content="Nosek, B. A., Spies, J., &amp; Motyl, M. (2012). Scientific Utopia: II - Restructuring Incentives and Practices to" /><p class="c-article-references__text" id="ref-CR27">Nosek, B. A., Spies, J., &amp; Motyl, M. (2012). Scientific Utopia: II - Restructuring Incentives and Practices to Promote Truth Over Publishability. <i>Perspectives on Psychological Science, 7,</i> 615–631. doi:<a href="https://doi.org/10.1177/1745691612459058">10.1177/1745691612459058</a>
                        </p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1177%2F1745691612459058" aria-label="View reference 27">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=26168121" aria-label="View reference 27 on PubMed" rel="nofollow">PubMed</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 27 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Scientific%20Utopia%3A%20II%20-%20Restructuring%20Incentives%20and%20Practices%20to%20Promote%20Truth%20Over%20Publishability&amp;journal=Perspectives%20on%20Psychological%20Science&amp;doi=10.1177%2F1745691612459058&amp;volume=7&amp;pages=615-631&amp;publication_year=2012&amp;author=Nosek%2CBA&amp;author=Spies%2CJ&amp;author=Motyl%2CM">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="R Core Team. (2014). R: A Language and Environment for Statistical Computing. http://www.R-project.org/&#xA;      " /><p class="c-article-references__text" id="ref-CR28">R Core Team. (2014). R: A Language and Environment for Statistical Computing. <a href="http://www.r-project.org/">http://www.R-project.org/</a>
                        </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="WW. Rozeboom, " /><meta itemprop="datePublished" content="1960" /><meta itemprop="headline" content="Rozeboom, W. W. (1960). The fallacy of the null hypothesis significance test. Psychological Bulletin, 57, 416–" /><p class="c-article-references__text" id="ref-CR29">Rozeboom, W. W. (1960). The fallacy of the null hypothesis significance test. <i>Psychological Bulletin, 57,</i> 416–428.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1037%2Fh0042040" aria-label="View reference 29">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=13744252" aria-label="View reference 29 on PubMed" rel="nofollow">PubMed</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 29 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20fallacy%20of%20the%20null%20hypothesis%20significance%20test&amp;journal=Psychological%20Bulletin&amp;volume=57&amp;pages=416-428&amp;publication_year=1960&amp;author=Rozeboom%2CWW">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="J. Sakaluk, A. Williams, M. Biernat, " /><meta itemprop="datePublished" content="2014" /><meta itemprop="headline" content="Sakaluk, J., Williams, A., &amp; Biernat, M. (2014). Analytic Review as a Solution to the Misreporting of Statisti" /><p class="c-article-references__text" id="ref-CR30">Sakaluk, J., Williams, A., &amp; Biernat, M. (2014). Analytic Review as a Solution to the Misreporting of Statistical Results in Psychological Science. <i>Perspectives on Psychological Science, 9</i>(6), 652–660.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1177%2F1745691614549257" aria-label="View reference 30">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=26186115" aria-label="View reference 30 on PubMed" rel="nofollow">PubMed</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 30 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Analytic%20Review%20as%20a%20Solution%20to%20the%20Misreporting%20of%20Statistical%20Results%20in%20Psychological%20Science&amp;journal=Perspectives%20on%20Psychological%20Science&amp;volume=9&amp;issue=6&amp;pages=652-660&amp;publication_year=2014&amp;author=Sakaluk%2CJ&amp;author=Williams%2CA&amp;author=Biernat%2CM">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="U. Simonsohn, LD. Nelson, JP. Simmons, " /><meta itemprop="datePublished" content="2014" /><meta itemprop="headline" content="Simonsohn, U., Nelson, L. D., &amp; Simmons, J. P. (2014). P-curve: A key to the file-drawer. Journal of Experimen" /><p class="c-article-references__text" id="ref-CR31">Simonsohn, U., Nelson, L. D., &amp; Simmons, J. P. (2014). P-curve: A key to the file-drawer. <i>Journal of Experimental Psychology: General, 143</i>(2), 534–547.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1037%2Fa0033242" aria-label="View reference 31">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 31 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=P-curve%3A%20A%20key%20to%20the%20file-drawer&amp;journal=Journal%20of%20Experimental%20Psychology%3A%20General&amp;volume=143&amp;issue=2&amp;pages=534-547&amp;publication_year=2014&amp;author=Simonsohn%2CU&amp;author=Nelson%2CLD&amp;author=Simmons%2CJP">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="TD. Sterling, " /><meta itemprop="datePublished" content="1959" /><meta itemprop="headline" content="Sterling, T. D. (1959). Publication decisions and their possible effects on inferences drawn from tests of sig" /><p class="c-article-references__text" id="ref-CR32">Sterling, T. D. (1959). Publication decisions and their possible effects on inferences drawn from tests of significance - Or vice versa. <i>Journal of the American Statistical Association, 54,</i> 30–34.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 32 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Publication%20decisions%20and%20their%20possible%20effects%20on%20inferences%20drawn%20from%20tests%20of%20significance%20-%20Or%20vice%20versa&amp;journal=Journal%20of%20the%20American%20Statistical%20Association&amp;volume=54&amp;pages=30-34&amp;publication_year=1959&amp;author=Sterling%2CTD">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="TD. Sterling, WL. Rosenbaum, JJ. Weinkam, " /><meta itemprop="datePublished" content="1995" /><meta itemprop="headline" content="Sterling, T. D., Rosenbaum, W. L., &amp; Weinkam, J. J. (1995). Publication decisions revisited - The effect of th" /><p class="c-article-references__text" id="ref-CR33">Sterling, T. D., Rosenbaum, W. L., &amp; Weinkam, J. J. (1995). Publication decisions revisited - The effect of the outcome of statistical tests on the decision to publish and vice-versa. <i>American Statistician, 49</i>(1), 108–112.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 33 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Publication%20decisions%20revisited%20-%20The%20effect%20of%20the%20outcome%20of%20statistical%20tests%20on%20the%20decision%20to%20publish%20and%20vice-versa&amp;journal=American%20Statistician&amp;volume=49&amp;issue=1&amp;pages=108-112&amp;publication_year=1995&amp;author=Sterling%2CTD&amp;author=Rosenbaum%2CWL&amp;author=Weinkam%2CJJ">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Van Assen, M. A. L. M., Van Aert, R. C. M., &amp; Wicherts, J. M. (2014). Meta-analysis using effect size distribu" /><p class="c-article-references__text" id="ref-CR34">Van Assen, M. A. L. M., Van Aert, R. C. M., &amp; Wicherts, J. M. (2014). Meta-analysis using effect size distributions of only statistically significant studies. <i>Psychological Methods</i>.</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="headline" content="Veldkamp, C. L. S., Nuijten, M. B., Dominguez-Alvarez, L., Van Assen, M. A. L. M., &amp; Wicherts, J. M. (2014). S" /><p class="c-article-references__text" id="ref-CR35">Veldkamp, C. L. S., Nuijten, M. B., Dominguez-Alvarez, L., Van Assen, M. A. L. M., &amp; Wicherts, J. M. (2014). Statistical reporting errors and collaboration on statistical analyses in psychological science <i>PLoS One</i>.</p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="EJ. Wagenmakers, " /><meta itemprop="datePublished" content="2007" /><meta itemprop="headline" content="Wagenmakers, E. J. (2007). A practical solution to the pervasive problems of p values. Psychonomic Bulletin &amp; " /><p class="c-article-references__text" id="ref-CR36">Wagenmakers, E. J. (2007). A practical solution to the pervasive problems of p values. <i>Psychonomic Bulletin &amp; Review, 14,</i> 779–804. doi:<a href="https://doi.org/10.3758/BF03194105">10.3758/BF03194105</a>
                        </p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.3758%2FBF03194105" aria-label="View reference 36">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 36 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20practical%20solution%20to%20the%20pervasive%20problems%20of%20p%20values&amp;journal=Psychonomic%20Bulletin%20%26%20Review&amp;doi=10.3758%2FBF03194105&amp;volume=14&amp;pages=779-804&amp;publication_year=2007&amp;author=Wagenmakers%2CEJ">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="JM. Wicherts, " /><meta itemprop="datePublished" content="2011" /><meta itemprop="headline" content="Wicherts, J. M. (2011). Psychology must learn a lesson from fraud case. Nature, 480, 7. doi:10.1038/480007a&#xA;  " /><p class="c-article-references__text" id="ref-CR37">Wicherts, J. M. (2011). Psychology must learn a lesson from fraud case. <i>Nature, 480,</i> 7. doi:<a href="https://doi.org/10.1038/480007a">10.1038/480007a</a>
                        </p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1038%2F480007a" aria-label="View reference 37">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=22129686" aria-label="View reference 37 on PubMed" rel="nofollow">PubMed</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 37 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Psychology%20must%20learn%20a%20lesson%20from%20fraud%20case&amp;journal=Nature&amp;doi=10.1038%2F480007a&amp;volume=480&amp;publication_year=2011&amp;author=Wicherts%2CJM">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="JM. Wicherts, " /><meta itemprop="datePublished" content="2013" /><meta itemprop="headline" content="Wicherts, J. M. (2013). Science revolves around the data. Journal of Open Psychology Data, 1(1), e1." /><p class="c-article-references__text" id="ref-CR38">Wicherts, J. M. (2013). Science revolves around the data. <i>Journal of Open Psychology Data, 1</i>(1), e1.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.5334%2Fjopd.e1" aria-label="View reference 38">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 38 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Science%20revolves%20around%20the%20data&amp;journal=Journal%20of%20Open%20Psychology%20Data&amp;volume=1&amp;issue=1&amp;publication_year=2013&amp;author=Wicherts%2CJM">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="JM. Wicherts, M. Bakker, " /><meta itemprop="datePublished" content="2012" /><meta itemprop="headline" content="Wicherts, J. M., &amp; Bakker, M. (2012). Publish (your data) or (let the data) perish! Why not publish your data " /><p class="c-article-references__text" id="ref-CR39">Wicherts, J. M., &amp; Bakker, M. (2012). Publish (your data) or (let the data) perish! Why not publish your data too? <i>Intelligence</i>. doi:<a href="https://doi.org/10.1016/j.intell.2012.01.004">10.1016/j.intell.2012.01.004</a>
                        </p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 39 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Publish%20%28your%20data%29%20or%20%28let%20the%20data%29%20perish%21%20Why%20not%20publish%20your%20data%20too%3F&amp;journal=Intelligence&amp;doi=10.1016%2Fj.intell.2012.01.004&amp;publication_year=2012&amp;author=Wicherts%2CJM&amp;author=Bakker%2CM">
                        Google Scholar</a></li></ul></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="JM. Wicherts, M. Bakker, D. Molenaar, " /><meta itemprop="datePublished" content="2011" /><meta itemprop="headline" content="Wicherts, J. M., Bakker, M., &amp; Molenaar, D. (2011). Willingness to share research data is related to the stren" /><p class="c-article-references__text" id="ref-CR40">Wicherts, J. M., Bakker, M., &amp; Molenaar, D. (2011). Willingness to share research data is related to the strength of the evidence and the quality of reporting of statistical results. <i>PLoS One, 6</i>(11), e26828.</p><ul class="c-article-references__links u-hide-print"><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="https://doi.org/10.1371%2Fjournal.pone.0026828" aria-label="View reference 40">Article</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=22073203" aria-label="View reference 40 on PubMed" rel="nofollow">PubMed</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3206853" aria-label="View reference 40 on PubMed Central" rel="nofollow">PubMed Central</a></li><li><a data-track="click" data-track-action="outbound reference" data-track-category="article body" data-track-label="link" aria-label="Search for reference 40 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Willingness%20to%20share%20research%20data%20is%20related%20to%20the%20strength%20of%20the%20evidence%20and%20the%20quality%20of%20reporting%20of%20statistical%20results&amp;journal=PLoS%20One&amp;volume=6&amp;issue=11&amp;publication_year=2011&amp;author=Wicherts%2CJM&amp;author=Bakker%2CM&amp;author=Molenaar%2CD">
                        Google Scholar</a></li></ul></li></ol><p class="c-article-references__download u-hide-print"><a data-track="click" data-track-action="download citation references" data-track-category="article body" data-track-label="link" href="/article/10.3758/s13428-015-0664-2-references.ris">Download references<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p></div></div></div></section><section aria-labelledby="Ack1"><div class="c-article-section" id="Ack1-section"><h2 class="c-article-section__title u-h2 js-section-title js-c-reading-companion-sections-item" id="Ack1">Author note</h2><div class="c-article-section__content" id="Ack1-content"><p>The preparation of this article was supported by The Innovational Research Incentives Scheme Vidi (no. 452-11-004) from the Netherlands Organization for Scientific Research.</p></div></div></section><section aria-labelledby="author-information"><div class="c-article-section" id="author-information-section"><h2 class="c-article-section__title u-h2 js-section-title js-c-reading-companion-sections-item" id="author-information">Author information</h2><div class="c-article-section__content" id="author-information-content"><h3 class="c-article-author-information__subtitle u-h3" id="affiliations">Affiliations</h3><ol class="c-article-author-affiliation__list"><li id="Aff1"><span class="c-article-author-affiliation__address u-h3">Department of Methodology and Statistics, Tilburg School of Social and Behavioral Sciences, Tilburg University, Tilburg, Netherlands</span><ul class="c-article-author-affiliation__authors-list"><li class="c-article-author-affiliation__authors-item">Michèle B. Nuijten</li><li class="c-article-author-affiliation__authors-item">, Chris H. J. Hartgerink</li><li class="c-article-author-affiliation__authors-item">, Marcel A. L. M. van Assen</li><li class="c-article-author-affiliation__authors-item"> &amp; Jelte M. Wicherts</li></ul></li><li id="Aff2"><span class="c-article-author-affiliation__address u-h3">Psychological Methods, University of Amsterdam, Amsterdam, Netherlands</span><ul class="c-article-author-affiliation__authors-list"><li class="c-article-author-affiliation__authors-item">Sacha Epskamp</li></ul></li></ol><div class="js-hide u-hide-print" data-test="author-info"><span class="c-article-author-information__subtitle u-h3">Authors</span><ol class="c-article-authors-search u-list-reset"><li id="auth-1"><span class="c-article-authors-search__title u-h3 js-search-name">Michèle B. Nuijten</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Mich%C3%A8le B.+Nuijten&#34;" class="c-article-button" data-track="click" data-track-category="Article body" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><span class="search-in-title-js">You can also search for this author in </span><ul class="c-article-identifiers"><li class="c-article-identifiers__item"><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Mich%C3%A8le B.+Nuijten" data-track="click" data-track-category="Article body" data-track-action="author link - pubmed" data-track-label="link">PubMed</a></li><li class="c-article-identifiers__item"><a href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Mich%C3%A8le B.+Nuijten%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-category="Article body" data-track-action="author link - scholar" data-track-label="link">
                                Google Scholar
                            </a></li></ul></div></div></li><li id="auth-2"><span class="c-article-authors-search__title u-h3 js-search-name">Chris H. J. Hartgerink</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Chris H. J.+Hartgerink&#34;" class="c-article-button" data-track="click" data-track-category="Article body" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><span class="search-in-title-js">You can also search for this author in </span><ul class="c-article-identifiers"><li class="c-article-identifiers__item"><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Chris H. J.+Hartgerink" data-track="click" data-track-category="Article body" data-track-action="author link - pubmed" data-track-label="link">PubMed</a></li><li class="c-article-identifiers__item"><a href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Chris H. J.+Hartgerink%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-category="Article body" data-track-action="author link - scholar" data-track-label="link">
                                Google Scholar
                            </a></li></ul></div></div></li><li id="auth-3"><span class="c-article-authors-search__title u-h3 js-search-name">Marcel A. L. M. van Assen</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Marcel A. L. M.+Assen&#34;" class="c-article-button" data-track="click" data-track-category="Article body" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><span class="search-in-title-js">You can also search for this author in </span><ul class="c-article-identifiers"><li class="c-article-identifiers__item"><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Marcel A. L. M.+Assen" data-track="click" data-track-category="Article body" data-track-action="author link - pubmed" data-track-label="link">PubMed</a></li><li class="c-article-identifiers__item"><a href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Marcel A. L. M.+Assen%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-category="Article body" data-track-action="author link - scholar" data-track-label="link">
                                Google Scholar
                            </a></li></ul></div></div></li><li id="auth-4"><span class="c-article-authors-search__title u-h3 js-search-name">Sacha Epskamp</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Sacha+Epskamp&#34;" class="c-article-button" data-track="click" data-track-category="Article body" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><span class="search-in-title-js">You can also search for this author in </span><ul class="c-article-identifiers"><li class="c-article-identifiers__item"><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Sacha+Epskamp" data-track="click" data-track-category="Article body" data-track-action="author link - pubmed" data-track-label="link">PubMed</a></li><li class="c-article-identifiers__item"><a href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Sacha+Epskamp%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-category="Article body" data-track-action="author link - scholar" data-track-label="link">
                                Google Scholar
                            </a></li></ul></div></div></li><li id="auth-5"><span class="c-article-authors-search__title u-h3 js-search-name">Jelte M. Wicherts</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Jelte M.+Wicherts&#34;" class="c-article-button" data-track="click" data-track-category="Article body" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><span class="search-in-title-js">You can also search for this author in </span><ul class="c-article-identifiers"><li class="c-article-identifiers__item"><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Jelte M.+Wicherts" data-track="click" data-track-category="Article body" data-track-action="author link - pubmed" data-track-label="link">PubMed</a></li><li class="c-article-identifiers__item"><a href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Jelte M.+Wicherts%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-category="Article body" data-track-action="author link - scholar" data-track-label="link">
                                Google Scholar
                            </a></li></ul></div></div></li></ol></div><h3 class="c-article-author-information__subtitle u-h3" id="corresponding-author">Corresponding author</h3><p>Correspondence to
                <a id="corresp-c1" rel="nofollow" href="/article/10.3758/s13428-015-0664-2/email/correspondent/c1/new">Michèle B. Nuijten</a>.</p></div></div></section><section aria-labelledby="appendices"><div class="c-article-section" id="appendices-section"><h2 class="c-article-section__title u-h2 js-section-title js-c-reading-companion-sections-item" id="appendices">Appendices</h2><div class="c-article-section__content" id="appendices-content"><h3 class="c-article__sub-heading u-h3" id="App1">
                           <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.3758/s13428-015-0664-2#Sec14">Appendix A</a>: Results validity check statcheck</h3><p>Here we investigate the validity of the R program “statcheck” (Epskamp &amp; Nuijten, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2015" title="Epskamp, S., &amp; Nuijten, M. B. (2015). statcheck: Extract statistics from articles and recompute p values. R package version 1.0.1. &#xA;                    http://CRAN.R-project.org/package=statcheck&#xA;                    &#xA;                  &#xA;                        " href="/article/10.3758/s13428-015-0664-2#ref-CR11" id="ref-link-section-d131366e2912">2015</a>) by comparing the results of statcheck with the results of a study in which all statistics were manually retrieved, recalculated, and verified (Wicherts et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Wicherts, J. M., Bakker, M., &amp; Molenaar, D. (2011). Willingness to share research data is related to the strength of the evidence and the quality of reporting of statistical results. PLoS One, 6(11), e26828." href="/article/10.3758/s13428-015-0664-2#ref-CR40" id="ref-link-section-d131366e2915">2011</a>).</p><h3 class="c-article__sub-heading u-h3" id="Sec15">Method</h3><h4 class="c-article__sub-heading u-h3 c-article__sub-heading--light" id="Sec16">Sample</h4><p>We used statcheck to scan the same 49 articles from the Journal of Experimental Psychology: Learning, Memory, and Cognition (JEP:LMC) and the Journal of Personality and Social Psychology (JPSP) that have been manually checked for reporting errors in Wicherts et al., who also double checked each reported error after it had been uncovered. The inclusion criteria for the statistical results to check for inconsistencies differed slightly between the study of Wicherts et al. and statcheck (see Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.3758/s13428-015-0664-2#Tab3">3</a>).</p><p>Both in Wicherts et al. and in this validity study only <i>p</i>-values smaller than .05 and only results from <i>t</i>, <i>F</i>, or χ<sup>2</sup> tests were included. Wicherts et al. required the result to be reported completely. statcheck had the equivalent, but stricter criterion that the results had to be reported exactly according to American Psychological Association (APA) guidelines (in general: test statistic (degrees of freedom) =/&lt;/&gt; …, <i>p</i> =/&lt;/&gt;…). Furthermore, Wicherts et al. included all results reported in the text or a table in the <i>Results</i> section of an article. statcheck did not distinguish between different sections in a paper, but included all complete results in APA style. This, in practice, often excludes results reported in a table. Lastly, Wicherts et al. stated that they only evaluated results of NHST. statcheck did not explicitly have this criterion, but implicitly APA reported results of a <i>t</i>, <i>F</i>, or χ<sup>2</sup> test will always be a NHST result.</p><h4 class="c-article__sub-heading u-h3 c-article__sub-heading--light" id="Sec17">Procedure</h4><p>We ran statcheck on the 49 articles twice: once in default mode, and once with an automatic one-tailed test detection. The one-tailed test detection works as follows: if the words “one-tailed,” “one-sided,” or “directional” (with various spacing or punctuation) are mentioned in the article <i>and</i> a result is not an inconsistency if it is a one-tailed test, the result is counted as correct. From the complete statcheck results, we selected the cases in which the test statistic was <i>t</i>, <i>F</i>, or χ<sup>2</sup>, and in where <i>p</i> &lt; .05.</p><h3 class="c-article__sub-heading u-h3" id="Sec18">Results</h3><h4 class="c-article__sub-heading u-h3 c-article__sub-heading--light" id="Sec19">Descriptives</h4><p>Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.3758/s13428-015-0664-2#Tab4">4</a> below shows the number of extracted statistics and the number of identified errors for both Wicherts et al., statcheck in default mode, and statcheck with the automatic one-tailed test detection.</p><p>Wicherts et al. extracted 1,148 results from the 49 articles, whereas statcheck extracted 775 results (67.5 %). Even though statcheck found fewer results, it found relatively more reporting errors (4.3 % of all results in Wicherts et al. vs. 9.0 % or 7.2 % of all results in statcheck, without or with one-tailed detection, respectively). In the next sections we will identify possible causes for these differences.</p><h4 class="c-article__sub-heading u-h3 c-article__sub-heading--light" id="Sec20">Explanations for discrepancies in the number of extracted statistics</h4><p>We found that in 13 articles statcheck reported the exact same amount of statistics as Wicherts et al. In 23 articles Wicherts et al. found more statistics than statcheck, and in 13 articles statcheck found more results than Wicherts et al. Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.3758/s13428-015-0664-2#Tab5">5</a> shows the explanations for these discrepancies.</p><p>Most of the results that statcheck missed were results that were not reported completely (e.g., results in tables) or not exactly according to the APA format (e.g., an effect size reported in between the test statistic and the <i>p</i>-value, or the results being reported in a sentence). Furthermore, one article in the sample of Wicherts et al. has been retracted since 2011, and we could not download it anymore; its 28 <i>p</i>-values were not included in the statcheck validity study.</p><p>Most of the results that were only included by statcheck but not by Wicherts et al. were results that were that were not reported in the <i>Results</i> section but in footnotes, in the <i>Methods</i> section, or in the <i>Discussion</i>. Wicherts et al. did not take these results into account; their explicit inclusion criterion was that the result had to be in the text or in a table in the <i>Results</i> section of a paper. statcheck could not make this distinction and included results independent from their location. Furthermore, Wicherts et al. did not include the two G<sup>2</sup> statistics that statcheck counted as χ<sup>2</sup> statistics. Statcheck also included an inexactly reported <i>F</i>-statistic that Wicherts et al. excluded, because it referred to multiple tests. Finally, we found two results that fitted their inclusion criteria, but were inadvertently not included by the Wicherts et al. sample.</p><h4 class="c-article__sub-heading u-h3 c-article__sub-heading--light" id="Sec21">Explanations for discrepancies in the number of identified inconsistencies</h4><p>There were discrepancies in the number of (gross) inconsistencies that Wicherts et al. and statcheck found. Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.3758/s13428-015-0664-2#Tab6">6</a> explains these inconsistencies in detail. In 13 cases Wicherts et al. found more errors than statcheck (with default options). However, all these cases were results that statcheck did not scan for one of the reasons mentioned above. There are no other cases in which Wicherts et al. found more errors. The use of default statcheck did not highlight any false negatives.</p><p>The default statcheck did, however, find 34 false positives (i.e., it marked results as inconsistent whereas Wicherts et al. did not). Closer inspection of these cases highlighted four main causes. Firstly, seven cases were not included in the sample of Wicherts et al. Secondly, seven of the results that statcheck classified as an error, but Wicherts et al. did not, were results in which the <i>p</i>-value was reported to be zero (<i>p</i> = .000). Wicherts et al. counted this as correct, in cases where rounding would indeed render <i>p</i> = .000. However, statcheck counts this as inconsistent, because a <i>p</i>-value this small should be reported as <i>p</i> &lt; .001, but not as <i>p</i> = .000 (American Psychological Association, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="American Psychological Association. (2010). Publication Manual of the American Psychological Association (6th ed.). Washington, DC: American Psychological Association." href="/article/10.3758/s13428-015-0664-2#ref-CR3" id="ref-link-section-d131366e3078">2010</a>, p. 114). Thirdly, there were 11 cases (in two articles) in which the <i>p</i>-value was inconsistent due to a Huyn-Feldt correction, which statcheck cannot take into account. Fourthly, there were nine cases in which the reported <i>p</i>-value was one-tailed and therefore twice as low as statcheck computed.</p><p>The discrepancies in the gross inconsistencies between the default statcheck and Wicherts et al. were due to seven one-tailed tests (see Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.3758/s13428-015-0664-2#Tab7">7</a>). Because of these one-tailed tests, statcheck gives an exaggerated image of how many inconsistencies there are in the literature. Therefore, we also inspect the results of statcheck with the one-tailed test detection.</p><p>When statcheck uses the one-tailed test detection all but one one-tailed test previously marked as inconsistent are now categorized as correct (see Tables <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.3758/s13428-015-0664-2#Tab6">6</a> and <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.3758/s13428-015-0664-2#Tab7">7</a>).<sup><a href="#Fn2"><span class="u-visually-hidden">Footnote </span>2</a></sup> The one-tailed test detection does result in six more false negatives, in which an inconsistent two-tailed test is counted as correct (see Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.3758/s13428-015-0664-2#Tab6">6</a>). Overall, statcheck now detected 56 inconsistencies in 775 <i>p</i>-values (7.2 %) and eight gross inconsistencies (1.0 %), which is closer to the inconsistency prevalence found by Wicherts et al. (4.3 % and .9 %, respectively) than without the one-tailed test detection. In sum, statcheck performs better with the one-tailed test detection.</p><h4 class="c-article__sub-heading u-h3 c-article__sub-heading--light" id="Sec22">Inter-rater reliability manual versus statcheck</h4><p>We also calculated the inter-rater reliability between the manual coding of inconsistencies and gross inconsistencies in Wicherts et al. and the automatic coding in statcheck. We distinguished between three different scenarios: in the first statcheck ran in default mode (without one-tailed test detection), in the second the automatic one-tailed test detection in statcheck was switched on, and in the last we ran statcheck with the automatic one-tailed test detection and we excluded cases in which <i>p</i> was reported as <i>p</i> = .000, since this was not counted as an inconsistency in Wicherts et al., but statcheck is intentionally programmed to see this as an inconsistency (since <i>p</i> cannot be zero and it should have been reported as <i>p</i> &lt; .001). In all three scenarios we only included <i>p</i>-values that were rated both by Wicherts et al. and statcheck.</p><p>Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.3758/s13428-015-0664-2#Tab8">8</a> shows the inter-rater reliabilities for the inconsistencies and gross inconsistencies in the three scenarios. If statcheck is ran without one-tailed test detection, Cohen’s kappa for the inconsistencies is .71 and for the gross inconsistencies .74. If we turn on the automatic one-tailed test detection, Cohen’s kappa for the gross inconsistencies increases to .89, but it slightly decreases for the inconsistencies to .69. Note, however, there are fewer <i>p</i>-values that statcheck wrongly marked as inconsistent with the one-tailed test detection (see Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.3758/s13428-015-0664-2#Tab5">5</a>). When both the one-tailed detection is switched on and we exclude cases in which <i>p</i> is reported as <i>p</i> = .000, Cohen’s kappa for the inconsistencies increases to .76, and remains at .89 for the gross inconsistencies.</p><h3 class="c-article__sub-heading u-h3" id="Sec23">Discussion</h3><p>In this validity check we compared the results of Wicherts et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Wicherts, J. M., Bakker, M., &amp; Molenaar, D. (2011). Willingness to share research data is related to the strength of the evidence and the quality of reporting of statistical results. PLoS One, 6(11), e26828." href="/article/10.3758/s13428-015-0664-2#ref-CR40" id="ref-link-section-d131366e3167">2011</a>) with the results of the default version of statcheck and statcheck with automatic one-tailed test detection. The results show that statcheck extracted 67.5 % of the manually retrieved results. The main reason for this is that statcheck could not read results that were not reported completely or not in APA style. Even though statcheck included fewer results than Wicherts et al., it found more inconsistencies. These inconsistencies were mainly one-tailed tests that were counted as inconsistent. Specifically, Wicherts et al. found 49 of the 1,148 results (4.3 %) to be inconsistent and ten to be grossly inconsistent (.9 %), whereas statcheck found 70 of the 775 results (9.0 %) to be inconsistent and 17 (2.2 %) to be grossly inconsistent. In other words, statcheck found an inconsistency rate that was 4.7 percentage points higher than the one found in a manual search and a gross inconsistency rate that is 1.3 percentage point higher. The inter-rater reliability for inconsistencies was .71 and for gross inconsistencies .74.</p><p>When statcheck was run with automatic one-tailed test detection, it still found more errors than did Wicherts et al. but the difference was smaller. Now statcheck found 56 of 775 results (7.2 %) to be inconsistent and eight results (1.0 %) to be grossly inconsistent. That means that with automatic one-tailed test detection statcheck found an inconsistency rate of only 2.9 percentage points higher than the one found in a manual search and a gross inconsistency rate of .1 percentage point higher. The inter-rater reliability for gross inconsistencies was as high as .89, but decreased slightly for inconsistencies to .69. However, since there are fewer <i>p</i>-values wrongly marked as inconsistent with the automatic one-tailed test detection, we advise users to use this option when searching for reporting inconsistencies.</p><p>The main limitation of statcheck is that it seems to give an overestimation of the number of inconsistencies in a sample. A large part of these false positives were due to the conscious choice to count <i>p</i> = .000 as inconsistent. If we exclude these cases, the inter-rater reliability for inconsistencies goes up to .76, and remains .89 for gross inconsistencies (with automatic one-tailed test detection).Furthermore, the false positives caused by one-tailed tests are mostly solved by statcheck’s one-tailed test detection. That leaves only the false positives due to <i>p</i>-values adjusted for multiple testing, eventually resulting in only a slight overestimation of the inconsistencies. Herein lies a possibility for future improvement of the program.</p><p>In conclusion, since statcheck slightly overestimated the prevalence of inconsistencies in our study, its results should be interpreted with care. We also advise against using statcheck blindly to point out mistakes in a single article. The main two usages of statcheck are: (1) to give an overall indication of the prevalence of inconsistencies in a large amount of literature, and (2) to give a first indication of inconsistent <i>p</i>-values in a single article, after which the results should be checked by hand. The final verdict on whether a result is erroneous should be based on careful consideration by an expert.</p><h3 class="c-article__sub-heading u-h3" id="App1">
                           <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.3758/s13428-015-0664-2#Sec24">Appendix B</a>: Additional Analyses</h3><h3 class="c-article__sub-heading u-h3" id="Sec25">Number of articles with null-hypothesis significance testing results</h3><p>Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.3758/s13428-015-0664-2#Fig8">8</a> shows the number of articles that contain null-hypothesis significance testing (NHST) results over the years averaged over all American Psychological Association (APA) journals (<i>Developmental Psychology</i> (DP), <i>Journal of Consulting and Clinical Psychology</i> (JCCP), <i>Journal of Experimental Psychology: General</i> (JEPG), <i>Journal of Personality and Social Psychology</i> (JPSP), and <i>Journal of Applied Psychology</i> (JAP); dark gray panel) and split up per journal (light gray panels for the APA journals and white panels for the non-APA journals –<i>Psychological Science</i> (PS), <i>Frontiers in Psychology</i> (FP), and <i>Public Library of Science</i> (PLoS)). The number of articles with NHST results seems to remain relatively stable over the years in JCCP and JAP. JPSP has published fewer articles with NHST results over the years. In DP and JEPG the number of articles with NHST results increased over the years. The newer journals PS, FP, and especially PLOS show a steep increase in articles with NHST results in the last few years.</p><h4 class="c-article__sub-heading u-h3 c-article__sub-heading--light" id="Sec26">Number of exactly and inexactly reported <i>p</i>-values over the years</h4><p>Besides the general prevalence of NHST results over the years, we were also interested in the prevalence of exactly reported <i>p</i>-values (<i>p</i> = …) and inexactly reported <i>p</i>-values (<i>p</i> &lt;/&gt; …, or “ns”, which could be interpreted the same as <i>p</i> &gt; .05).<sup><a href="#Fn3"><span class="u-visually-hidden">Footnote </span>3</a></sup> From the fourth edition of the APA Publication Manual onward (1994), researchers have been encouraged to report <i>p</i>-values exactly, so we expected to find an increase of exactly reported <i>p</i>-values.</p><p>We inspected the prevalence of exact and inexact <i>p</i>-values over time averaged over all APA journals (DP, JCCP, JEPG, JPSP, and JAP; dark gray panel in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.3758/s13428-015-0664-2#Fig9">9</a>), and split up per journal (light gray panels for the APA journals and white panels for the non-APA journals in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.3758/s13428-015-0664-2#Fig9">9</a>). The average number of exact <i>p</i>-values per article with NHST results increases for all journals. For all journals except JAP and PS the number of inexact <i>p</i>-values per article with NHST results increased, although the increase is less steep than for exact <i>p</i>-values.</p>
                      <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-8"><figure><figcaption><b id="Fig8" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 8</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-category="article body" data-track-label="image" data-track-action="view figure" href="/article/10.3758/s13428-015-0664-2/figures/8" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.3758%2Fs13428-015-0664-2/MediaObjects/13428_2015_664_Fig8_HTML.gif?as=webp"></source><img aria-describedby="figure-8-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.3758%2Fs13428-015-0664-2/MediaObjects/13428_2015_664_Fig8_HTML.gif" alt="figure8" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-8-desc"><p>The total number of downloaded articles and the number of published articles that contain NHST results over the years, averaged over all American Psychological Association (APA) journals (<i>Developmental Psychology</i> (DP), <i>Journal of Consulting and Clinical Psychology</i> (JCCP), <i>Journal of Experimental Psychology: General</i> (JEPG), <i>Journal of Personality and Social Psychology</i> (JPSP), and <i>Journal of Applied Psychology</i> (JAP); dark gray panel), and split up per journal (light gray panels for the APA journals and white panels for the non-APA journals –<i>Psychological Science</i> (PS), <i>Frontiers in Psychology</i> (FP), and <i>Public Library of Science</i> (PLoS)). Note that the y-axes in the plot for All APA Journals, FP, and PLOS are different from the others and continue until 1,000, 1,050, and 3,750, respectively. The unstandardized regression coefficient ‘b’ and the coefficient of determination ‘R<sup>2</sup>’ of the linear trend are shown per journal for both the downloaded articles (down) as articles with null-hypothesis significance testing results (NHST) over the years</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-category="article body" data-track-label="button" data-track-action="view figure" href="/article/10.3758/s13428-015-0664-2/figures/8" data-track-dest="link:Figure8 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                    
                      <div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-9"><figure><figcaption><b id="Fig9" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 9</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-category="article body" data-track-label="image" data-track-action="view figure" href="/article/10.3758/s13428-015-0664-2/figures/9" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.3758%2Fs13428-015-0664-2/MediaObjects/13428_2015_664_Fig9_HTML.gif?as=webp"></source><img aria-describedby="figure-9-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.3758%2Fs13428-015-0664-2/MediaObjects/13428_2015_664_Fig9_HTML.gif" alt="figure9" loading="lazy" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-9-desc"><p>The average number of exact and inexact null-hypothesis significance testing (NHST) results per article over the years, averaged over all journals (grey panel), and split up by journal (white panels). The unstandardized regression coefficient ‘b’ and the coefficient of determination ‘R<sup>2</sup>’ of the linear trend are shown per journal for both exact (ex) as inexact (inex) p-values over the years. <i>APA</i> American Psychological Assocation, <i>DP</i> Developmental Psychology, <i>JCCP</i> Journal of Consulting and Clinical Psychology, JEPG Journal of Experimental Psychology: General , <i>JPSP</i> Journal of Personality and Social Psychology, <i>JAP</i> Journal of Applied Psychology, <i>PS</i> Psychological Science, <i>FP</i> Frontiers in Psychology, <i>PLoS</i> Public Library of Science</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-category="article body" data-track-label="button" data-track-action="view figure" href="/article/10.3758/s13428-015-0664-2/figures/9" data-track-dest="link:Figure9 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                    
                      <div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-3"><figure><figcaption class="c-article-table__figcaption"><b id="Tab3" data-test="table-caption">Table 3 Inclusion criteria for the statistical results to check for inconsistencies in Wicherts et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Wicherts, J. M., Bakker, M., &amp; Molenaar, D. (2011). Willingness to share research data is related to the strength of the evidence and the quality of reporting of statistical results. PLoS One, 6(11), e26828." href="/article/10.3758/s13428-015-0664-2#ref-CR40" id="ref-link-section-d131366e3415">2011</a>) and statcheck</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-category="article body" data-track-label="button" rel="nofollow" href="/article/10.3758/s13428-015-0664-2/tables/3"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                    
                      <div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-4"><figure><figcaption class="c-article-table__figcaption"><b id="Tab4" data-test="table-caption">Table 4 The number of extracted statistics and the number of identified errors for both Wicherts et al. and statcheck (with automatic one-tailed test detection)</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-category="article body" data-track-label="button" rel="nofollow" href="/article/10.3758/s13428-015-0664-2/tables/4"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                    
                      <div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-5"><figure><figcaption class="c-article-table__figcaption"><b id="Tab5" data-test="table-caption">Table 5 Explanation of the discrepancies between the number of results that Wicherts et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Wicherts, J. M., Bakker, M., &amp; Molenaar, D. (2011). Willingness to share research data is related to the strength of the evidence and the quality of reporting of statistical results. PLoS One, 6(11), e26828." href="/article/10.3758/s13428-015-0664-2#ref-CR40" id="ref-link-section-d131366e3772">2011</a>) and statcheck extracted</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-category="article body" data-track-label="button" rel="nofollow" href="/article/10.3758/s13428-015-0664-2/tables/5"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                    
                      <div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-6"><figure><figcaption class="c-article-table__figcaption"><b id="Tab6" data-test="table-caption">Table 6 Explanation of the discrepancies between the number of inconsistencies found by Wicherts et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Wicherts, J. M., Bakker, M., &amp; Molenaar, D. (2011). Willingness to share research data is related to the strength of the evidence and the quality of reporting of statistical results. PLoS One, 6(11), e26828." href="/article/10.3758/s13428-015-0664-2#ref-CR40" id="ref-link-section-d131366e4120">2011</a>) and statcheck (with automatic one-tailed test detection)</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-category="article body" data-track-label="button" rel="nofollow" href="/article/10.3758/s13428-015-0664-2/tables/6"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                    
                      <div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-7"><figure><figcaption class="c-article-table__figcaption"><b id="Tab7" data-test="table-caption">Table 7 Explanation of the discrepancies between the number of gross inconsistencies found by Wicherts et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Wicherts, J. M., Bakker, M., &amp; Molenaar, D. (2011). Willingness to share research data is related to the strength of the evidence and the quality of reporting of statistical results. PLoS One, 6(11), e26828." href="/article/10.3758/s13428-015-0664-2#ref-CR40" id="ref-link-section-d131366e4440">2011</a>) and statcheck (with automatic one-tailed test detection)</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-category="article body" data-track-label="button" rel="nofollow" href="/article/10.3758/s13428-015-0664-2/tables/7"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                    
                      <div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-8"><figure><figcaption class="c-article-table__figcaption"><b id="Tab8" data-test="table-caption">Table 8 The inter-rater reliability expressed in Cohen’s kappa between the manual coding in Wicherts et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2011" title="Wicherts, J. M., Bakker, M., &amp; Molenaar, D. (2011). Willingness to share research data is related to the strength of the evidence and the quality of reporting of statistical results. PLoS One, 6(11), e26828." href="/article/10.3758/s13428-015-0664-2#ref-CR40" id="ref-link-section-d131366e4643">2011</a>) and the automatic coding in statcheck without or with automatic one-tailed detection, and with and without exclusion of <i>p</i> = .000</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-category="article body" data-track-label="button" rel="nofollow" href="/article/10.3758/s13428-015-0664-2/tables/8"><span>Full size table</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                    </div></div></section><section aria-labelledby="rightslink"><div class="c-article-section" id="rightslink-section"><h2 class="c-article-section__title u-h2 js-section-title js-c-reading-companion-sections-item" id="rightslink">Rights and permissions</h2><div class="c-article-section__content" id="rightslink-content"><div class="c-article-license">
                <p>
                           <b>Open Access</b>  This article is distributed under the terms of the Creative Commons Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made.</p>
              </div><p class="c-article-rights"><a data-track="click" data-track-action="view rights and permissions" data-track-category="article body" data-track-label="link" href="https://s100.copyright.com/AppDispatchServlet?title=The%20prevalence%20of%20statistical%20reporting%20errors%20in%20psychology%20%281985%E2%80%932013%29&amp;author=Mich%C3%A8le%20B.%20Nuijten%20et%20al&amp;contentID=10.3758%2Fs13428-015-0664-2&amp;publication=1554-3528&amp;publicationDate=2015-10-23&amp;publisherName=SpringerNature&amp;orderBeanReset=true&amp;oa=CC%20BY">Reprints and Permissions</a></p></div></div></section><section aria-labelledby="article-info"><div class="c-article-section" id="article-info-section"><h2 class="c-article-section__title u-h2 js-section-title js-c-reading-companion-sections-item" id="article-info">About this article</h2><div class="c-article-section__content" id="article-info-content"><div class="c-bibliographic-information"><div class="u-hide-print c-bibliographic-information__column c-bibliographic-information__column--border"><a data-crossmark="10.3758/s13428-015-0664-2" target="_blank" rel="noopener" href="https://crossmark.crossref.org/dialog/?doi=10.3758/s13428-015-0664-2" data-track="click" data-track-action="Click Crossmark" data-track-category="article body" data-track-label="link" data-test="crossmark"><img width="57" height="81" alt="Verify currency and authenticity via CrossMark" src="data:image/svg+xml;base64,<svg height="81" width="57" xmlns="http://www.w3.org/2000/svg"><g fill="none" fill-rule="evenodd"><path d="m17.35 35.45 21.3-14.2v-17.03h-21.3" fill="#989898"/><path d="m38.65 35.45-21.3-14.2v-17.03h21.3" fill="#747474"/><path d="m28 .5c-12.98 0-23.5 10.52-23.5 23.5s10.52 23.5 23.5 23.5 23.5-10.52 23.5-23.5c0-6.23-2.48-12.21-6.88-16.62-4.41-4.4-10.39-6.88-16.62-6.88zm0 41.25c-9.8 0-17.75-7.95-17.75-17.75s7.95-17.75 17.75-17.75 17.75 7.95 17.75 17.75c0 4.71-1.87 9.22-5.2 12.55s-7.84 5.2-12.55 5.2z" fill="#535353"/><path d="m41 36c-5.81 6.23-15.23 7.45-22.43 2.9-7.21-4.55-10.16-13.57-7.03-21.5l-4.92-3.11c-4.95 10.7-1.19 23.42 8.78 29.71 9.97 6.3 23.07 4.22 30.6-4.86z" fill="#9c9c9c"/><path d="m.2 58.45c0-.75.11-1.42.33-2.01s.52-1.09.91-1.5c.38-.41.83-.73 1.34-.94.51-.22 1.06-.32 1.65-.32.56 0 1.06.11 1.51.35.44.23.81.5 1.1.81l-.91 1.01c-.24-.24-.49-.42-.75-.56-.27-.13-.58-.2-.93-.2-.39 0-.73.08-1.05.23-.31.16-.58.37-.81.66-.23.28-.41.63-.53 1.04-.13.41-.19.88-.19 1.39 0 1.04.23 1.86.68 2.46.45.59 1.06.88 1.84.88.41 0 .77-.07 1.07-.23s.59-.39.85-.68l.91 1c-.38.43-.8.76-1.28.99-.47.22-1 .34-1.58.34-.59 0-1.13-.1-1.64-.31-.5-.2-.94-.51-1.31-.91-.38-.4-.67-.9-.88-1.48-.22-.59-.33-1.26-.33-2.02zm8.4-5.33h1.61v2.54l-.05 1.33c.29-.27.61-.51.96-.72s.76-.31 1.24-.31c.73 0 1.27.23 1.61.71.33.47.5 1.14.5 2.02v4.31h-1.61v-4.1c0-.57-.08-.97-.25-1.21-.17-.23-.45-.35-.83-.35-.3 0-.56.08-.79.22-.23.15-.49.36-.78.64v4.8h-1.61zm7.37 6.45c0-.56.09-1.06.26-1.51.18-.45.42-.83.71-1.14.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.36c.07.62.29 1.1.65 1.44.36.33.82.5 1.38.5.29 0 .57-.04.83-.13s.51-.21.76-.37l.55 1.01c-.33.21-.69.39-1.09.53-.41.14-.83.21-1.26.21-.48 0-.92-.08-1.34-.25-.41-.16-.76-.4-1.07-.7-.31-.31-.55-.69-.72-1.13-.18-.44-.26-.95-.26-1.52zm4.6-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.07.45-.31.29-.5.73-.58 1.3zm2.5.62c0-.57.09-1.08.28-1.53.18-.44.43-.82.75-1.13s.69-.54 1.1-.71c.42-.16.85-.24 1.31-.24.45 0 .84.08 1.17.23s.61.34.85.57l-.77 1.02c-.19-.16-.38-.28-.56-.37-.19-.09-.39-.14-.61-.14-.56 0-1.01.21-1.35.63-.35.41-.52.97-.52 1.67 0 .69.17 1.24.51 1.66.34.41.78.62 1.32.62.28 0 .54-.06.78-.17.24-.12.45-.26.64-.42l.67 1.03c-.33.29-.69.51-1.08.65-.39.15-.78.23-1.18.23-.46 0-.9-.08-1.31-.24-.4-.16-.75-.39-1.05-.7s-.53-.69-.7-1.13c-.17-.45-.25-.96-.25-1.53zm6.91-6.45h1.58v6.17h.05l2.54-3.16h1.77l-2.35 2.8 2.59 4.07h-1.75l-1.77-2.98-1.08 1.23v1.75h-1.58zm13.69 1.27c-.25-.11-.5-.17-.75-.17-.58 0-.87.39-.87 1.16v.75h1.34v1.27h-1.34v5.6h-1.61v-5.6h-.92v-1.2l.92-.07v-.72c0-.35.04-.68.13-.98.08-.31.21-.57.4-.79s.42-.39.71-.51c.28-.12.63-.18 1.04-.18.24 0 .48.02.69.07.22.05.41.1.57.17zm.48 5.18c0-.57.09-1.08.27-1.53.17-.44.41-.82.72-1.13.3-.31.65-.54 1.04-.71.39-.16.8-.24 1.23-.24s.84.08 1.24.24c.4.17.74.4 1.04.71s.54.69.72 1.13c.19.45.28.96.28 1.53s-.09 1.08-.28 1.53c-.18.44-.42.82-.72 1.13s-.64.54-1.04.7-.81.24-1.24.24-.84-.08-1.23-.24-.74-.39-1.04-.7c-.31-.31-.55-.69-.72-1.13-.18-.45-.27-.96-.27-1.53zm1.65 0c0 .69.14 1.24.43 1.66.28.41.68.62 1.18.62.51 0 .9-.21 1.19-.62.29-.42.44-.97.44-1.66 0-.7-.15-1.26-.44-1.67-.29-.42-.68-.63-1.19-.63-.5 0-.9.21-1.18.63-.29.41-.43.97-.43 1.67zm6.48-3.44h1.33l.12 1.21h.05c.24-.44.54-.79.88-1.02.35-.24.7-.36 1.07-.36.32 0 .59.05.78.14l-.28 1.4-.33-.09c-.11-.01-.23-.02-.38-.02-.27 0-.56.1-.86.31s-.55.58-.77 1.1v4.2h-1.61zm-47.87 15h1.61v4.1c0 .57.08.97.25 1.2.17.24.44.35.81.35.3 0 .57-.07.8-.22.22-.15.47-.39.73-.73v-4.7h1.61v6.87h-1.32l-.12-1.01h-.04c-.3.36-.63.64-.98.86-.35.21-.76.32-1.24.32-.73 0-1.27-.24-1.61-.71-.33-.47-.5-1.14-.5-2.02zm9.46 7.43v2.16h-1.61v-9.59h1.33l.12.72h.05c.29-.24.61-.45.97-.63.35-.17.72-.26 1.1-.26.43 0 .81.08 1.15.24.33.17.61.4.84.71.24.31.41.68.53 1.11.13.42.19.91.19 1.44 0 .59-.09 1.11-.25 1.57-.16.47-.38.85-.65 1.16-.27.32-.58.56-.94.73-.35.16-.72.25-1.1.25-.3 0-.6-.07-.9-.2s-.59-.31-.87-.56zm0-2.3c.26.22.5.37.73.45.24.09.46.13.66.13.46 0 .84-.2 1.15-.6.31-.39.46-.98.46-1.77 0-.69-.12-1.22-.35-1.61-.23-.38-.61-.57-1.13-.57-.49 0-.99.26-1.52.77zm5.87-1.69c0-.56.08-1.06.25-1.51.16-.45.37-.83.65-1.14.27-.3.58-.54.93-.71s.71-.25 1.08-.25c.39 0 .73.07 1 .2.27.14.54.32.81.55l-.06-1.1v-2.49h1.61v9.88h-1.33l-.11-.74h-.06c-.25.25-.54.46-.88.64-.33.18-.69.27-1.06.27-.87 0-1.56-.32-2.07-.95s-.76-1.51-.76-2.65zm1.67-.01c0 .74.13 1.31.4 1.7.26.38.65.58 1.15.58.51 0 .99-.26 1.44-.77v-3.21c-.24-.21-.48-.36-.7-.45-.23-.08-.46-.12-.7-.12-.45 0-.82.19-1.13.59-.31.39-.46.95-.46 1.68zm6.35 1.59c0-.73.32-1.3.97-1.71.64-.4 1.67-.68 3.08-.84 0-.17-.02-.34-.07-.51-.05-.16-.12-.3-.22-.43s-.22-.22-.38-.3c-.15-.06-.34-.1-.58-.1-.34 0-.68.07-1 .2s-.63.29-.93.47l-.59-1.08c.39-.24.81-.45 1.28-.63.47-.17.99-.26 1.54-.26.86 0 1.51.25 1.93.76s.63 1.25.63 2.21v4.07h-1.32l-.12-.76h-.05c-.3.27-.63.48-.98.66s-.73.27-1.14.27c-.61 0-1.1-.19-1.48-.56-.38-.36-.57-.85-.57-1.46zm1.57-.12c0 .3.09.53.27.67.19.14.42.21.71.21.28 0 .54-.07.77-.2s.48-.31.73-.56v-1.54c-.47.06-.86.13-1.18.23-.31.09-.57.19-.76.31s-.33.25-.41.4c-.09.15-.13.31-.13.48zm6.29-3.63h-.98v-1.2l1.06-.07.2-1.88h1.34v1.88h1.75v1.27h-1.75v3.28c0 .8.32 1.2.97 1.2.12 0 .24-.01.37-.04.12-.03.24-.07.34-.11l.28 1.19c-.19.06-.4.12-.64.17-.23.05-.49.08-.76.08-.4 0-.74-.06-1.02-.18-.27-.13-.49-.3-.67-.52-.17-.21-.3-.48-.37-.78-.08-.3-.12-.64-.12-1.01zm4.36 2.17c0-.56.09-1.06.27-1.51s.41-.83.71-1.14c.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.37c.08.62.29 1.1.65 1.44.36.33.82.5 1.38.5.3 0 .58-.04.84-.13.25-.09.51-.21.76-.37l.54 1.01c-.32.21-.69.39-1.09.53s-.82.21-1.26.21c-.47 0-.92-.08-1.33-.25-.41-.16-.77-.4-1.08-.7-.3-.31-.54-.69-.72-1.13-.17-.44-.26-.95-.26-1.52zm4.61-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.08.45-.31.29-.5.73-.57 1.3zm3.01 2.23c.31.24.61.43.92.57.3.13.63.2.98.2.38 0 .65-.08.83-.23s.27-.35.27-.6c0-.14-.05-.26-.13-.37-.08-.1-.2-.2-.34-.28-.14-.09-.29-.16-.47-.23l-.53-.22c-.23-.09-.46-.18-.69-.3-.23-.11-.44-.24-.62-.4s-.33-.35-.45-.55c-.12-.21-.18-.46-.18-.75 0-.61.23-1.1.68-1.49.44-.38 1.06-.57 1.83-.57.48 0 .91.08 1.29.25s.71.36.99.57l-.74.98c-.24-.17-.49-.32-.73-.42-.25-.11-.51-.16-.78-.16-.35 0-.6.07-.76.21-.17.15-.25.33-.25.54 0 .14.04.26.12.36s.18.18.31.26c.14.07.29.14.46.21l.54.19c.23.09.47.18.7.29s.44.24.64.4c.19.16.34.35.46.58.11.23.17.5.17.82 0 .3-.06.58-.17.83-.12.26-.29.48-.51.68-.23.19-.51.34-.84.45-.34.11-.72.17-1.15.17-.48 0-.95-.09-1.41-.27-.46-.19-.86-.41-1.2-.68z" fill="#535353"/></g></svg>" /></a></div><div class="c-bibliographic-information__column"><h3 class="c-article__sub-heading" id="citeas">Cite this article</h3><p class="c-bibliographic-information__citation">Nuijten, M.B., Hartgerink, C.H.J., van Assen, M.A.L.M. <i>et al.</i> The prevalence of statistical reporting errors in psychology (1985–2013).
                    <i>Behav Res </i> <b>48, </b>1205–1226 (2016). https://doi.org/10.3758/s13428-015-0664-2</p><p class="c-bibliographic-information__download-citation u-hide-print"><a data-test="citation-link" data-track="click" data-track-action="download article citation" data-track-category="article body" data-track-label="link" href="/article/10.3758/s13428-015-0664-2.ris">Download citation<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p><ul class="c-bibliographic-information__list" data-test="publication-history"><li class="c-bibliographic-information__list-item"><p>Published<span class="u-hide">: </span><span class="u-clearfix c-bibliographic-information__value"><time datetime="2015-10-23">23 October 2015</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Issue Date<span class="u-hide">: </span><span class="u-clearfix c-bibliographic-information__value"><time datetime="2016-12">December 2016</time></span></p></li><li class="c-bibliographic-information__list-item c-bibliographic-information__list-item--doi"><p><abbr title="Digital Object Identifier">DOI</abbr><span class="u-hide">: </span><span class="u-clearfix c-bibliographic-information__value"><a href="https://doi.org/10.3758/s13428-015-0664-2" data-track="click" data-track-action="view doi" data-track-category="article body" data-track-label="link" itemprop="sameAs">https://doi.org/10.3758/s13428-015-0664-2</a></span></p></li></ul><div data-component="share-box"></div><h3 class="c-article__sub-heading u-h3">Keywords</h3><ul class="c-article-subject-list"><li class="c-article-subject-list__subject"><span itemprop="about">Reporting errors</span></li><li class="c-article-subject-list__subject"><span itemprop="about">
                        <i>p</i>-values</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Significance</span></li><li class="c-article-subject-list__subject"><span itemprop="about">False positives</span></li><li class="c-article-subject-list__subject"><span itemprop="about">NHST</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Questionable research practices</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Publication bias</span></li></ul><div data-component="article-info-list"></div></div></div></div></div></section>
                    </div>
                </article>
            </main>

            <div class="c-article-extras u-text-sm u-hide-print" id="sidebar" data-container-type="reading-companion" data-track-component="reading companion">
                <aside>
                    <div data-test="download-article-link-wrapper">
                        <div id="pdflink-container" class="download-article test-pdf-link">
    
    <div class="c-pdf-download u-clear-both">
        <a href="//link.springer.com/content/pdf/10.3758/s13428-015-0664-2.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-category="article body" data-track-label="button">
            <span>Download PDF</span>
            <svg width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
        </a>
    </div>
    
</div>

                    </div>

                    <div data-test="collections">
                        
                    </div>

                    <div data-test="editorial-summary">
                        
                    </div>

                    <div class="c-reading-companion">
                        <div class="c-reading-companion__sticky" data-component="reading-companion-sticky" data-test="reading-companion-sticky">
                            

                            <div class="c-reading-companion__panel c-reading-companion__sections c-reading-companion__panel--active" id="tabpanel-sections">
                                <div class="js-ad">
    <div class="c-ad c-ad--MPU1">
        <div class="c-ad c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-MPU1" data-gpt-unitpath="/270604982/springerlink/13428/article" data-gpt-sizes="300x250" data-gpt-targeting="pos=MPU1;articleid=664;"></div>
        </div>
    </div>
</div>

                            </div>
                            <div class="c-reading-companion__panel c-reading-companion__figures c-reading-companion__panel--full-width" id="tabpanel-figures"></div>
                            <div class="c-reading-companion__panel c-reading-companion__references c-reading-companion__panel--full-width" id="tabpanel-references"></div>
                        </div>
                    </div>
                </aside>
            </div>

        </div>
    </div>

    <div class="c-page-layout__footer">
        
    <footer class="app-footer" role="contentinfo">
        <div class="app-footer__aside-wrapper u-hide-print">
            <div class="app-footer__container">
                <p class="app-footer__strapline">Over 10 million scientific documents at your fingertips</p>
                
                    <div class="app-footer__edition" data-component="SV.EditionSwitcher">
                        <span class="u-visually-hidden" data-role="button-dropdown__title" data-btn-text="Switch between Academic & Corporate Edition">Switch Edition</span>
                        <ul class="app-footer-edition-list" data-role="button-dropdown__content" data-test="footer-edition-switcher-list">
                            <li class="selected">
                                <a data-test="footer-academic-link"
                                   href="/siteEdition/link"
                                   id="siteedition-academic-link">Academic Edition</a>
                            </li>
                            <li>
                                <a data-test="footer-corporate-link"
                                   href="/siteEdition/rd"
                                   id="siteedition-corporate-link">Corporate Edition</a>
                            </li>
                        </ul>
                    </div>
                
            </div>
        </div>
        <div class="app-footer__container">
            <ul class="app-footer__nav u-hide-print">
                <li><a href="/">Home</a></li>
                <li><a href="/impressum">Impressum</a></li>
                <li><a href="/termsandconditions">Legal information</a></li>
                <li><a href="/privacystatement">Privacy statement</a></li>
                <li><a href="/cookiepolicy">How we use cookies</a></li>
                <li><a href="/accessibility">Accessibility</a></li>
                <li><a id="contactus-footer-link" href="/contactus">Contact us</a></li>
            </ul>
            <div class="c-user-metadata">
    
        <p class="c-user-metadata__item">
            <span data-test="footer-user-login-status">Not logged in</span>
            <span data-test="footer-user-ip"> - 83.82.188.55</span>
        </p>
        <p class="c-user-metadata__item" data-test="footer-business-partners">
            Not affiliated
        </p>

        
    
</div>

            <a class="app-footer__parent-logo" target="_blank" rel="noopener" href="//www.springernature.com"  title="Go to Springer Nature">
                <span class="u-visually-hidden">Springer Nature</span>
                <svg width="125" height="12" focusable="false" aria-hidden="true">
                    <image width="125" height="12" alt="Springer Nature logo"
                           src=/oscar-static/images/springerlink/png/springernature-60a72a849b.png
                           xmlns:xlink="http://www.w3.org/1999/xlink"
                           xlink:href=/oscar-static/images/springerlink/svg/springernature-ecf01c77dd.svg>
                    </image>
                </svg>
            </a>
            <p class="app-footer__copyright">&copy; 2020 Springer Nature Switzerland AG. Part of <a target="_blank" rel="noopener" href="//www.springernature.com">Springer Nature</a>.</p>
            
        </div>
        
    <svg class="u-hide hide">
        <symbol id="global-icon-chevron-right" viewBox="0 0 16 16">
            <path d="M7.782 7L5.3 4.518c-.393-.392-.4-1.022-.02-1.403a1.001 1.001 0 011.417 0l4.176 4.177a1.001 1.001 0 010 1.416l-4.176 4.177a.991.991 0 01-1.4.016 1 1 0 01.003-1.42L7.782 9l1.013-.998z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-download" viewBox="0 0 16 16">
            <path d="M2 14c0-.556.449-1 1.002-1h9.996a.999.999 0 110 2H3.002A1.006 1.006 0 012 14zM9 2v6.8l2.482-2.482c.392-.392 1.022-.4 1.403-.02a1.001 1.001 0 010 1.417l-4.177 4.177a1.001 1.001 0 01-1.416 0L3.115 7.715a.991.991 0 01-.016-1.4 1 1 0 011.42.003L7 8.8V2c0-.55.444-.996 1-.996.552 0 1 .445 1 .996z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-email" viewBox="0 0 18 18">
            <path d="M1.995 2h14.01A2 2 0 0118 4.006v9.988A2 2 0 0116.005 16H1.995A2 2 0 010 13.994V4.006A2 2 0 011.995 2zM1 13.994A1 1 0 001.995 15h14.01A1 1 0 0017 13.994V4.006A1 1 0 0016.005 3H1.995A1 1 0 001 4.006zM9 11L2 7V5.557l7 4 7-4V7z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-institution" viewBox="0 0 18 18">
            <path d="M14 8a1 1 0 011 1v6h1.5a.5.5 0 01.5.5v.5h.5a.5.5 0 01.5.5V18H0v-1.5a.5.5 0 01.5-.5H1v-.5a.5.5 0 01.5-.5H3V9a1 1 0 112 0v6h8V9a1 1 0 011-1zM6 8l2 1v4l-2 1zm6 0v6l-2-1V9zM9.573.401l7.036 4.925A.92.92 0 0116.081 7H1.92a.92.92 0 01-.528-1.674L8.427.401a1 1 0 011.146 0zM9 2.441L5.345 5h7.31z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-search" viewBox="0 0 14 14">
            <path d="M13.545 12.648a.641.641 0 01.006.903.646.646 0 01-.903-.006l-2.664-2.663a6.125 6.125 0 11.897-.898l2.664 2.664zm-7.42-1.273a5.25 5.25 0 100-10.5 5.25 5.25 0 000 10.5z"></path>
        </symbol>
    </svg>

    </footer>



    </div>

    <script>
    window.config = {
        mustardcut: false
    };

    
    (function(H){H.className=H.className.replace(/\bno-js\b/,'js')})(document.documentElement);

        
    var mustardcutlink = document.getElementById('js-mustard');
    if (mustardcutlink && window.matchMedia && window.matchMedia(mustardcutlink.media).matches) {
        window.config.mustardcut = true;
    }
</script>

<script src=/oscar-static/app-springerlink/js/app-bundle-39cd0d3eb0.js></script>

<script>
    if (window.config && window.config.mustardcut) {
        var globalArticle = document.createElement('script');

        globalArticle.src = '/oscar-static/app-springerlink/js/global-article-bundle-97130aa30d.js';
        
        window.Component = {};
        document.body.appendChild(globalArticle);
        
    }
</script>

    <div id="googleanalytics-container">
    
        
    
</div>
<div id="google-tag-manager-head-container">
    
        
            <!-- Google Tag Manager -->
            <script>
                (function (w, d, s, l, i) {
                w[l] = w[l] || [];
                w[l].push({'gtm.start': new Date().getTime(), event: 'gtm.js'});
                var f = d.getElementsByTagName(s)[0],
                        j = d.createElement(s),
                        dl = l != 'dataLayer' ? '&l=' + l : '';
                j.async = true;
                j.src = 'https://www.googletagmanager.com/gtm.js?id=' + i + dl;
                f.parentNode.insertBefore(j, f);
            })(window, document, 'script', 'dataLayer', 'GTM-WCF9Z9');
            </script>
            <!-- End Google Tag Manager -->
        
    
</div>

<div id="google-tag-manager-body-container">
    
        
            <!-- Google Tag Manager (noscript) -->
            <noscript>
                <iframe src="https://www.googletagmanager.com/ns.html?id=GTM-WCF9Z9"
                        height="0" width="0" style="display:none;visibility:hidden"></iframe>
            </noscript>
            <!-- End Google Tag Manager (noscript) -->
        
    
</div>

</body>
</html>
